<!DOCTYPE html>
<html lang="en">

<head>
    <title>MyArxiv</title>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="robots" content="noindex, nofollow"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
    <link href="index.css" rel="stylesheet"/>
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
          integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
            integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx"
            crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
            integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR"
            crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function () {
            renderMathInElement(document.body, {
                // customised options
                // • auto-render specific keys, e.g.:
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true},
                    {left: "\\begin{equation}", right: "\\end{equation}", display: true},
                    {left: "\\begin{align}", right: "\\end{align}", display: true},
                    {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
                    {left: "\\begin{gather}", right: "\\end{gather}", display: true},
                    {left: "\\begin{CD}", right: "\\end{CD}", display: true},
                ],
                // • rendering keys, e.g.:
                throwOnError: false
            });
        });
    </script>
</head>

<body>
<section class="header-container">
    <div style="display:flex; justify-content:space-between; align-items:flex-end;">
        <div>
            <div class="header-title">
                MyArxiv
            </div>
        </div>

        <div class=icons>
            <label class="theme-switch" for="checkbox">
                <input type="checkbox" id="checkbox"/>
                <i id="theme-icon" class="ri-moon-line" style="font-size: 32px" rel="noopener noreferrer"></i>
            </label>
        </div>
    </div>
</section>

    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-13T00:00:00Z">2025-02-13</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">115</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Theoretical Benefit and Limitation of Diffusion Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guhao Feng, Yihan Geng, Jian Guan, Wei Wu, Liwei Wang, Di He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion language models have emerged as a promising approach for text
generation. One would naturally expect this method to be an efficient
replacement for autoregressive models since multiple tokens can be sampled in
parallel during each diffusion step. However, its efficiency-accuracy trade-off
is not yet well understood. In this paper, we present a rigorous theoretical
analysis of a widely used type of diffusion language model, the Masked
Diffusion Model (MDM), and find that its effectiveness heavily depends on the
target evaluation metric. Under mild conditions, we prove that when using
perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling
steps regardless of sequence length, demonstrating that efficiency can be
achieved without sacrificing performance. However, when using the sequence
error rate--which is important for understanding the "correctness" of a
sequence, such as a reasoning chain--we show that the required sampling steps
must scale linearly with sequence length to obtain "correct" sequences, thereby
eliminating MDM's efficiency advantage over autoregressive models. Our analysis
establishes the first theoretical foundation for understanding the benefits and
limitations of MDMs. All theoretical findings are supported by empirical
studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for
  Reasoning Quality, Robustness, and Efficiency 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09621v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09621v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Answering questions with Chain-of-Thought (CoT) has significantly enhanced
the reasoning capabilities of Large Language Models (LLMs), yet its impact on
Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth
investigation. In this paper, we introduce MME-CoT, a specialized benchmark
evaluating the CoT reasoning performance of LMMs, spanning six domains: math,
science, OCR, logic, space-time, and general scenes. As the first comprehensive
study in this area, we propose a thorough evaluation suite incorporating three
novel metrics that assess the reasoning quality, robustness, and efficiency at
a fine-grained level. Leveraging curated high-quality data and a unique
evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs,
uncovering several key insights: 1) Models with reflection mechanism
demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and
demonstrating the highest quality results; 2) CoT prompting often degrades LMM
performance on perception-heavy tasks, suggesting a potentially harmful
overthinking behavior; and 3) Although the CoT quality is high, LMMs with
reflection exhibit significant inefficiency in both normal response and
self-correction phases. We hope MME-CoT serves as a foundation for advancing
multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project Page: https://mmecot.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring the Potential of Encoder-free Architectures in 3D LMMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09620v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09620v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Encoder-free architectures have been preliminarily explored in the 2D visual
domain, yet it remains an open question whether they can be effectively applied
to 3D understanding scenarios. In this paper, we present the first
comprehensive investigation into the potential of encoder-free architectures to
overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs).
These challenges include the failure to adapt to varying point cloud
resolutions and the point features from the encoder not meeting the semantic
needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to
remove the encoder and enable the LLM to assume the role of the 3D encoder: 1)
We propose the LLM-embedded Semantic Encoding strategy in the pre-training
stage, exploring the effects of various point cloud self-supervised losses. And
we present the Hybrid Semantic Loss to extract high-level semantics. 2) We
introduce the Hierarchical Geometry Aggregation strategy in the instruction
tuning stage. This incorporates inductive bias into the LLM early layers to
focus on the local details of the point clouds. To the end, we present the
first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current
state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the
classification, captioning, and VQA tasks, respectively. Our results
demonstrate that the encoder-free architecture is highly promising for
replacing encoder-based architectures in the field of 3D understanding. The
code is released at https://github.com/Ivan-Tang-3D/ENEL
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The code is released at https://github.com/Ivan-Tang-3D/ENEL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human-LLM Coevolution: Evidence from Academic Writing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingmeng Geng, Roberto Trotta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With a statistical analysis of arXiv paper abstracts, we report a marked drop
in the frequency of several words previously identified as overused by ChatGPT,
such as "delve", starting soon after they were pointed out in early 2024. The
frequency of certain other words favored by ChatGPT, such as "significant", has
instead kept increasing. These phenomena suggest that some authors of academic
papers have adapted their use of large language models (LLMs), for example, by
selecting outputs or applying modifications to the LLM-generated content. Such
coevolution and cooperation of humans and LLMs thus introduce additional
challenges to the detection of machine-generated text in real-world scenarios.
Estimating the impact of LLMs on academic writing by examining word frequency
remains feasible, and more attention should be paid to words that were already
frequently employed, including those that have decreased in frequency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SelfCite: <span class="highlight-title">Self-Supervised</span> Alignment for Context Attribution in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SelfCite, a novel self-supervised approach that aligns LLMs to
generate high-quality, fine-grained, sentence-level citations for the
statements in their generated responses. Instead of only relying on costly and
labor-intensive annotations, SelfCite leverages a reward signal provided by the
LLM itself through context ablation: If a citation is necessary, removing the
cited text from the context should prevent the same response; if sufficient,
retaining the cited text alone should preserve the same response. This reward
can guide the inference-time best-of-N sampling strategy to improve citation
quality significantly, as well as be used in preference optimization to
directly fine-tune the models for generating better citations. The
effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3
points on the LongBench-Cite benchmark across five long-form question answering
tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Implementation available at https://github.com/voidism/SelfCite</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoT-Valve: Length-Compressible Chain-of-Thought Tuning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09601v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09601v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chain-of-Thought significantly enhances a model's reasoning capability, but
it also comes with a considerable increase in inference costs due to long
chains. With the observation that the reasoning path can be easily compressed
under easy tasks but struggle on hard tasks, we explore the feasibility of
elastically controlling the length of reasoning paths with only one model,
thereby reducing the inference overhead of reasoning models dynamically based
on task difficulty. We introduce a new tuning and inference strategy named
CoT-Valve, designed to allow models to generate reasoning chains of varying
lengths. To achieve this, we propose to identify a direction in the parameter
space that, when manipulated, can effectively control the length of generated
CoT. Moreover, we show that this property is valuable for compressing the
reasoning chain. We construct datasets with chains from long to short for the
same questions and explore two enhanced strategies for CoT-Valve: (1) a precise
length-compressible CoT tuning method, and (2) a progressive chain length
compression approach. Our experiments show that CoT-Valve successfully enables
controllability and compressibility of the chain and shows better performance
than the prompt-based control. We applied this method to QwQ-32B-Preview,
reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor
performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with
only one additional incorrect answer.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress. Code will be released at
  https://github.com/horseee/CoT-Valve</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do LLMs Recognize Your Preferences? Evaluating Personalized Preference
  Following in LLMs <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly used as chatbots, yet their
ability to personalize responses to user preferences remains limited. We
introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize
and adhere to user preferences in a long-context conversational setting.
PrefEval comprises 3,000 manually curated user preference and query pairs
spanning 20 topics. PrefEval contains user personalization or preference
information in both explicit and implicit forms, and evaluates LLM performance
using a generation and a classification task. With PrefEval, we evaluated the
aforementioned preference following capabilities of 10 open-source and
proprietary LLMs in multi-session conversations with varying context lengths up
to 100k tokens. We benchmark with various prompting, iterative feedback, and
retrieval-augmented generation methods. Our benchmarking effort reveals that
state-of-the-art LLMs face significant challenges in proactively following
users' preferences during conversations. In particular, in zero-shot settings,
preference following accuracy falls below 10% at merely 10 turns (~3k tokens)
across most evaluated models. Even with advanced prompting and retrieval
methods, preference following still deteriorates in long-context conversations.
Furthermore, we show that fine-tuning on PrefEval significantly improves
performance. We believe PrefEval serves as a valuable resource for measuring,
understanding, and enhancing LLMs' preference following abilities, paving the
way for personalized conversational agents. Our code and dataset are available
at https://prefeval.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025 as oral presentation. Code and data at:
  https://prefeval.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Logical forms complement probability in understanding language model
  (and human) performance 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09589v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09589v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yixuan Wang, Freda Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing interest in using large language models (LLMs) for
planning in natural language, understanding their behaviors becomes an
important research question. This work conducts a systematic investigation of
LLMs' ability to perform logical reasoning in natural language. We introduce a
controlled dataset of hypothetical and disjunctive syllogisms in propositional
and modal logic and use it as the testbed for understanding LLM performance.
Our results lead to novel insights in predicting LLM behaviors: in addition to
the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical
forms should be considered as orthogonal factors. In addition, we show
similarities and differences between the logical reasoning performances of
humans and LLMs by comparing LLM and human behavioral results.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing <span class="highlight-title">GPT</span> for Video Understanding: Zero-Shot Performance and <span class="highlight-title">Prompt</span>
  Engineering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09573v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09573v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we tackle industry challenges in video content classification
by exploring and optimizing GPT-based models for zero-shot classification
across seven critical categories of video quality. We contribute a novel
approach to improving GPT's performance through prompt optimization and policy
refinement, demonstrating that simplifying complex policies significantly
reduces false negatives. Additionally, we introduce a new
decomposition-aggregation-based prompt engineering technique, which outperforms
traditional single-prompt methods. These experiments, conducted on real
industry problems, show that thoughtful prompt design can substantially enhance
GPT's performance without additional finetuning, offering an effective and
scalable solution for improving video classification systems across various
domains in industry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MorphNLI: A Stepwise Approach to Natural Language Inference Using Text
  Morphing <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09567v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09567v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 11 figures, 8 tables. Accepted for NAACL 2025 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-shot generation of synthetic neurosurgical data with large language
  models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Austin A. Barr, Eddie Guo, Emre Sezgin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical data is fundamental to advance neurosurgical research, but access is
often constrained by data availability, small sample sizes, privacy
regulations, and resource-intensive preprocessing and de-identification
procedures. Synthetic data offers a potential solution to challenges associated
with accessing and using real-world data (RWD). This study aims to evaluate the
capability of zero-shot generation of synthetic neurosurgical data with a large
language model (LLM), GPT-4o, by benchmarking with the conditional tabular
generative adversarial network (CTGAN). Synthetic datasets were compared to
real-world neurosurgical data to assess fidelity (means, proportions,
distributions, and bivariate correlations), utility (ML classifier performance
on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated
datasets matched or exceeded CTGAN performance, despite no fine-tuning or
access to RWD for pre-training. Datasets demonstrated high univariate and
bivariate fidelity to RWD without directly exposing any real patient records,
even at amplified sample size. Training an ML classifier on GPT-4o-generated
data and testing on RWD for a binary prediction task showed an F1 score (0.706)
with comparable performance to training on the CTGAN data (0.705) for
predicting postoperative functional status deterioration. GPT-4o demonstrated a
promising ability to generate high-fidelity synthetic neurosurgical data. These
findings also indicate that data synthesized with GPT-4o can effectively
augment clinical data with small sample sizes, and train ML models for
prediction of neurosurgical outcomes. Further investigation is necessary to
improve the preservation of distributional characteristics and boost classifier
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 4 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language
  Models for Vision-Driven Embodied Agents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09560v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09560v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Leveraging Multi-modal Large Language Models (MLLMs) to create embodied
agents offers a promising avenue for tackling real-world tasks. While
language-centric embodied agents have garnered substantial attention,
MLLM-based embodied agents remain underexplored due to the lack of
comprehensive evaluation frameworks. To bridge this gap, we introduce
EmbodiedBench, an extensive benchmark designed to evaluate vision-driven
embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing
tasks across four environments, ranging from high-level semantic tasks (e.g.,
household) to low-level tasks involving atomic actions (e.g., navigation and
manipulation); and (2) six meticulously curated subsets evaluating essential
agent capabilities like commonsense reasoning, complex instruction
understanding, spatial awareness, visual perception, and long-term planning.
Through extensive experiments, we evaluated 13 leading proprietary and
open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel
at high-level tasks but struggle with low-level manipulation, with the best
model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a
multifaceted standardized evaluation platform that not only highlights existing
challenges but also offers valuable insights to advance MLLM-based embodied
agents. Our code is available at https://embodiedbench.github.io.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>51 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Gap! Choice Independence in Using Multilingual LLMs for
  Persuasive Co-Writing Tasks in Different Languages 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09532v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09532v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shreyan Biswas, Alexander Erlei, Ujwal Gadiraju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in generative AI have precipitated a proliferation of novel
writing assistants. These systems typically rely on multilingual large language
models (LLMs), providing globalized workers the ability to revise or create
diverse forms of content in different languages. However, there is substantial
evidence indicating that the performance of multilingual LLMs varies between
languages. Users who employ writing assistance for multiple languages are
therefore susceptible to disparate output quality. Importantly, recent research
has shown that people tend to generalize algorithmic errors across independent
tasks, violating the behavioral axiom of choice independence. In this paper, we
analyze whether user utilization of novel writing assistants in a charity
advertisement writing task is affected by the AI's performance in a second
language. Furthermore, we quantify the extent to which these patterns translate
into the persuasiveness of generated charity advertisements, as well as the
role of peoples' beliefs about LLM utilization in their donation choices. Our
results provide evidence that writers who engage with an LLM-based writing
assistant violate choice independence, as prior exposure to a Spanish LLM
reduces subsequent utilization of an English LLM. While these patterns do not
affect the aggregate persuasiveness of the generated advertisements, people's
beliefs about the source of an advertisement (human versus AI) do. In
particular, Spanish-speaking female participants who believed that they read an
AI-generated advertisement strongly adjusted their donation behavior downwards.
Furthermore, people are generally not able to adequately differentiate between
human-generated and LLM-generated ads. Our work has important implications for
the design, development, integration, and adoption of multilingual LLMs as
assistive agents -- particularly in writing tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improve LLM-based Automatic Essay Scoring with Linguistic Features <span class="chip">AAAI</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09497v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09497v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaoyi Joey Hou, Alejandro Ciuba, Xiang Lorraine Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic Essay Scoring (AES) assigns scores to student essays, reducing the
grading workload for instructors. Developing a scoring system capable of
handling essays across diverse prompts is challenging due to the flexibility
and diverse nature of the writing task. Existing methods typically fall into
two categories: supervised feature-based approaches and large language model
(LLM)-based methods. Supervised feature-based approaches often achieve higher
performance but require resource-intensive training. In contrast, LLM-based
methods are computationally efficient during inference but tend to suffer from
lower performance. This paper combines these approaches by incorporating
linguistic features into LLM-based scoring. Experimental results show that this
hybrid method outperforms baseline models for both in-domain and out-of-domain
writing prompts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To be published in the workshop Innovation and Responsibility in
  AI-Supported Education (iRaise) at the 2025 Conference on Artificial
  Intelligence (AAAI)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Objective quantification of mood states using large language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09487v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09487v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakub Onysk, Quentin Huys
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emotional states influence human behaviour and cognition, leading to diverse
thought trajectories. Similarly, Large Language Models (LLMs) showcase an
excellent level of response consistency across wide-ranging contexts (prompts).
We leverage these parallels to establish a framework for quantifying mental
states. Our approach utilises self-report questionnaires that reliably assess
these states due to their inherent sensitivity to patterns of co-occurring
responses. Specifically, we recruited a large sample of participants (N=422) to
investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set
of depressive mood states measured with participants' open-ended responses to a
depression questionnaire. We show LLM responses to held-out multiple-choice
questions, given participants' open-ended answers, correlate strongly (r:
0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation
from mood representations. We explore a link between these representations and
factor analysis. Using ridge regression, we find depression-related subspaces
within LLM hidden states. We show these subspaces to be predictive of
participants' "Depression" and "Somatic & Emotional Distress" factor scores, as
well as suicidality severity. Overall, LLMs can provide quantitative measures
of mental states. The reliability of these hinges upon how informative the
questions we ask participants are. Used correctly, this approach could
supplement mental state assessment in a variety of settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main text - 9 pages, 5 figures;</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Multilingual Mind : A <span class="highlight-title">Survey</span> of Multilingual Reasoning in Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09457v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09457v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Akash Ghosh, Debayan Datta, Sriparna Saha, Chirag Agarwal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While reasoning and multilingual capabilities in Language Models (LMs) have
achieved remarkable progress in recent years, their integration into a unified
paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning
requires language models to handle logical reasoning across languages while
addressing misalignment, biases, and challenges in low-resource settings. This
survey provides the first in-depth review of multilingual reasoning in LMs. In
this survey, we provide a systematic overview of existing methods that leverage
LMs for multilingual reasoning, specifically outlining the challenges,
motivations, and foundational aspects of applying language models to reason
across diverse languages. We provide an overview of the standard data resources
used for training multilingual reasoning in LMs and the evaluation benchmarks
employed to assess their multilingual capabilities. Next, we analyze various
state-of-the-art methods and their performance on these benchmarks. Finally, we
explore future research opportunities to improve multilingual reasoning in LMs,
focusing on enhancing their ability to handle diverse languages and complex
reasoning tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Pixel-Level Reasoning Segmentation via Multi-turn Conversations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09447v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09447v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dexian Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing visual perception systems focus on region-level segmentation in
single-turn dialogues, relying on complex and explicit query instructions. Such
systems cannot reason at the pixel level and comprehend dynamic user intent
that changes over interaction. Our work tackles this issue by introducing a
novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on
multi-turn conversations, tracking evolving user intent via multi-turn
interactions for fine-grained segmentation. To establish a benchmark for this
novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on
Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k
multi-turn conversational scenarios with segmentation targets. Building on
PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning
Segmentation framework, integrates pixel-level segmentation with robust
multi-turn conversation understanding, generating pixel-grounded explanations
aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in
pixel-level reasoning segmentation. Experimental results on the PRIST dataset
demonstrate that our method outperforms current segmentation-specific baselines
in terms of segmentation and LLM-based reasoning metrics. The code and data are
available at: https://github.com/ccccai239/PixelRIST.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On multi-token prediction for efficient LLM inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somesh Mehra, Javier Alonso Garcia, Lukas Mauch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We systematically investigate multi-token prediction (MTP) capabilities
within LLMs pre-trained for next-token prediction (NTP). We first show that
such models inherently possess MTP capabilities via numerical marginalization
over intermediate token probabilities, though performance is data-dependent and
improves with model scale. Furthermore, we explore the challenges of
integrating MTP heads into frozen LLMs and find that their hidden layers are
strongly specialized for NTP, making adaptation non-trivial. Finally, we show
that while joint training of MTP heads with the backbone improves performance,
it cannot fully overcome this barrier, prompting further research in this
direction. Our findings provide a deeper understanding of MTP applied to
pretrained LLMs, informing strategies for accelerating inference through
parallel token prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use
  a Different Evaluation Process than Human? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09416v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09416v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Takumi Goto, Yusuke Sakai, Taro Watanabe
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  One of the goals of automatic evaluation metrics in grammatical error
correction (GEC) is to rank GEC systems such that it matches human preferences.
However, current automatic evaluations are based on procedures that diverge
from human evaluation. Specifically, human evaluation derives rankings by
aggregating sentence-level relative evaluation results, e.g., pairwise
comparisons, using a rating algorithm, whereas automatic evaluation averages
sentence-level absolute scores to obtain corpus-level scores, which are then
sorted to determine rankings. In this study, we propose an aggregation method
for existing automatic evaluation metrics which aligns with human evaluation
methods to bridge this gap. We conducted experiments using various metrics,
including edit-based metrics, $n$-gram based metrics, and sentence-level
metrics, and show that resolving the gap improves results for the most of
metrics on the SEEDA benchmark. We also found that even BERT-based metrics
sometimes outperform the metrics of GPT-4. We publish our unified
implementation of the metrics and meta-evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages, 2 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SQuARE: Sequential Question Answering Reasoning Engine for Enhanced
  Chain-of-Thought in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving field of Natural Language Processing, Large Language
Models (LLMs) are tasked with increasingly complex reasoning challenges.
Traditional methods like chain-of-thought prompting have shown promise but
often fall short in fully leveraging a model's reasoning capabilities. This
paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a
novel prompting technique designed to improve reasoning through a
self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts
models to generate and resolve multiple auxiliary questions before tackling the
main query, promoting a more thorough exploration of various aspects of a
topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models
across multiple question-answering datasets, demonstrate that SQuARE
significantly surpasses traditional CoT prompts and existing
rephrase-and-respond methods. By systematically decomposing queries, SQuARE
advances LLM capabilities in reasoning tasks. The code is publicly available at
https://github.com/IntelLabs/RAG-FiT/tree/square.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Truth Knows No Language: Evaluating Truthfulness Beyond English 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09387v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09387v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, Rodrigo Agerri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a professionally translated extension of the TruthfulQA
benchmark designed to evaluate truthfulness in Basque, Catalan, Galician, and
Spanish. Truthfulness evaluations of large language models (LLMs) have
primarily been conducted in English. However, the ability of LLMs to maintain
truthfulness across languages remains under-explored. Our study evaluates 12
state-of-the-art open LLMs, comparing base and instruction-tuned models using
human evaluation, multiple-choice metrics, and LLM-as-a-Judge scoring. Our
findings reveal that, while LLMs perform best in English and worst in Basque
(the lowest-resourced language), overall truthfulness discrepancies across
languages are smaller than anticipated. Furthermore, we show that
LLM-as-a-Judge correlates more closely with human judgments than
multiple-choice metrics, and that informativeness plays a critical role in
truthfulness assessment. Our results also indicate that machine translation
provides a viable approach for extending truthfulness benchmarks to additional
languages, offering a scalable alternative to professional translation.
Finally, we observe that universal knowledge questions are better handled
across languages than context- and time-dependent ones, highlighting the need
for truthfulness evaluations that account for cultural and temporal
variability. Dataset and code are publicly available under open licenses.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 5 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Language Agents as Digital Representatives in Collective Decision-Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Jarrett, Miruna Pîslar, Michiel A. Bakker, Michael Henry Tessler, Raphael Köster, Jan Balaguer, Romuald Elie, Christopher Summerfield, Andrea Tacchetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consider the process of collective decision-making, in which a group of
individuals interactively select a preferred outcome from among a universe of
alternatives. In this context, "representation" is the activity of making an
individual's preferences present in the process via participation by a proxy
agent -- i.e. their "representative". To this end, learned models of human
behavior have the potential to fill this role, with practical implications for
multi-agent scenario studies and mechanism design. In this work, we investigate
the possibility of training \textit{language agents} to behave in the capacity
of representatives of human agents, appropriately expressing the preferences of
those individuals whom they stand for. First, we formalize the setting of
\textit{collective decision-making} -- as the episodic process of interaction
between a group of agents and a decision mechanism. On this basis, we then
formalize the problem of \textit{digital representation} -- as the simulation
of an agent's behavior to yield equivalent outcomes from the mechanism.
Finally, we conduct an empirical case study in the setting of
\textit{consensus-finding} among diverse humans, and demonstrate the
feasibility of fine-tuning large language models to act as digital
representatives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond English: The Impact of <span class="highlight-title">Prompt</span> Translation Strategies across
  Languages and Tasks in Multilingual LLMs <span class="chip">NAACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09331v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09331v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite advances in the multilingual capabilities of Large Language Models
(LLMs) across diverse tasks, English remains the dominant language for LLM
research and development. So, when working with a different language, this has
led to the widespread practice of pre-translation, i.e., translating the task
prompt into English before inference. Selective pre-translation, a more
surgical approach, focuses on translating specific prompt components. However,
its current use is sporagic and lacks a systematic research foundation.
Consequently, the optimal pre-translation strategy for various multilingual
settings and tasks remains unclear. In this work, we aim to uncover the optimal
setup for pre-translation by systematically assessing its use. Specifically, we
view the prompt as a modular entity, composed of four functional parts:
instruction, context, examples, and output, either of which could be translated
or not. We evaluate pre-translation strategies across 35 languages covering
both low and high-resource languages, on various tasks including Question
Answering (QA), Natural Language Inference (NLI), Named Entity Recognition
(NER), and Abstractive Summarization. Our experiments show the impact of
factors as similarity to English, translation quality and the size of
pre-trained data, on the model performance with pre-translation. We suggest
practical guidelines for choosing optimal strategies in various multilingual
settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted for NAACL findings 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Judge-free LLM Open-ended Generation Benchmark Based on the
  Distributional Hypothesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09316v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09316v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kentaro Imajo, Masanori Hirano, Shuji Suzuki, Hiroaki Mikami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Evaluating the open-ended text generation of large language models (LLMs) is
challenging because of the lack of a clear ground truth and the high cost of
human or LLM-based assessments. We propose a novel benchmark that evaluates
LLMs using n-gram statistics and rules, without relying on human judgement or
LLM-as-a-judge approaches. Using 50 question and reference answer sets, we
introduce three new metrics based on n-grams and rules: Fluency, Truthfulness,
and Helpfulness. Our benchmark strongly correlates with GPT-4o-based
evaluations while requiring significantly fewer computational resources,
demonstrating its effectiveness as a scalable alternative for assessing LLMs'
open-ended generation capabilities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When the LM misunderstood the human chuckled: Analyzing garden path
  effects in humans and language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern Large Language Models (LLMs) have shown human-like abilities in many
language tasks, sparking interest in comparing LLMs' and humans' language
processing. In this paper, we conduct a detailed comparison of the two on a
sentence comprehension task using garden-path constructions, which are
notoriously challenging for humans. Based on psycholinguistic research, we
formulate hypotheses on why garden-path sentences are hard, and test these
hypotheses on human participants and a large suite of LLMs using comprehension
questions. Our findings reveal that both LLMs and humans struggle with specific
syntactic complexities, with some models showing high correlation with human
comprehension. To complement our findings, we test LLM comprehension of
garden-path constructions with paraphrasing and text-to-image generation tasks,
and find that the results mirror the sentence comprehension question results,
further validating our findings on LLM understanding of these constructions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SparQLe: Speech Queries to Text Translation Through LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09284v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09284v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirbek Djanibekov, Hanan Aldarmaki
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing influence of Large Language Models (LLMs), there is
increasing interest in integrating speech representations with them to enable
more seamless multi-modal processing and speech understanding. This study
introduces a novel approach that leverages self-supervised speech
representations in combination with instruction-tuned LLMs for speech-to-text
translation. The proposed approach leverages a modality adapter to align
extracted speech features with instruction-tuned LLMs using English-language
data. Our experiments demonstrate that this method effectively preserves the
semantic content of the input speech and serves as an effective bridge between
self-supervised speech models and instruction-tuned LLMs, offering a promising
solution for various speech understanding applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Joint Entity-Relation Extraction Model Based on Span and Interactive
  Fusion Representation for Chinese Medical Texts with Complex Semantics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09247v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09247v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danni Feng, Runzhi Li, Jing Wang, Siyu Yan, Lihong Ma, Yunli Xing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Joint entity-relation extraction is a critical task in transforming
unstructured or semi-structured text into triplets, facilitating the
construction of large-scale knowledge graphs, and supporting various downstream
applications. Despite its importance, research on Chinese text, particularly
with complex semantics in specialized domains like medicine, remains limited.
To address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions
dataset designed to capture the intricacies of medical text. Leveraging the
strengths of attention mechanisms in capturing long-range dependencies, we
propose the SEA module, which enhances the extraction of complex contextual
semantic information, thereby improving entity recognition and relation
extraction. Additionally, to address the inefficiencies of existing methods in
facilitating information exchange between entity recognition and relation
extraction, we present an interactive fusion representation module. This module
employs Cross Attention for bidirectional information exchange between the
tasks and further refines feature extraction through BiLSTM. Experimental
results on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that
our model exhibits strong generalization capabilities. On the CH-DDI dataset,
our model achieves an F1-score of 96.73% for entity recognition and 78.43% for
relation extraction. On the CoNLL04 dataset, it attains an entity recognition
precision of 89.54% and a relation extraction accuracy of 71.64%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ You Do Not Fully Utilize <span class="highlight-title">Transformer</span>'s Representation Capacity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In contrast to RNNs, which compress previous tokens into a single hidden
state, Transformers can attend to all previous tokens directly. However,
standard Transformers only use representations from the immediately preceding
layer. In this paper, we show that this design choice causes representation
collapse and leads to suboptimal performance. To address this issue, we
introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that
preserves the model's overall memory footprint while expanding its
representational capacity by allowing access to hidden states from earlier
layers. Through extensive experiments across various architectures and
different lookup mechanisms, we demonstrate consistent performance improvements
on a wide range of tasks. Moreover, our analysis of the learned representation
dynamics and our exploration of depthwise circuits reveal how LIMe integrates
information across layers, pointing to promising directions for future
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Reliable Conversational Agents under ASP Control that Understand Natural
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09237v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09237v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yankai Zeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efforts have been made to make machines converse like humans in the past few
decades. The recent techniques of Large Language Models (LLMs) make it possible
to have human-like conversations with machines, but LLM's flaws of lacking
understanding and reliability are well documented. We believe that the best way
to eliminate this problem is to use LLMs only as parsers to translate text to
knowledge and vice versa and carry out the conversation by reasoning over this
knowledge using the answer set programming. I have been developing a framework
based on LLMs and ASP to realize reliable chatbots that "understand" human
conversation. This framework has been used to develop task-specific chatbots as
well as socialbots. My future research is focused on making these chatbots
scalable and trainable.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Answer Set Counting and its Applications 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09231v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09231v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohimenul Kabir
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We have focused on Answer Set Programming (ASP), more specifically, answer
set counting, exploring both exact and approximate methodologies. We developed
an exact ASP counter, sharpASP, which utilizes a compact encoding for
propositional formulas, significantly enhancing efficiency compared to existing
methods that often struggle with inefficient encodings. Our evaluations
indicate that sharpASP outperforms current ASP counters on several benchmarks.
In addition, we proposed an approximate ASP counter, named ApproxASP, a
hashing-based counter integrating Gauss-Jordan elimination within the ASP
solver, clingo. As a practical application, we employed ApproxASP for network
reliability estimation, demonstrating superior performance over both
traditional reliability estimators and #SAT-based methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mind the Gaps: Logical English, Prolog, and Multi-agent Systems for
  Autonomous Vehicles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09216v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09216v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Galileo Sartor, Adam Wyner, Giuseppe Contissa
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we present a modular system for representing and reasoning
with legal aspects of traffic rules for autonomous vehicles. We focus on a
subset of the United Kingdom's Highway Code (HC) related to junctions. As human
drivers and automated vehicles (AVs) will interact on the roads, especially in
urban environments, we claim that an accessible, unitary, high-level
computational model should exist and be applicable to both users. Autonomous
vehicles introduce a shift in liability that should not bring disadvantages or
increased burden on human drivers. We develop a system "in silico" of the
model. The proposed system is built of three main components: a natural
language interface, using Logical English, which encodes the rules; an internal
representation of the rules in Prolog; and an multi-agent-based simulation
environment, built in NetLogo. The three components interact: Logical English
is translated into and out of Prolog (along with some support code); Prolog and
NetLogo interface via predicates. Such a modular approach enables the different
components to carry different "burdens" in the overall system; it also allows
swapping of modules. Given NetLogo, we can visualize the effect of the modeled
rules as well as validate the system with a simple dynamic running scenario.
Designated agents monitor the behaviour of the vehicles for compliance and
record potential violations where they occur. The information on potential
violations is then utilized by Validators, to determine whether the violation
is punishable, differentiating between exceptions and cases.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neuro-Symbolic Contrastive Learning for Cross-domain Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09213v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09213v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models (PLMs) have made significant advances in natural
language inference (NLI) tasks, however their sensitivity to textual
perturbations and dependence on large datasets indicate an over-reliance on
shallow heuristics. In contrast, inductive logic programming (ILP) excels at
inferring logical relationships across diverse, sparse and limited datasets,
but its discrete nature requires the inputs to be precisely specified, which
limits their application. This paper proposes a bridge between the two
approaches: neuro-symbolic contrastive learning. This allows for smooth and
differentiable optimisation that improves logical accuracy across an otherwise
discrete, noisy, and sparse topological space of logical functions. We show
that abstract logical relationships can be effectively embedded within a
neuro-symbolic paradigm, by representing data as logic programs and sets of
logic rules. The embedding space captures highly varied textual information
with similar semantic logical relations, but can also separate similar textual
relations that have dissimilar logical relations. Experimental results
demonstrate that our approach significantly improves the inference capabilities
of the models in terms of generalisation and reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LP-LM: No Hallucinations in Question Answering with Logic Programming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09212v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09212v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Katherine Wu, Yanhong A. Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) are able to generate human-like responses to
user queries. However, LLMs exhibit inherent limitations, especially because
they hallucinate. This paper introduces LP-LM, a system that grounds answers to
questions in known facts contained in a knowledge base (KB), facilitated
through semantic parsing in Prolog, and always produces answers that are
reliable.
  LP-LM generates a most probable constituency parse tree along with a
corresponding Prolog term for an input question via Prolog definite clause
grammar (DCG) parsing. The term is then executed against a KB of natural
language sentences also represented as Prolog terms for question answering. By
leveraging DCG and tabling, LP-LM runs in linear time in the size of input
sentences for sufficiently many grammar rules. Performing experiments comparing
LP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate
on even simple questions, unlike LP-LM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Thinking beyond the anthropomorphic paradigm benefits LLM research 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09192v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09192v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lujain Ibrahim, Myra Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Anthropomorphism, or the attribution of human traits to technology, is an
automatic and unconscious response that occurs even in those with advanced
technical expertise. In this position paper, we analyze hundreds of thousands
of computer science research articles from the past decade and present
empirical evidence of the prevalence and growth of anthropomorphic terminology
in research on large language models (LLMs). This terminology reflects deeper
anthropomorphic conceptualizations which shape how we think about and conduct
LLM research. We argue these conceptualizations may be limiting, and that
challenging them opens up new pathways for understanding and improving LLMs
beyond human analogies. To illustrate this, we identify and analyze five core
anthropomorphic assumptions shaping prominent methodologies across the LLM
development lifecycle, from the assumption that models must use natural
language for reasoning tasks to the assumption that model capabilities should
be evaluated through human-centric benchmarks. For each assumption, we
demonstrate how non-anthropomorphic alternatives can open new directions for
research and development.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Matina: A Large-Scale 73B Token Persian Text Corpus 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09188v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09188v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sara Bourbour Hosseinbeigi, Fatemeh Taherinezhad, Heshaam Faili, Hamed Baghbani, Fatemeh Nadi, Mostafa Amiri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text corpora are essential for training models used in tasks like
summarization, translation, and large language models (LLMs). While various
efforts have been made to collect monolingual and multilingual datasets in many
languages, Persian has often been underrepresented due to limited resources for
data collection and preprocessing. Existing Persian datasets are typically
small and lack content diversity, consisting mainly of weblogs and news
articles. This shortage of high-quality, varied data has slowed the development
of NLP models and open-source LLMs for Persian. Since model performance depends
heavily on the quality of training data, we address this gap by introducing the
Matina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed
and deduplicated to ensure high data quality. We further assess its
effectiveness by training and evaluating transformer-based models on key NLP
tasks. Both the dataset and preprocessing codes are publicly available,
enabling researchers to build on and improve this resource for future Persian
NLP advancements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RefineCoder: Iterative Improving of Large Language Models via Adaptive
  Critique Refinement for Code Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09183v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09183v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Changzhi Zhou, Xinyu Zhang, Dandan Song, Xiancai Chen, Wanli Gu, Huipeng Ma, Yuhang Tian, Mengdi Zhang, Linmei Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code generation has attracted increasing attention with the rise of Large
Language Models (LLMs). Many studies have developed powerful code LLMs by
synthesizing code-related instruction data and applying supervised fine-tuning.
However, these methods are limited by teacher model distillation and ignore the
potential of iterative refinement by self-generated code. In this paper, we
propose Adaptive Critique Refinement (ACR), which enables the model to refine
itself by self-generated code and external critique, rather than directly
imitating the code responses of the teacher model. Concretely, ACR includes a
composite scoring system with LLM-as-a-Judge to evaluate the quality of code
responses and a selective critique strategy with LLM-as-a-Critic to critique
self-generated low-quality code responses. We develop the RefineCoder series by
iteratively applying ACR, achieving continuous performance improvement on
multiple code generation benchmarks. Compared to the baselines of the same
size, our proposed RefineCoder series can achieve comparable or even superior
performance using less data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>work in process</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FLAME: Flexible LLM-Assisted Moderation Engine 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09175v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09175v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ivan Bakulin, Ilia Kopanichuk, Iaroslav Bespalov, Nikita Radchenko, Vladimir Shaposhnikov, Dmitry Dylov, Ivan Oseledets
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of Large Language Models (LLMs) has introduced
significant challenges in moderating user-model interactions. While LLMs
demonstrate remarkable capabilities, they remain vulnerable to adversarial
attacks, particularly ``jailbreaking'' techniques that bypass content safety
measures. Current content moderation systems, which primarily rely on input
prompt filtering, have proven insufficient, with techniques like Best-of-N
(BoN) jailbreaking achieving success rates of 80% or more against popular LLMs.
In this paper, we introduce Flexible LLM-Assisted Moderation Engine (FLAME): a
new approach that shifts the focus from input filtering to output moderation.
Unlike traditional circuit-breaking methods that analyze user queries, FLAME
evaluates model responses, offering several key advantages: (1) computational
efficiency in both training and inference, (2) enhanced resistance to BoN
jailbreaking attacks, and (3) flexibility in defining and updating safety
criteria through customizable topic filtering. Our experiments demonstrate that
FLAME significantly outperforms current moderation systems. For example, FLAME
reduces attack success rate in GPT-4o-mini and DeepSeek-v3 by a factor of ~9,
while maintaining low computational overhead. We provide comprehensive
evaluation on various LLMs and analyze the engine's efficiency against the
state-of-the-art jailbreaking. This work contributes to the development of more
robust and adaptable content moderation systems for LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Musical Heritage Historical Entity Linking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09168v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09168v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arianna Graciotti, Nicolas Lazzari, Valentina Presutti, Rocco Tripodi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Linking named entities occurring in text to their corresponding entity in a
Knowledge Base (KB) is challenging, especially when dealing with historical
texts. In this work, we introduce Musical Heritage named Entities Recognition,
Classification and Linking (MHERCL), a novel benchmark consisting of manually
annotated sentences extrapolated from historical periodicals of the music
domain. MHERCL contains named entities under-represented or absent in the most
famous KBs. We experiment with several State-of-the-Art models on the Entity
Linking (EL) task and show that MHERCL is a challenging dataset for all of
them. We propose a novel unsupervised EL model and a method to extend
supervised entity linkers by using Knowledge Graphs (KGs) to tackle the main
difficulties posed by historical documents. Our experiments reveal that relying
on unsupervised techniques and improving models with logical constraints based
on KGs and heuristics to predict NIL entities (entities not represented in the
KB of reference) results in better EL performance on historical documents.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear in Artificial Intelligence Review Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving TCM Question Answering through Tree-Organized Self-Reflective
  Retrieval with LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09156v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09156v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chang Liu, Ying Chang, Jianmin Li, Yiqian Qu, Yu Li, Lingyong Cao, Shuyuan Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Objectives: Large language models (LLMs) can harness medical knowledge for
intelligent question answering (Q&A), promising support for auxiliary diagnosis
and medical talent cultivation. However, there is a deficiency of highly
efficient retrieval-augmented generation (RAG) frameworks within the domain of
Traditional Chinese Medicine (TCM). Our purpose is to observe the effect of the
Tree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A
tasks.
  Materials and Methods: We introduce the novel approach of knowledge
organization, constructing a tree structure knowledge base with hierarchy. At
inference time, our self-reflection framework retrieves from this knowledge
base, integrating information across chapters. Questions from the TCM Medical
Licensing Examination (MLE) and the college Classics Course Exam (CCE) were
randomly selected as benchmark datasets.
  Results: By coupling with GPT-4, the framework can improve the best
performance on the TCM MLE benchmark by 19.85% in absolute accuracy, and
improve recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,
the framework improves a total of 18.52 points across dimensions of safety,
consistency, explainability, compliance, and coherence.
  Conclusion: The TOSRR framework can effectively improve LLM's capability in
Q&A tasks of TCM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Dialect-Aware Framework for the Classification of Arabic
  Dialects and Emotions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasser A Alsadhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Arabic is one of the oldest languages still in use today. As a result,
several Arabic-speaking regions have developed dialects that are unique to
them. Dialect and emotion recognition have various uses in Arabic text
analysis, such as determining an online customer's origin based on their
comments. Furthermore, intelligent chatbots that are aware of a user's emotions
can respond appropriately to the user. Current research in emotion detection in
the Arabic language lacks awareness of how emotions are exhibited in different
dialects, which motivates the work found in this study. This research addresses
the problems of dialect and emotion classification in Arabic. Specifically,
this is achieved by building a novel framework that can identify and predict
Arabic dialects and emotions from a given text. The framework consists of three
modules: A text-preprocessing module, a classification module, and a clustering
module with the novel capability of building new dialect-aware emotion
lexicons. The proposed framework generated a new emotional lexicon for
different dialects. It achieved an accuracy of 88.9% in classifying Arabic
dialects, which outperforms the state-of-the-art results by 6.45 percentage
points. Furthermore, the framework achieved 89.1-79% accuracy in detecting
emotions in the Egyptian and Gulf dialects, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The influence of visual and linguistic cues on ignorance inference in
  Vision-Language Models (VLMs) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09120v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09120v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ye-eun Cho, Yunho Maeng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study explored how Vision-Language Models (VLMs) process ignorance
implicatures with visual and linguistic cues. Particularly, we focused on the
effects of contexts (precise and approximate contexts) and modifier types (bare
numerals, superlative, and comparative modifiers), which were considered
pragmatic and semantic factors respectively. Methodologically, we conducted a
truth-value judgment task in visually grounded settings using GPT-4o and Gemini
1.5 Pro. The results indicate that while both models exhibited sensitivity to
linguistic cues (modifier), they failed to process ignorance implicatures with
visual cues (context) as humans do. Specifically, the influence of context was
weaker and inconsistent across models, indicating challenges in pragmatic
reasoning for VLMs. On the other hand, superlative modifiers were more strongly
associated with ignorance implicatures as compared to comparative modifiers,
supporting the semantic view. These findings highlight the need for further
advancements in VLMs to process language-vision information in a
context-dependent way to achieve human-like pragmatic inference.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 3 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Logical Reasoning in Large Language Models: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09100v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09100v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the emergence of advanced reasoning models like OpenAI o3 and
DeepSeek-R1, large language models (LLMs) have demonstrated remarkable
reasoning capabilities. However, their ability to perform rigorous logical
reasoning remains an open question. This survey synthesizes recent advancements
in logical reasoning within LLMs, a critical area of AI research. It outlines
the scope of logical reasoning in LLMs, its theoretical foundations, and the
benchmarks used to evaluate reasoning proficiency. We analyze existing
capabilities across different reasoning paradigms - deductive, inductive,
abductive, and analogical - and assess strategies to enhance reasoning
performance, including data-centric tuning, reinforcement learning, decoding
strategies, and neuro-symbolic approaches. The review concludes with future
directions, emphasizing the need for further exploration to strengthen logical
reasoning in AI systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hybrid <span class="highlight-title">Transformer</span> Model for Fake News Detection: Leveraging Bayesian
  Optimization and Bidirectional Recurrent Unit 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09097v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09097v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianyi Huang, Zeqiu Xu, Peiyang Yu, Jingyuan Yi, Xiaochuan Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose an optimized Transformer model that integrates
Bayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and
apply it to fake news classification for the first time. First, we employ the
TF-IDF method to extract features from news texts and transform them into
numeric representations to facilitate subsequent machine learning tasks. Two
sets of experiments are then conducted for fake news detection and
classification: one using a Transformer model optimized only with BiGRU, and
the other incorporating Bayesian algorithms into the BiGRU-based Transformer.
Experimental results show that the BiGRU-optimized Transformer achieves 100%
accuracy on the training set and 99.67% on the test set, while the addition of
the Bayesian algorithm maintains 100% accuracy on the training set and slightly
improves test-set accuracy to 99.73%. This indicates that the Bayesian
algorithm boosts model accuracy by 0.06%, further enhancing the detection
capability for fake news. Moreover, the proposed algorithm converges rapidly at
around the 10th training epoch with accuracy nearing 100%, demonstrating both
its effectiveness and its fast classification ability. Overall, the optimized
Transformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits
excellent continuous learning and detection performance, offering a robust
technical means to combat the spread of fake news in the current era of
information overload.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 7 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Hybrid Model for Few-Shot Text Classification Using Transfer and
  Meta-Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09086v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09086v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jia Gao, Shuangquan Lyu, Guiran Liu, Binrong Zhu, Hongye Zheng, Xiaoxuan Liao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the continuous development of natural language processing (NLP)
technology, text classification tasks have been widely used in multiple
application fields. However, obtaining labeled data is often expensive and
difficult, especially in few-shot learning scenarios. To solve this problem,
this paper proposes a few-shot text classification model based on transfer
learning and meta-learning. The model uses the knowledge of the pre-trained
model for transfer and optimizes the model's rapid adaptability in few-sample
tasks through a meta-learning mechanism. Through a series of comparative
experiments and ablation experiments, we verified the effectiveness of the
proposed method. The experimental results show that under the conditions of few
samples and medium samples, the model based on transfer learning and
meta-learning significantly outperforms traditional machine learning and deep
learning methods. In addition, ablation experiments further analyzed the
contribution of each component to the model performance and confirmed the key
role of transfer learning and meta-learning in improving model accuracy.
Finally, this paper discusses future research directions and looks forward to
the potential of this method in practical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Show Me the Work: Fact-Checkers' Requirements for Explainable Automated
  Fact-Checking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09083v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09083v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Greta Warren, Irina Shklovski, Isabelle Augenstein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The pervasiveness of large language models and generative AI in online media
has amplified the need for effective automated fact-checking to assist
fact-checkers in tackling the increasing volume and sophistication of
misinformation. The complex nature of fact-checking demands that automated
fact-checking systems provide explanations that enable fact-checkers to
scrutinise their outputs. However, it is unclear how these explanations should
align with the decision-making and reasoning processes of fact-checkers to be
effectively integrated into their workflows. Through semi-structured interviews
with fact-checking professionals, we bridge this gap by: (i) providing an
account of how fact-checkers assess evidence, make decisions, and explain their
processes; (ii) examining how fact-checkers use automated tools in practice;
and (iii) identifying fact-checker explanation requirements for automated
fact-checking tools. The findings show unmet explanation needs and identify
important criteria for replicable fact-checking explanations that trace the
model's reasoning path, reference specific evidence, and highlight uncertainty
and information gaps.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Conditionally accepted to CHI'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CoSER: Coordinating LLM-Based Persona Simulation of Established Roles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09082v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09082v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, Yanghua Xiao, Shuchang Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Role-playing language agents (RPLAs) have emerged as promising applications
of large language models (LLMs). However, simulating established characters
presents a challenging task for RPLAs, due to the lack of authentic character
datasets and nuanced evaluation methods using such data. In this paper, we
present CoSER, a collection of a high-quality dataset, open models, and an
evaluation protocol towards effective RPLAs of established characters. The
CoSER dataset covers 17,966 characters from 771 renowned books. It provides
authentic dialogues with real-world intricacies, as well as diverse data types
such as conversation setups, character experiences and internal thoughts.
Drawing from acting methodology, we introduce given-circumstance acting for
training and evaluating role-playing LLMs, where LLMs sequentially portray
multiple characters in book scenes. Using our dataset, we develop CoSER 8B and
CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models.
Extensive experiments demonstrate the value of the CoSER dataset for RPLA
training, evaluation and retrieval. Moreover, CoSER 70B exhibits
state-of-the-art performance surpassing or matching GPT-4o on our evaluation
and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on
the InCharacter and LifeChoice benchmarks respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing RAG with Active Learning on Conversation Records: Reject
  Incapables and Answer Capables 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09073v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09073v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuzhao Geng, Haozhao Wang, Jun Wang, Wei Liu, Ruixuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is a key technique for leveraging
external knowledge and reducing hallucinations in large language models (LLMs).
However, RAG still struggles to fully prevent hallucinated responses. To
address this, it is essential to identify samples prone to hallucination or
guide LLMs toward correct responses, which experts then annotate to develop
high-quality datasets for refining LLMs. However, the growing scarcity of such
datasets makes their creation challenging. This paper proposes using the vast
amount of conversations from widespread LLM usage to build these datasets,
training LLMs to avoid hallucination-prone questions while accurately
responding to manageable ones. Given the impracticality of expert-annotating
all conversation records, the paper introduces AL4RAG, which uses active
learning to select the most suitable conversation samples for annotation,
optimizing performance within an annotation budget. Additionally, recognizing
that traditional active learning methods are not fully compatible with RAG due
to unsuitable distance metrics, we develop a novel sample distance measurement
for RAG active learning. Extensive experiments show that our method
consistently outperforms baselines across multiple metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in
  One Day via Model Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09056v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09056v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates data selection and model merging methodologies aimed
at incorporating advanced reasoning capabilities such as those of DeepSeek R1
into language-specific large language models (LLMs), with a particular focus on
the Thai LLM. Our goal is to enhance the reasoning capabilities of
language-specific LLMs while maintaining their target language abilities.
DeepSeek R1 excels in reasoning but primarily benefits high-resource languages
such as English and Chinese. However, low-resource languages remain underserved
due to the dominance of English-centric training data and model optimizations,
which limit performance in these languages. This limitation results in
unreliable code-switching and diminished effectiveness on tasks in low-resource
languages. Meanwhile, local and regional LLM initiatives have attempted to
bridge this gap by developing language-specific LLMs that focus on improving
local linguistic fidelity. We demonstrate that, with only publicly available
datasets and a computational budget of $120, it is possible to enhance the
reasoning capabilities of language-specific LLMs to match the level of DeepSeek
R1, without compromising their performance on target language tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Typhoon T1: An Open Thai Reasoning Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09042v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09042v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai, Kunat Pipatanakul
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces Typhoon T1, an open effort to develop an open Thai
reasoning model. A reasoning model is a relatively new type of generative model
built on top of large language models (LLMs). A reasoning model generates a
long chain of thought before arriving at a final answer, an approach found to
improve performance on complex tasks. However, details on developing such a
model are limited, especially for reasoning models that can generate traces in
a low-resource language. Typhoon T1 presents an open effort that dives into the
details of developing a reasoning model in a more cost-effective way by
leveraging supervised fine-tuning using open datasets, instead of reinforcement
learning. This paper shares the details about synthetic data generation and
training, as well as our dataset and model weights. Additionally, we provide
insights gained from developing a reasoning model that generalizes across
domains and is capable of generating reasoning traces in a low-resource
language, using Thai as an example. We hope this open effort provides a
foundation for further research in this field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>25 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diversity Enhances an LLM's Performance in RAG and Long-context Task 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09017v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09017v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhchao Wang, Bin Bi, Yanqi Luo, Sitaram Asur, Claire Na Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in large language models (LLMs) have highlighted the
challenge of context window limitations, primarily due to the quadratic time
complexity of the self-attention mechanism (\(O(N^2)\), where \(N\) denotes the
context window length). This constraint impacts tasks such as
retrieval-augmented generation (RAG) in question answering (Q\&A) and long
context summarization. A common approach involves selecting content with the
highest similarity to the query; however, this often leads to redundancy and
the exclusion of diverse yet relevant information. Building on principles from
Maximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we
integrate diversity into the content selection process. Our findings reveal
that incorporating diversity substantially increases the recall of selecting
relevant sentences or chunks before LLM-based Q\&A and summarization. These
results highlight the importance of maintaining diversity in future LLM
applications to further improve summarization and Q\&A outcomes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hope vs. Hate: Understanding User Interactions with LGBTQ+ News Content
  in Mainstream US News Media through the Lens of Hope Speech 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09004v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09004v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Pofcher, Christopher M. Homan, Randall Sell, Ashiqur R. KhudaBukhsh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper makes three contributions. First, via a substantial corpus of
1,419,047 comments posted on 3,161 YouTube news videos of major US cable news
outlets, we analyze how users engage with LGBTQ+ news content. Our analyses
focus both on positive and negative content. In particular, we construct a
fine-grained hope speech classifier that detects positive (hope speech),
negative, neutral, and irrelevant content. Second, in consultation with a
public health expert specializing on LGBTQ+ health, we conduct an annotation
study with a balanced and diverse political representation and release a
dataset of 3,750 instances with fine-grained labels and detailed annotator
demographic information. Finally, beyond providing a vital resource for the
LGBTQ+ community, our annotation study and subsequent in-the-wild assessments
reveal (1) strong association between rater political beliefs and how they rate
content relevant to a marginalized community; (2) models trained on individual
political beliefs exhibit considerable in-the-wild disagreement; and (3)
zero-shot large language models (LLMs) align more with liberal raters.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context
  Learning <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08972v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08972v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hyundong Cho, Karishma Sharma, Nicolaas Jedema, Leonardo F. R. Ribeiro, Alessandro Moschitti, Ravi Krishnan, Jonathan May
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Language models are aligned to the collective voice of many, resulting in
generic outputs that do not align with specific users' styles. In this work, we
present Trial-Error-Explain In-Context Learning (TICL), a tuning-free method
that personalizes language models for text generation tasks with fewer than 10
examples per user. TICL iteratively expands an in-context learning prompt via a
trial-error-explain process, adding model-generated negative samples and
explanations that provide fine-grained guidance towards a specific user's
style. TICL achieves favorable win rates on pairwise comparisons with
LLM-as-a-judge up to 91.5% against the previous state-of-the-art and
outperforms competitive tuning-free baselines for personalized alignment tasks
of writing emails, essays and news articles. Both lexical and qualitative
analyses show that the negative samples and explanations enable language models
to learn stylistic context more effectively and overcome the bias towards
structural and formal phrases observed in their zero-shot outputs. By
front-loading inference compute to create a user-specific in-context learning
prompt that does not require extra generation steps at test time, TICL presents
a novel yet simple approach for personalized alignment.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 Findings</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs
  for Clinical Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08954v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08954v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leon Nissen, Philipp Zagar, Vishnu Ravi, Aydin Zahedivash, Lara Marie Reimer, Stephan Jonas, Oliver Aalami, Paul Schmiedmayer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The deployment of Large Language Models (LLM) on mobile devices offers
significant potential for medical applications, enhancing privacy, security,
and cost-efficiency by eliminating reliance on cloud-based services and keeping
sensitive health data local. However, the performance and accuracy of on-device
LLMs in real-world medical contexts remain underexplored. In this study, we
benchmark publicly available on-device LLMs using the AMEGA dataset, evaluating
accuracy, computational efficiency, and thermal limitation across various
mobile devices. Our results indicate that compact general-purpose models like
Phi-3 Mini achieve a strong balance between speed and accuracy, while medically
fine-tuned models such as Med42 and Aloe attain the highest accuracy. Notably,
deploying LLMs on older devices remains feasible, with memory constraints
posing a greater challenge than raw processing power. Our study underscores the
potential of on-device LLMs for healthcare while emphasizing the need for more
efficient inference and models tailored to real-world clinical reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Structured Convergence in Large Language Model Representations via
  Hierarchical Latent Space Folding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08947v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08947v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fenella Harcourt, Naderdel Piero, Gilbert Sutherland, Daphne Holloway, Harriet Bracknell, Julian Ormsby
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Token representations in high-dimensional latent spaces often exhibit
redundancy, limiting computational efficiency and reducing structural coherence
across model layers. Hierarchical latent space folding introduces a structured
transformation mechanism that enforces a multi-scale organization within
learned embeddings, refining representational compactness while preserving
essential contextual distinctions. The proposed approach incorporates dynamic
folding operations that iteratively adjust token embeddings through structured
transformations, influencing both short-range and long-range dependencies in
sequential processing tasks. Empirical evaluation demonstrates a reduction in
representational variance across layers, contributing to more stable perplexity
distributions and enhancing predictive confidence in text generation. The
structured redistribution of attention head utilization leads to more efficient
allocation of computational resources, particularly in deeper layers, where
hierarchical refinements improve contextual abstraction. Comparative analysis
of activation sparsity patterns suggests that hierarchical adjustments
selectively reinforce critical pathways while reducing computational overhead
in non-essential regions of the model. Statistical assessments of token
reordering frequencies reveal that hierarchical modifications introduce subtle
shifts in sequential dependencies, improving contextual alignment while
maintaining syntactic correctness. Computational trade-offs associated with
hierarchical folding introduce marginal increases in training time per epoch,
yet empirical findings indicate that inference efficiency benefits from the
structured representation adjustments. The results highlight the impact of
hierarchical latent space folding on optimizing model performance through
improved representation structuring and computational efficiency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of
  Physical Concept Understanding <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08946v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08946v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mo Yu, Lemao Liu, Junjie Wu, Tsz Ting Chung, Shunchi Zhang, Jiangnan Li, Dit-Yan Yeung, Jie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In a systematic way, we investigate a widely asked question: Do LLMs really
understand what they say?, which relates to the more familiar term Stochastic
Parrot. To this end, we propose a summative assessment over a carefully
designed physical concept understanding task, PhysiCo. Our task alleviates the
memorization issue via the usage of grid-format inputs that abstractly describe
physical phenomena. The grids represents varying levels of understanding, from
the core phenomenon, application examples to analogies to other abstract
patterns in the grid world. A comprehensive study on our task demonstrates: (1)
state-of-the-art LLMs, including GPT-4o, o1 and Gemini 2.0 flash thinking, lag
behind humans by ~40%; (2) the stochastic parrot phenomenon is present in LLMs,
as they fail on our grid task but can describe and recognize the same concepts
well in natural language; (3) our task challenges the LLMs due to intrinsic
difficulties rather than the unfamiliar grid format, as in-context learning and
fine-tuning on same formatted data added little to their performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 Main Conference. First 5 authors contributed equally.
  Project page: https://physico-benchmark.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Beyond the Singular: The Essential Role of Multiple Generations in
  Effective Benchmark Evaluation and Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08943v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08943v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenbo Zhang, Hengrui Cai, Wenyu Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have demonstrated significant utilities in
real-world applications, exhibiting impressive capabilities in natural language
processing and understanding. Benchmark evaluations are crucial for assessing
the capabilities of LLMs as they can provide a comprehensive assessment of
their strengths and weaknesses. However, current evaluation methods often
overlook the inherent randomness of LLMs by employing deterministic generation
strategies or relying on a single random sample, resulting in unaccounted
sampling variance and unreliable benchmark score estimates. In this paper, we
propose a hierarchical statistical model that provides a more comprehensive
representation of the benchmarking process by incorporating both benchmark
characteristics and LLM randomness. We show that leveraging multiple
generations improves the accuracy of estimating the benchmark score and reduces
variance. We also introduce $\mathbb P\left(\text{correct}\right)$, a
prompt-level difficulty score based on correct ratios, providing fine-grained
insights into individual prompts. Additionally, we create a data map that
visualizes difficulty and semantic prompts, enabling error detection and
quality control in benchmark construction.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 1 table, 4 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Escaping Collapse: The Strength of Weak Data for Large Language Model
  Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08924v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08924v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kareem Amin, Sara Babakniya, Alex Bie, Weiwei Kong, Umar Syed, Sergei Vassilvitskii
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Synthetically-generated data plays an increasingly larger role in training
large language models. However, while synthetic data has been found to be
useful, studies have also shown that without proper curation it can cause LLM
performance to plateau, or even "collapse", after many training iterations. In
this paper, we formalize this question and develop a theoretical framework to
investigate how much curation is needed in order to ensure that LLM performance
continually improves. We find that the requirements are nearly minimal. We
describe a training procedure that converges to an optimal LLM even if almost
all of the non-synthetic training data is of poor quality. Our analysis is
inspired by boosting, a classic machine learning technique that leverages a
very weak learning algorithm to produce an arbitrarily good classifier. Our
training procedure subsumes many recently proposed methods for training LLMs on
synthetic data, and thus our analysis sheds light on why they are successful,
and also suggests opportunities for future improvement. We present experiments
that validate our theory, and show that dynamically focusing labeling resources
on the most challenging examples -- in much the same way that boosting focuses
the efforts of the weak learner -- leads to improved performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CopySpec: Accelerating LLMs with Speculative Copy-and-Paste Without
  Compromising Quality 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08923v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08923v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Razvan-Gabriel Dumitru, Minglai Yang, Vikas Yadav, Mihai Surdeanu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce CopySpec, an innovative technique designed to tackle the
inefficiencies LLMs face when generating responses that closely resemble
previous outputs. CopySpec identifies repeated sequences in the model's chat
history and speculates that the same tokens will follow, enabling seamless
copying without compromising output quality or requiring additional GPU memory.
To evaluate the effectiveness of our approach, we conducted experiments using
five LLMs and five datasets: MT-Bench, CNN/DM, GSM-8K, HumanEval, and our newly
created dataset, MT-Redundant. MT-Redundant, introduced in this paper,
transforms the second turn of MT-Bench into a request for variations of the
first turn's answer, simulating real-world scenarios where users request
modifications to prior responses. Our results demonstrate significant
speed-ups: up to 2.35x on CNN/DM, 3.08x on the second turn of select
MT-Redundant categories, and 2.66x on the third turn of GSM-8K's
self-correction tasks. Moreover, we show that CopySpec integrates seamlessly
with speculative decoding, yielding an average 49% additional speed-up over
speculative decoding for the second turn of MT-Redundant across all eight
categories. While LLMs, even with speculative decoding, suffer from slower
inference as context sizes grow, CopySpec leverages the expanded context to
accelerate inference, making it faster as the context size increases. Our code
and dataset are publicly available at https://github.com/RazvanDu/CopySpec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>33 pages, 18 figures, 19 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic
  Decision-Making Applied to Histopathology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08916v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08916v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fatemeh Ghezloo, Mehmet Saygin Seyfioglu, Rustin Soraki, Wisdom O. Ikezogwo, Beibin Li, Tejoram Vivekanandan, Joann G. Elmore, Ranjay Krishna, Linda Shapiro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diagnosing diseases through histopathology whole slide images (WSIs) is
fundamental in modern pathology but is challenged by the gigapixel scale and
complexity of WSIs. Trained histopathologists overcome this challenge by
navigating the WSI, looking for relevant patches, taking notes, and compiling
them to produce a final holistic diagnostic. Traditional AI approaches, such as
multiple instance learning and transformer-based models, fail short of such a
holistic, iterative, multi-scale diagnostic procedure, limiting their adoption
in the real-world. We introduce PathFinder, a multi-modal, multi-agent
framework that emulates the decision-making process of expert pathologists.
PathFinder integrates four AI agents, the Triage Agent, Navigation Agent,
Description Agent, and Diagnosis Agent, that collaboratively navigate WSIs,
gather evidence, and provide comprehensive diagnoses with natural language
explanations. The Triage Agent classifies the WSI as benign or risky; if risky,
the Navigation and Description Agents iteratively focus on significant regions,
generating importance maps and descriptive insights of sampled patches.
Finally, the Diagnosis Agent synthesizes the findings to determine the
patient's diagnostic classification. Our Experiments show that PathFinder
outperforms state-of-the-art methods in skin melanoma diagnosis by 8% while
offering inherent explainability through natural language descriptions of
diagnostically relevant patches. Qualitative analysis by pathologists shows
that the Description Agent's outputs are of high quality and comparable to
GPT-4o. PathFinder is also the first AI-based system to surpass the average
performance of pathologists in this challenging melanoma classification task by
9%, setting a new record for efficient, accurate, and interpretable AI-assisted
diagnostics in pathology. Data, code and models available at
https://pathfinder-dx.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on
  a Single GPU 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08910v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08910v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Heejun Lee, Geon Park, Jaduk Suh, Sung Ju Hwang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In modern large language models (LLMs), handling very long context lengths
presents significant challenges as it causes slower inference speeds and
increased memory costs. Additionally, most existing pre-trained LLMs fail to
generalize beyond their original training sequence lengths. To enable efficient
and practical long-context utilization, we introduce InfiniteHiP, a novel, and
practical LLM inference framework that accelerates processing by dynamically
eliminating irrelevant context tokens through a modular hierarchical token
pruning algorithm. Our method also allows generalization to longer sequences by
selectively applying various RoPE adjustment methods according to the internal
attention patterns within LLMs. Furthermore, we offload the key-value cache to
host memory during inference, significantly reducing GPU memory pressure. As a
result, InfiniteHiP enables the processing of up to 3 million tokens on a
single L40s 48GB GPU -- 3x larger -- without any permanent loss of context
information. Our framework achieves an 18.95x speedup in attention decoding for
a 1 million token context without requiring additional training. We implement
our method in the SGLang framework and demonstrate its effectiveness and
practicality through extensive evaluations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Automated Fact-Checking of Real-World Claims: Exploring Task
  Formulation and Assessment with LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08909v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08909v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Premtim Sahitaj, Iffat Maab, Junichi Yamagishi, Jawan Kolanowski, Sebastian Möller, Vera Schmitt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fact-checking is necessary to address the increasing volume of
misinformation. Traditional fact-checking relies on manual analysis to verify
claims, but it is slow and resource-intensive. This study establishes baseline
comparisons for Automated Fact-Checking (AFC) using Large Language Models
(LLMs) across multiple labeling schemes (binary, three-class, five-class) and
extends traditional claim verification by incorporating analysis, verdict
classification, and explanation in a structured setup to provide comprehensive
justifications for real-world claims. We evaluate Llama-3 models of varying
sizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024)
using evidence retrieved via restricted web searches. We utilize TIGERScore as
a reference-free evaluation metric to score the justifications. Our results
show that larger LLMs consistently outperform smaller LLMs in classification
accuracy and justification quality without fine-tuning. We find that smaller
LLMs in a one-shot scenario provide comparable task performance to fine-tuned
Small Language Models (SLMs) with large context sizes, while larger LLMs
consistently surpass them. Evidence integration improves performance across all
models, with larger LLMs benefiting most. Distinguishing between nuanced labels
remains challenging, emphasizing the need for further exploration of labeling
schemes and alignment with evidences. Our findings demonstrate the potential of
retrieval-augmented AFC with LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can Uniform Meaning Representation Help <span class="highlight-title">GPT</span>-4 Translate from Indigenous
  Languages? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08900v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08900v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shira Wein
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While ChatGPT and GPT-based models are able to effectively perform many tasks
without additional fine-tuning, they struggle with related to extremely
low-resource languages and indigenous languages. Uniform Meaning Representation
(UMR), a semantic representation designed to capture the meaning of texts in
many languages, is well-poised to be leveraged in the development of
low-resource language technologies. In this work, we explore the downstream
technical utility of UMR for low-resource languages by incorporating it into
GPT-4 prompts. Specifically, we examine the ability of GPT-4 to perform
translation from three indigenous languages (Navajo, Ar\'apaho, and Kukama),
with and without demonstrations, as well as with and without UMR annotations.
Ultimately we find that in the majority of our test cases, integrating UMR into
the prompt results in a statistically significant increase in performance,
which is a promising indication of future applications of the UMR formalism.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Communication is All You Need: Persuasion <span class="highlight-title">Dataset</span> Construction via
  Multi-LLM Communication <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08896v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08896v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weicheng Ma, Hefan Zhang, Ivory Yang, Shiyu Ji, Joice Chen, Farnoosh Hashemi, Shubham Mohole, Ethan Gearey, Michael Macy, Saeed Hassanpour, Soroush Vosoughi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have shown proficiency in generating persuasive
dialogue, yet concerns about the fluency and sophistication of their outputs
persist. This paper presents a multi-LLM communication framework designed to
enhance the generation of persuasive data automatically. This framework
facilitates the efficient production of high-quality, diverse linguistic
content with minimal human oversight. Through extensive evaluations, we
demonstrate that the generated data excels in naturalness, linguistic
diversity, and the strategic use of persuasion, even in complex scenarios
involving social taboos. The framework also proves adept at generalizing across
novel contexts. Our results highlight the framework's potential to
significantly advance research in both computational and social science domains
concerning persuasive communication.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2025 Main Conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM-Enhanced Multiple Instance Learning for Joint Rumor and Stance
  Detection with Social Context Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08888v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08888v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruichao Yang, Jing Ma, Wei Gao, Hongzhan Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proliferation of misinformation, such as rumors on social media, has
drawn significant attention, prompting various expressions of stance among
users. Although rumor detection and stance detection are distinct tasks, they
can complement each other. Rumors can be identified by cross-referencing
stances in related posts, and stances are influenced by the nature of the
rumor. However, existing stance detection methods often require post-level
stance annotations, which are costly to obtain. We propose a novel LLM-enhanced
MIL approach to jointly predict post stance and claim class labels, supervised
solely by claim labels, using an undirected microblog propagation model. Our
weakly supervised approach relies only on bag-level labels of claim veracity,
aligning with multi-instance learning (MIL) principles. To achieve this, we
transform the multi-class problem into multiple MIL-based binary classification
problems. We then employ a discriminative attention layer to aggregate the
outputs from these classifiers into finer-grained classes. Experiments
conducted on three rumor datasets and two stance datasets demonstrate the
effectiveness of our approach, highlighting strong connections between rumor
veracity and expressed stances in responding posts. Our method shows promising
performance in joint rumor and stance detection compared to the
state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ACM TIST</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ BrainWavLM: Fine-tuning Speech Representations with Brain Responses to
  Language 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08866v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08866v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nishitha Vattikonda, Aditya R. Vaidya, Richard J. Antonello, Alexander G. Huth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Speech encoding models use auditory representations to predict how the human
brain responds to spoken language stimuli. Most performant encoding models
linearly map the hidden states of artificial neural networks to brain data, but
this linear restriction may limit their effectiveness. In this work, we use
low-rank adaptation (LoRA) to fine-tune a WavLM-based encoding model end-to-end
on a brain encoding objective, producing a model we name BrainWavLM. We show
that fine-tuning across all of cortex improves average encoding performance
with greater stability than without LoRA. This improvement comes at the expense
of low-level regions like auditory cortex (AC), but selectively fine-tuning on
these areas improves performance in AC, while largely retaining gains made in
the rest of cortex. Fine-tuned models generalized across subjects, indicating
that they learned robust brain-like representations of the speech stimuli.
Finally, by training linear probes, we showed that the brain data strengthened
semantic representations in the speech model without any explicit annotations.
Our results demonstrate that brain fine-tuning produces best-in-class speech
encoding models, and that non-linear methods have the potential to bridge the
gap between artificial and biological representations of semantics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08859v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08859v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Clinton J. Wang, Dean Lee, Cristina Menghini, Johannes Mols, Jack Doughty, Adam Khoja, Jayson Lynch, Sean Hendryx, Summer Yue, Dan Hendrycks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As language models master existing reasoning benchmarks, we need new
challenges to evaluate their cognitive frontiers. Puzzle-solving events are
rich repositories of challenging multimodal problems that test a wide range of
advanced reasoning and knowledge capabilities, making them a unique testbed for
evaluating frontier language models. We introduce EnigmaEval, a dataset of
problems and solutions derived from puzzle competitions and events that probes
models' ability to perform implicit knowledge synthesis and multi-step
deductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle
solving challenges models to discover hidden connections between seemingly
unrelated pieces of information to uncover solution paths. The benchmark
comprises 1184 puzzles of varying complexity -- each typically requiring teams
of skilled solvers hours to days to complete -- with unambiguous, verifiable
solutions that enable efficient evaluation. State-of-the-art language models
achieve extremely low accuracy on these puzzles, even lower than other
difficult benchmarks such as Humanity's Last Exam, unveiling models'
shortcomings when challenged with problems requiring unstructured and lateral
reasoning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s Learn Low Sensitivity Functions: Investigations and
  Implications <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06925v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06925v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhavya Vasudeva, Deqing Fu, Tianyi Zhou, Elliott Kau, Youqi Huang, Vatsal Sharan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers achieve state-of-the-art accuracy and robustness across many
tasks, but an understanding of their inductive biases and how those biases
differ from other neural network architectures remains elusive. In this work,
we identify the sensitivity of the model to token-wise random perturbations in
the input as a unified metric which explains the inductive bias of transformers
across different data modalities and distinguishes them from other
architectures. We show that transformers have lower sensitivity than MLPs,
CNNs, ConvMixers and LSTMs, across both vision and language tasks. We also show
that this low-sensitivity bias has important implications: i) lower sensitivity
correlates with improved robustness; it can also be used as an efficient
intervention to further improve the robustness of transformers; ii) it
corresponds to flatter minima in the loss landscape; and iii) it can serve as a
progress measure for grokking. We support these findings with theoretical
results showing (weak) spectral bias of transformers in the NTK regime, and
improved robustness due to the lower sensitivity. The code is available at
https://github.com/estija/sensitivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. 24 pages, 19 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hello Again! LLM-powered Personalized Agent for Long-term Dialogue <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05925v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05925v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Open-domain dialogue systems have seen remarkable advancements with the
development of large language models (LLMs). Nonetheless, most existing
dialogue systems predominantly focus on brief single-session interactions,
neglecting the real-world demands for long-term companionship and personalized
interactions with chatbots. Crucial to addressing this real-world need are
event summary and persona management, which enable reasoning for appropriate
long-term dialogue responses. Recent progress in the human-like cognitive and
reasoning capabilities of LLMs suggests that LLM-based agents could
significantly enhance automated perception, decision-making, and
problem-solving. In response to this potential, we introduce a model-agnostic
framework, the Long-term Dialogue Agent (LD-Agent), which incorporates three
independently tunable modules dedicated to event perception, persona
extraction, and response generation. For the event memory module, long and
short-term memory banks are employed to separately focus on historical and
ongoing sessions, while a topic-based retrieval mechanism is introduced to
enhance the accuracy of memory retrieval. Furthermore, the persona module
conducts dynamic persona modeling for both users and agents. The integration of
retrieved memories and extracted personas is subsequently fed into the
generator to induce appropriate responses. The effectiveness, generality, and
cross-domain capabilities of LD-Agent are empirically demonstrated across
various illustrative benchmarks, models, and tasks. The code is released at
https://github.com/leolee99/LD-Agent.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating Zero-Shot Long-Context LLM Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06773v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06773v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyu Wang, Yihan Wang, Kai Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study evaluates the effectiveness of zero-shot compression techniques on
large language models (LLMs) under long-context. We identify the tendency for
computational errors to increase under long-context when employing certain
compression methods. We propose a hypothesis to explain the varied behavior of
different LLM compression techniques and explore remedies to mitigate the
performance decline observed in some techniques under long-context. This is a
course report for COS 598D Machine Learning and Systems by Prof. Kai Li at
Princeton University. Due to limited computational resources, our experiments
were conducted only on LLaMA-2-7B-32K.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Salamandra Technical Report 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08489v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08489v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aitor Gonzalez-Agirre, Marc Pàmies, Joan Llop, Irene Baucells, Severino Da Dalt, Daniel Tamayo, José Javier Saiz, Ferran Espuña, Jaume Prats, Javier Aula-Blasco, Mario Mina, Iñigo Pikabea, Adrián Rubio, Alexander Shvets, Anna Sallés, Iñaki Lacunza, Jorge Palomar, Júlia Falcão, Lucía Tormo, Luis Vasquez-Reina, Montserrat Marimon, Oriol Pareras, Valle Ruiz-Fernández, Marta Villegas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This work introduces Salamandra, a suite of open-source decoder-only large
language models available in three different sizes: 2, 7, and 40 billion
parameters. The models were trained from scratch on highly multilingual data
that comprises text in 35 European languages and code. Our carefully curated
corpus is made exclusively from open-access data compiled from a wide variety
of sources. Along with the base models, supplementary checkpoints that were
fine-tuned on public-domain instruction data are also released for chat
applications. Additionally, we also share our preliminary experiments on
multimodality, which serve as proof-of-concept to showcase potential
applications for the Salamandra family. Our extensive evaluations on
multilingual benchmarks reveal that Salamandra has strong capabilities,
achieving competitive performance when compared to similarly sized open-source
models. We provide comprehensive evaluation results both on standard downstream
tasks as well as key aspects related to bias and safety.With this technical
report, we intend to promote open science by sharing all the details behind our
design choices, data curation strategy and evaluation methodology. In addition
to that, we deviate from the usual practice by making our training and
evaluation scripts publicly accessible. We release all models under a
permissive Apache 2.0 license in order to foster future research and facilitate
commercial use, thereby contributing to the open-source ecosystem of large
language models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fine-Tuned LLMs are "Time Capsules" for Tracking Societal Bias Through
  Books <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05331v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05331v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sangmitra Madhusudan, Robert Morabito, Skye Reid, Nikta Gohari Sadr, Ali Emami
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Books, while often rich in cultural insights, can also mirror societal biases
of their eras - biases that Large Language Models (LLMs) may learn and
perpetuate during training. We introduce a novel method to trace and quantify
these biases using fine-tuned LLMs. We develop BookPAGE, a corpus comprising
593 fictional books across seven decades (1950-2019), to track bias evolution.
By fine-tuning LLMs on books from each decade and using targeted prompts, we
examine shifts in biases related to gender, sexual orientation, race, and
religion. Our findings indicate that LLMs trained on decade-specific books
manifest biases reflective of their times, with both gradual trends and notable
shifts. For example, model responses showed a progressive increase in the
portrayal of women in leadership roles (from 8% to 22%) from the 1950s to
2010s, with a significant uptick in the 1990s (from 4% to 12%), possibly
aligning with third-wave feminism. Same-sex relationship references increased
markedly from the 1980s to 2000s (from 0% to 10%), mirroring growing LGBTQ+
visibility. Concerningly, negative portrayals of Islam rose sharply in the
2000s (26% to 38%), likely reflecting post-9/11 sentiments. Importantly, we
demonstrate that these biases stem mainly from the books' content and not the
models' architecture or initial training. Our study offers a new perspective on
societal bias trends by bridging AI, literary studies, and social science
research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages (excluding references), accepted to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Measuring Human Contribution in AI-Assisted Content Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14792v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14792v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yueqi Xie, Tao Qi, Jingwei Yi, Xiyuan Yang, Ryan Whalen, Junming Huang, Qian Ding, Yu Xie, Xing Xie, Fangzhao Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the growing prevalence of generative artificial intelligence (AI), an
increasing amount of content is no longer exclusively generated by humans but
by generative AI models with human guidance. This shift presents notable
challenges for the delineation of originality due to the varying degrees of
human contribution in AI-assisted works. This study raises the research
question of measuring human contribution in AI-assisted content generation and
introduces a framework to address this question that is grounded in information
theory. By calculating mutual information between human input and AI-assisted
output relative to self-information of AI-assisted output, we quantify the
proportional information contribution of humans in content generation. Our
experimental results demonstrate that the proposed measure effectively
discriminates between varying degrees of human contribution across multiple
creative domains. We hope that this work lays a foundation for measuring human
contributions in AI-assisted content generation in the era of generative AI.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rationalization Models for Text-to-SQL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06759v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06759v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gaetano Rossiello, Nhan Pham, Michael Glass, Junkyu Lee, Dharmashankar Subramanian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a framework for generating Chain-of-Thought (CoT) rationales to
enhance text-to-SQL model fine-tuning. These rationales consist of intermediate
SQL statements and explanations, serving as incremental steps toward
constructing the final SQL query. The process begins with manually annotating a
small set of examples, which are then used to prompt a large language model in
an iterative, dynamic few-shot knowledge distillation procedure from a teacher
model. A rationalization model is subsequently trained on the validated
decomposed queries, enabling extensive synthetic CoT annotations for
text-to-SQL datasets. To evaluate the approach, we fine-tune small language
models with and without these rationales on the BIRD dataset. Results indicate
that step-by-step query generation improves execution accuracy, especially for
moderately and highly complex queries, while also enhancing explainability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SARChat-Bench-2M: A Multi-Task Vision-Language Benchmark for SAR Image
  Interpretation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08168v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08168v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhiming Ma, Xiayang Xiao, Sihao Dong, Peidong Wang, HaiPeng Wang, Qingyun Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a powerful all-weather Earth observation tool, synthetic aperture radar
(SAR) remote sensing enables critical military reconnaissance, maritime
surveillance, and infrastructure monitoring. Although Vision language models
(VLMs) have made remarkable progress in natural language processing and image
understanding, their applications remain limited in professional domains due to
insufficient domain expertise. This paper innovatively proposes the first
large-scale multimodal dialogue dataset for SAR images, named SARChat-2M, which
contains approximately 2 million high-quality image-text pairs, encompasses
diverse scenarios with detailed target annotations. This dataset not only
supports several key tasks such as visual understanding and object detection
tasks, but also has unique innovative aspects: this study develop a
visual-language dataset and benchmark for the SAR domain, enabling and
evaluating VLMs' capabilities in SAR image interpretation, which provides a
paradigmatic framework for constructing multimodal datasets across various
remote sensing vertical domains. Through experiments on 16 mainstream VLMs, the
effectiveness of the dataset has been fully verified. The project will be
released at https://github.com/JimmyMa99/SARChat.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Agent-OM: Leveraging LLM Agents for Ontology Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00326v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00326v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangcheng Qiang, Weiqing Wang, Kerry Taylor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ontology matching (OM) enables semantic interoperability between different
ontologies and resolves their conceptual heterogeneity by aligning related
entities. OM systems currently have two prevailing design paradigms:
conventional knowledge-based expert systems and newer machine learning-based
predictive systems. While large language models (LLMs) and LLM agents have
revolutionised data engineering and have been applied creatively in many
domains, their potential for OM remains underexplored. This study introduces a
novel agent-powered LLM-based design paradigm for OM systems. With
consideration of several specific challenges in leveraging LLM agents for OM,
we propose a generic framework, namely Agent-OM (Agent for Ontology Matching),
consisting of two Siamese agents for retrieval and matching, with a set of OM
tools. Our framework is implemented in a proof-of-concept system. Evaluations
of three Ontology Alignment Evaluation Initiative (OAEI) tracks over
state-of-the-art OM systems show that our system can achieve results very close
to the long-standing best performance on simple OM tasks and can significantly
improve the performance on complex and few-shot OM tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Better Embeddings with Coupled Adam 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Stollenwerk, Tobias Stollenwerk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable capabilities, LLMs learn word representations that
exhibit the undesirable yet poorly understood feature of anisotropy. In this
paper, we argue that the second moment in Adam is a cause of anisotropic
embeddings, and suggest a modified optimizer called Coupled Adam to mitigate
the problem. Our experiments demonstrate that Coupled Adam significantly
improves the quality of embeddings, while also leading to better upstream and
downstream performance on large enough datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures; figures corrected</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Factual Consistency of News Summarization by Contrastive
  Preference Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.19347v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.19347v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huawen Feng, Yan Fan, Xiong Liu, Ting-En Lin, Zekun Yao, Yuchuan Wu, Fei Huang, Yongbin Li, Qianli Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the recent progress in news summarization made by large language
models (LLMs), they often generate summaries that are factually inconsistent
with original articles, known as "hallucinations" in text generation. Unlike
previous small models (e.g., BART, T5), current LLMs make fewer silly mistakes
but more sophisticated ones, such as imposing cause and effect, adding false
details, overgeneralizing, etc. These hallucinations are challenging to detect
through traditional methods, which poses great challenges for improving the
factual consistency of text summarization. In this paper, we propose
Contrastive Preference Optimization (CPO) to disentangle the LLMs' propensities
to generate faithful and fake content. Furthermore, we adopt a probing-based
specific training method to improve their capacity of distinguishing two types
of propensities. In this way, LLMs can execute the instructions more accurately
and have enhanced perception of hallucinations. Experimental results show that
CPO significantly improves the reliability of summarization based on LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The LLM Language Network: A Neuroscientific Approach for Identifying
  Causally Task-Relevant Units <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit remarkable capabilities on not just
language tasks, but also various tasks that are not linguistic in nature, such
as logical reasoning and social inference. In the human brain, neuroscience has
identified a core language system that selectively and causally supports
language processing. We here ask whether similar specialization for language
emerges in LLMs. We identify language-selective units within 18 popular LLMs,
using the same localization approach that is used in neuroscience. We then
establish the causal role of these units by demonstrating that ablating LLM
language-selective units -- but not random units -- leads to drastic deficits
in language tasks. Correspondingly, language-selective LLM units are more
aligned to brain recordings from the human language system than random units.
Finally, we investigate whether our localization method extends to other
cognitive domains: while we find specialized networks in some LLMs for
reasoning and social capabilities, there are substantial differences among
models. These findings provide functional and causal evidence for
specialization in large language models, and highlight parallels with the
functional organization in the brain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WarriorCoder: Learning from Expert Battles to Augment Code Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.17395v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.17395v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huawen Feng, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite recent progress achieved by code large language models (LLMs), their
remarkable abilities are largely dependent on fine-tuning on the high-quality
data, posing challenges for data collection and annotation. To address this,
current methods often design various data flywheels to collect complex code
instructions, enabling models to handle more intricate tasks. However, these
approaches typically rely on off-the-shelf datasets and data augmentation from
a limited set of proprietary LLMs (e.g., Claude, GPT4, and so on), which
restricts the diversity of the constructed data and makes it prone to systemic
biases. In this paper, we propose WarriorCoder, a novel paradigm learns from
expert battles to address these limitations. Specifically, we create an arena
where leading expert code LLMs challenge each other, with evaluations conducted
by impartial judges. This competitive framework generates novel training data
from scratch, leveraging the strengths of all participants. Experimental
results show that WarriorCoder achieves state-of-the-art performance compared
to previous models of the same size, even without relying on proprietary LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generative <span class="highlight-title">Prompt</span> Internalization <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.15927v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.15927v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haebin Shin, Lei Ji, Yeyun Gong, Sungdong Kim, Eunbi Choi, Minjoon Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prompts used in recent large language model based applications are often
fixed and lengthy, leading to significant computational overhead. To address
this challenge, we propose Generative Prompt Internalization (GenPI), a
lightweight method that employs a joint training approach. GenPI not only
replicates the behavior of models with prompt inputs but also generates the
content of the prompt along with reasons for why the model's behavior should
change accordingly. We demonstrate that our approach effectively internalizes
complex prompts across various agent-based application scenarios. For effective
training without interactions with the dedicated environments, we introduce a
data synthesis technique that autonomously collects conversational datasets by
swapping the roles of the agent and environment. This method is especially
useful in scenarios where only a predefined prompt is available without a
corresponding training dataset. By internalizing complex prompts, Generative
Prompt Internalization enables high performance and efficient inference without
the need for explicit prompts.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 (Main Conference)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Faithful, Unfaithful or Ambiguous? Multi-Agent Debate with Initial
  Stance for Summary Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08514v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08514v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahnaz Koupaee, Jake W. Vincent, Saab Mansour, Igor Shalyminov, Han He, Hwanjun Song, Raphael Shu, Jianfeng He, Yi Nian, Amy Wing-mei Wong, Kyu J. Han, Hang Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Faithfulness evaluators based on large language models (LLMs) are often
fooled by the fluency of the text and struggle with identifying errors in the
summaries. We propose an approach to summary faithfulness evaluation in which
multiple LLM-based agents are assigned initial stances (regardless of what
their belief might be) and forced to come up with a reason to justify the
imposed belief, thus engaging in a multi-round debate to reach an agreement.
The uniformly distributed initial assignments result in a greater diversity of
stances leading to more meaningful debates and ultimately more errors
identified. Furthermore, by analyzing the recent faithfulness evaluation
datasets, we observe that naturally, it is not always the case for a summary to
be either faithful to the source document or not. We therefore introduce a new
dimension, ambiguity, and a detailed taxonomy to identify such special cases.
Experiments demonstrate our approach can help identify ambiguities, and have
even a stronger performance on non-ambiguous summaries.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Actionable Framework for Assessing Bias and Fairness in Large
  Language Model Use Cases 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10853v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10853v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dylan Bouchard
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) can exhibit bias in a variety of ways. Such
biases can create or exacerbate unfair outcomes for certain groups within a
protected attribute, including, but not limited to sex, race, sexual
orientation, or age. In this paper, we propose a decision framework that allows
practitioners to determine which bias and fairness metrics to use for a
specific LLM use case. To establish the framework, we define bias and fairness
risks for LLMs, map those risks to a taxonomy of LLM use cases, and then define
various metrics to assess each type of risk. Instead of focusing solely on the
model itself, we account for both prompt-specific- and model-specific-risk by
defining evaluations at the level of an LLM use case, characterized by a model
and a population of prompts. Furthermore, because all of the evaluation metrics
are calculated solely using the LLM output, our proposed framework is highly
practical and easily actionable for practitioners. For streamlined
implementation, all evaluation metrics included in the framework are offered in
this paper's companion Python toolkit, LangFair. Finally, our experiments
demonstrate substantial variation in bias and fairness across use cases,
underscoring the importance of use-case-level assessments.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>LangFair repository: https://github.com/cvs-health/langfair</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On-Device Emoji Classifier Trained with <span class="highlight-title">GPT</span>-based Data Augmentation for
  a Mobile Keyboard 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.05031v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.05031v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hossam Amer, Joe Osborne, Michael Zaki, Mohamed Afify
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emojis improve communication quality among smart-phone users that use mobile
keyboards to exchange text. To predict emojis for users based on input text, we
should consider the on-device low memory and time constraints, ensure that the
on-device emoji classifier covers a wide range of emoji classes even though the
emoji dataset is typically imbalanced, and adapt the emoji classifier output to
user favorites. This paper proposes an on-device emoji classifier based on
MobileBert with reasonable memory and latency requirements for SwiftKey. To
account for the data imbalance, we utilize the widely used GPT to generate one
or more tags for each emoji class. For each emoji and corresponding tags, we
merge the original set with GPT-generated sentences and label them with this
emoji without human intervention to alleviate the data imbalance. At inference
time, we interpolate the emoji output with the user history for emojis for
better emoji classifications. Results show that the proposed on-device emoji
classifier deployed for SwiftKey increases the accuracy performance of emoji
prediction particularly on rare emojis and emoji engagement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DeepThink: Aligning Language Models with Domain-Specific User Intents 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05497v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05497v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yang Li, Mingxuan Luo, Yeyun Gong, Chen Lin, Jian Jiao, Yi Liu, Kaili Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Supervised fine-tuning with synthesized instructions has been a common
practice for adapting LLMs to domain-specific QA tasks. However, the
synthesized instructions deviate from real user questions and expected answers.
This study proposes a novel framework called DeepThink to generate high-quality
instructions. DeepThink first generates a few seed questions to mimic actual
user questions, simulates conversations to uncover the hidden user needs, and
refines the answer by conversational contexts and the retrieved documents for
more comprehensive answers. Experiments demonstrate that DeepThink achieves an
average performance improvement of 7.92% compared to a GPT-4-turbo+RAG-based
assistant on the real user test set in the advertising domain across dimensions
such as relevance, completeness, clarity, accuracy, and actionability.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Large Language Model Performance with Gradient-Based Parameter
  Selection <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.15330v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.15330v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoling Li, Xin Zhang, Xiao Liu, Yeyun Gong, Yifan Wang, Qi Chen, Peng Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have revolutionized lots of fields of research.
Although it is well-known that fine-tuning is essential for enhancing the
capabilities of LLMs, existing research suggests that there is potential
redundancy in the fine-tuning process and therefore proposes to update only a
subset of parameters. However, these methods fail to leverage the task-specific
information to identify important parameters during training. Based on the
insight that gradients inherently contain information on task-specific data, we
propose Gradient-Mask Tuning (GMT), a method that selectively updates
parameters during training based on their gradient information. Specifically,
we compute the absolute values of the gradients and apply masking to those with
relatively smaller magnitudes. Our empirical results across various tasks
demonstrate that GMT not only outperforms traditional fine-tuning methods but
also elevates the upper limits of LLM performance. Further analysis indicates
that GMT exhibits insensitivity to mask ratio and possesses computational
efficiency comparable to vanilla SFT.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ACEBench: Who Wins the Match Point in Tool Usage? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.12851v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.12851v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Chen, Xinlong Hao, Weiwen Liu, Xu Huang, Xingshan Zeng, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Yuefeng Huang, Wulong Liu, Xinzhi Wang, Defu Lian, Baoqun Yin, Yasheng Wang, Wu Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated significant potential in
decision-making and reasoning, particularly when integrated with various tools
to effectively solve complex problems. However, existing benchmarks for
evaluating LLMs' tool usage face several limitations: (1) limited evaluation
scenarios, often lacking assessments in real multi-turn dialogue contexts; (2)
narrow evaluation dimensions, with insufficient detailed assessments of how
LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation,
which introduces significant overhead. To address these challenges, we
introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs.
ACEBench categorizes data into three primary types based on evaluation
methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic
scenarios; "Special" evaluates tool usage in situations with ambiguous or
incomplete instructions; "Agent" evaluates tool usage through multi-agent
interactions to simulate real-world, multi-turn dialogues. We conducted
extensive experiments using ACEBench, analyzing various LLMs in-depth and
providing a more granular examination of error causes across different data
types.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ReFINE: A Reward-Based Framework for Interpretable and Nuanced
  Evaluation of Radiology Report Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17301v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17301v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunyi Liu, Yingshu Li, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Luping Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automated radiology report generation (R2Gen) has advanced significantly,
introducing challenges in accurate evaluation due to its complexity.
Traditional metrics often fall short by relying on rigid word-matching or
focusing only on pathological entities, leading to inconsistencies with human
assessments. To bridge this gap, we introduce ReFINE, an automatic evaluation
metric designed specifically for R2Gen. Our metric utilizes a reward model,
guided by our margin-based reward enforcement loss, along with a tailored
training data design that enables customization of evaluation criteria to suit
user-defined needs. It not only scores reports according to user-specified
criteria but also provides detailed sub-scores, enhancing interpretability and
allowing users to adjust the criteria between different aspects of reports.
Leveraging GPT-4, we designed an easy-to-use data generation pipeline, enabling
us to produce extensive training data based on two distinct scoring systems,
each containing reports of varying quality along with corresponding scores.
These GPT-generated reports are then paired as accepted and rejected samples
through our pairing rule to train an LLM towards our fine-grained reward model,
which assigns higher rewards to the report with high quality. Our
reward-control loss enables this model to simultaneously output multiple
individual rewards corresponding to the number of evaluation criteria, with
their summation as our final ReFINE. Our experiments demonstrate ReFINE's
heightened correlation with human judgments and superior performance in model
selection compared to traditional metrics. Notably, our model provides both an
overall score and individual scores for each evaluation item, enhancing
interpretability. We also demonstrate its flexible training across various
evaluation systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Creativity of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2304.00008v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2304.00008v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giorgio Franceschelli, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are revolutionizing several areas of Artificial
Intelligence. One of the most remarkable applications is creative writing,
e.g., poetry or storytelling: the generated outputs are often of astonishing
quality. However, a natural question arises: can LLMs be really considered
creative? In this article, we first analyze the development of LLMs under the
lens of creativity theories, investigating the key open questions and
challenges. In particular, we focus our discussion on the dimensions of value,
novelty, and surprise as proposed by Margaret Boden in her work. Then, we
consider different classic perspectives, namely product, process, press, and
person. We discuss a set of ``easy'' and ``hard'' problems in machine
creativity, presenting them in relation to LLMs. Finally, we examine the
societal impact of these technologies with a particular focus on the creative
industries, analyzing the opportunities offered, the challenges arising from
them, and the potential associated risks, from both legal and ethical points of
view.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in AI & SOCIETY at
  https://link.springer.com/article/10.1007/s00146-024-02127-3</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous
  Knowledge Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.16495v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.16495v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the outstanding capabilities of large language models (LLMs),
knowledge-intensive reasoning still remains a challenging task due to LLMs'
limitations in compositional reasoning and the hallucination problem. A
prevalent solution is to employ chain-of-thought (CoT) with retrieval-augmented
generation (RAG), which first formulates a reasoning plan by decomposing
complex questions into simpler sub-questions, and then applies iterative RAG at
each sub-question. However, prior works exhibit two crucial problems:
inadequate reasoning planning and poor incorporation of heterogeneous
knowledge. In this paper, we introduce AtomR, a framework for LLMs to conduct
accurate heterogeneous knowledge reasoning at the atomic level. Inspired by how
knowledge graph query languages model compositional reasoning through combining
predefined operations, we propose three atomic knowledge operators, a unified
set of operators for LLMs to retrieve and manipulate knowledge from
heterogeneous sources. First, in the reasoning planning stage, AtomR decomposes
a complex question into a reasoning tree where each leaf node corresponds to an
atomic knowledge operator, achieving question decomposition that is highly
fine-grained and orthogonal. Subsequently, in the reasoning execution stage,
AtomR executes each atomic knowledge operator, which flexibly selects,
retrieves, and operates atomic level knowledge from heterogeneous sources. We
also introduce BlendQA, a challenging benchmark specially tailored for
heterogeneous knowledge reasoning. Experiments on three single-source and two
multi-source datasets show that AtomR outperforms state-of-the-art baselines by
a large margin, with F1 score improvements of 9.4% on 2WikiMultihop and 9.5% on
BlendQA. We release our code and datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy Checklist: Privacy Violation Detection Grounding on Contextual
  Integrity Theory <span class="chip">NAACL 25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.10053v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.10053v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haoran Li, Wei Fan, Yulin Chen, Jiayang Cheng, Tianshu Chu, Xuebing Zhou, Peizhao Hu, Yangqiu Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Privacy research has attracted wide attention as individuals worry that their
private data can be easily leaked during interactions with smart devices,
social platforms, and AI applications. Computer science researchers, on the
other hand, commonly study privacy issues through privacy attacks and defenses
on segmented fields. Privacy research is conducted on various sub-fields,
including Computer Vision (CV), Natural Language Processing (NLP), and Computer
Networks. Within each field, privacy has its own formulation. Though pioneering
works on attacks and defenses reveal sensitive privacy issues, they are
narrowly trapped and cannot fully cover people's actual privacy concerns.
Consequently, the research on general and human-centric privacy research
remains rather unexplored. In this paper, we formulate the privacy issue as a
reasoning problem rather than simple pattern matching. We ground on the
Contextual Integrity (CI) theory which posits that people's perceptions of
privacy are highly correlated with the corresponding social context. Based on
such an assumption, we develop the first comprehensive checklist that covers
social identities, private attributes, and existing privacy regulations. Unlike
prior works on CI that either cover limited expert annotated norms or model
incomplete social context, our proposed privacy checklist uses the whole Health
Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to
show that we can resort to large language models (LLMs) to completely cover the
HIPAA's regulations. Additionally, our checklist also gathers expert
annotations across multiple ontologies to determine private information
including but not limited to personally identifiable information (PII). We use
our preliminary results on the HIPAA to shed light on future context-centric
privacy research to cover more privacy regulations, social norms and standards.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>To appear at NAACL 25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Language Models as Continuous Self-Evolving Data Engineers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.15151v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.15151v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peidong Wang, Ming Wang, Zhiming Ma, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have demonstrated remarkable capabilities on
various tasks, while the further evolvement is limited to the lack of
high-quality training data. In addition, traditional training approaches rely
too much on expert-labeled data, setting a ceiling on the performance of LLMs.
To address this issue, we propose a novel paradigm named LANCE (LANguage models
as Continuous self-Evolving data engineers) that enables LLMs to train
themselves by autonomously generating, cleaning, reviewing, and annotating data
with preference information. Our approach demonstrates that LLMs can serve as
continuous self-evolving data engineers, significantly reducing the time and
cost of the post-training data construction. Through iterative fine-tuning on
Qwen2 series models, we validate the effectiveness of LANCE across various
tasks, showing that it can maintain high-quality data generation and
continuously improve model performance. Across multiple benchmark dimensions,
LANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for
Qwen2-7B-Instruct. This training paradigm with autonomous data construction not
only reduces the reliance on human experts or external models but also ensures
that the data aligns with human preferences, paving the way for the development
of future superintelligent systems that can exceed human capabilities. Codes
are available at: https://github.com/Control-derek/LANCE.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Are Large Language Models Really Bias-Free? Jailbreak <span class="highlight-title">Prompt</span>s for
  Assessing Adversarial Robustness to Bias Elicitation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.08441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.08441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have revolutionized artificial intelligence,
demonstrating remarkable computational power and linguistic capabilities.
However, these models are inherently prone to various biases stemming from
their training data. These include selection, linguistic, and confirmation
biases, along with common stereotypes related to gender, ethnicity, sexual
orientation, religion, socioeconomic status, disability, and age. This study
explores the presence of these biases within the responses given by the most
recent LLMs, analyzing the impact on their fairness and reliability. We also
investigate how known prompt engineering techniques can be exploited to
effectively reveal hidden biases of LLMs, testing their adversarial robustness
against jailbreak prompts specially crafted for bias elicitation. Extensive
experiments are conducted using the most widespread LLMs at different scales,
confirming that LLMs can still be manipulated to produce biased or
inappropriate responses, despite their advanced capabilities and sophisticated
alignment processes. Our findings underscore the importance of enhancing
mitigation techniques to address these safety issues, toward a more sustainable
and inclusive artificial intelligence.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Large Language Models for Knowledge Graph Completion <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2308.13916v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2308.13916v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Yao, Jiazhen Peng, Chengsheng Mao, Yuan Luo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge graphs play a vital role in numerous artificial intelligence tasks,
yet they frequently face the issue of incompleteness. In this study, we explore
utilizing Large Language Models (LLM) for knowledge graph completion. We
consider triples in knowledge graphs as text sequences and introduce an
innovative framework called Knowledge Graph LLM (KG-LLM) to model these
triples. Our technique employs entity and relation descriptions of a triple as
prompts and utilizes the response for predictions. Experiments on various
benchmark knowledge graphs demonstrate that our method attains state-of-the-art
performance in tasks such as triple classification and relation prediction. We
also find that fine-tuning relatively smaller models (e.g., LLaMA-7B,
ChatGLM-6B) outperforms recent ChatGPT and GPT-4.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by the 2025 IEEE International Conference on Acoustics,
  Speech, and Signal Processing (ICASSP 2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An Evolved Universal <span class="highlight-title">Transformer</span> Memory <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13166v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13166v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edoardo Cetin, Qi Sun, Tianyu Zhao, Yujin Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prior methods propose to offset the escalating costs of modern foundation
models by dropping specific parts of their contexts with hand-designed rules,
while attempting to preserve their original performance. We overcome this
trade-off with Neural Attention Memory Models (NAMMs), introducing a learned
network for memory management that improves both the performance and efficiency
of transformers. We evolve NAMMs atop pre-trained transformers to provide
different latent contexts focusing on the most relevant information for
individual layers and attention heads. NAMMs are universally applicable to any
model using self-attention as they condition exclusively on the values in the
produced attention matrices. Learning NAMMs on a small set of problems, we
achieve substantial performance improvements across multiple long-context
benchmarks while cutting the model's input contexts up to a fraction of the
original sizes. We show the generality of our conditioning enables zero-shot
transfer of NAMMs trained only on language to entirely new transformer
architectures even across input modalities, with their benefits carrying over
to vision and reinforcement learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published at ICLR 2025. Source code available at
  https://github.com/SakanaAI/evo-memory</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring the use of a Large Language Model for data extraction in
  systematic <span class="highlight-title">review</span>s: a rapid feasibility study 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.14445v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.14445v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lena Schmidt, Kaitlyn Hair, Sergio Graziosi, Fiona Campbell, Claudia Kapp, Alireza Khanteymoori, Dawn Craig, Mark Engelbert, James Thomas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper describes a rapid feasibility study of using GPT-4, a large
language model (LLM), to (semi)automate data extraction in systematic reviews.
Despite the recent surge of interest in LLMs there is still a lack of
understanding of how to design LLM-based automation tools and how to robustly
evaluate their performance. During the 2023 Evidence Synthesis Hackathon we
conducted two feasibility studies. Firstly, to automatically extract study
characteristics from human clinical, animal, and social science domain studies.
We used two studies from each category for prompt-development; and ten for
evaluation. Secondly, we used the LLM to predict Participants, Interventions,
Controls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP
dataset. Overall, results indicated an accuracy of around 80%, with some
variability between domains (82% for human clinical, 80% for animal, and 72%
for studies of human social sciences). Causal inference methods and study
design were the data extraction items with the most errors. In the PICO study,
participants and intervention/control showed high accuracy (>80%), outcomes
were more challenging. Evaluation was done manually; scoring methods such as
BLEU and ROUGE showed limited value. We observed variability in the LLMs
predictions and changes in response quality. This paper presents a template for
future evaluations of LLMs in the context of data extraction for systematic
review automation. Our results show that there might be value in using LLMs,
for example as second or third reviewers. However, caution is advised when
integrating models such as GPT-4 into tools. Further research on stability and
reliability in practical settings is warranted for each type of data that is
processed by the LLM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Conference proceedings, peer-reviewed and presented at the 3rd
  Workshop on Augmented Intelligence for Technology-Assisted Reviews Systems,
  Glasgow, 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What Large Language Models Know and What People Think They Know 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.13835v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.13835v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mark Steyvers, Heliodoro Tejeda, Aakriti Kumar, Catarina Belem, Sheer Karny, Xinyue Hu, Lukas Mayer, Padhraic Smyth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As artificial intelligence (AI) systems, particularly large language models
(LLMs), become increasingly integrated into decision-making processes, the
ability to trust their outputs is crucial. To earn human trust, LLMs must be
well calibrated such that they can accurately assess and communicate the
likelihood of their predictions being correct. Whereas recent work has focused
on LLMs' internal confidence, less is understood about how effectively they
convey uncertainty to users. Here we explore the calibration gap, which refers
to the difference between human confidence in LLM-generated answers and the
models' actual confidence, and the discrimination gap, which reflects how well
humans and models can distinguish between correct and incorrect answers. Our
experiments with multiple-choice and short-answer questions reveal that users
tend to overestimate the accuracy of LLM responses when provided with default
explanations. Moreover, longer explanations increased user confidence, even
when the extra length did not improve answer accuracy. By adjusting LLM
explanations to better reflect the models' internal confidence, both the
calibration gap and the discrimination gap narrowed, significantly improving
user perception of LLM accuracy. These findings underscore the importance of
accurate uncertainty communication and highlight the effect of explanation
length in influencing user trust in AI-assisted decision-making environments.
Code and Data can be found at https://osf.io/y7pr6/ . Journal publication can
be found on Nature Machine Intelligence at
https://www.nature.com/articles/s42256-024-00976-7 .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 10 figures For the journal publication on Nature Machine
  Intelligence see https://www.nature.com/articles/s42256-024-00976-7 For the
  data and code see https://osf.io/y7pr6/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Hallucination is Inevitable: An Innate Limitation of Large Language
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.11817v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.11817v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziwei Xu, Sanjay Jain, Mohan Kankanhalli
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Hallucination has been widely recognized to be a significant drawback for
large language models (LLMs). There have been many works that attempt to reduce
the extent of hallucination. These efforts have mostly been empirical so far,
which cannot answer the fundamental question whether it can be completely
eliminated. In this paper, we formalize the problem and show that it is
impossible to eliminate hallucination in LLMs. Specifically, we define a formal
world where hallucination is defined as inconsistencies between a computable
LLM and a computable ground truth function. By employing results from learning
theory, we show that LLMs cannot learn all the computable functions and will
therefore inevitably hallucinate if used as general problem solvers. Since the
formal world is a part of the real world which is much more complicated,
hallucinations are also inevitable for real world LLMs. Furthermore, for real
world LLMs constrained by provable time complexity, we describe the
hallucination-prone tasks and empirically validate our claims. Finally, using
the formal world framework, we discuss the possible mechanisms and efficacies
of existing hallucination mitigators as well as the practical implications on
the safe deployment of LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Character<span class="highlight-title">GPT</span>: A Persona Reconstruction Framework for Role-Playing Agents <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.19778v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.19778v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jeiyoon Park, Chanjun Park, Heuiseok Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the recent introduction of Assistants API, it is expected that
document-based language models will be actively used in various domains,
especially Role-playing. However, a key challenge lies in utilizing
protagonist's persona: Assistants API often fails to achieve with its search
because the information extraction part is different each time and it often
omits important information such as protagonist's backstory or relationships.
It is hard to maintain a consistent persona simply by using the persona
document as input to the Assistants API. To address the challenge of achieving
stable persona consistency, we propose CharacterGPT, a novel persona
reconstruction framework to alleviate the shortcomings of the Assistants API.
Our method involves Character Persona Training (CPT), an effective persona
rebuilding process that updates the character persona by extracting the
character's traits from given summary of the novel for each character as if the
story in a novel progresses. In our experiments, we ask each character to take
the Big Five Inventory personality test in various settings and analyze the
results. To assess whether it can think outside the box, we let each character
generate short novels. Extensive experiments and human evaluation demonstrate
that CharacterGPT presents new possibilities for role-playing agent research.
Code and results are available at: https://github.com/Jeiyoon/charactergpt
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025 Industry Track (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bridging Internal Probability and Self-Consistency for Effective and
  Efficient LLM Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00511v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00511v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhi Zhou, Tan Yuhao, Zenan Li, Yuan Yao, Lan-Zhe Guo, Xiaoxing Ma, Yu-Feng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have demonstrated
remarkable reasoning capabilities. However, single-shot inference often yields
unreliable results for complex reasoning tasks, leading researchers to explore
multiple reasoning paths through methods such as perplexity and
self-consistency. In this paper, we present the first theoretical error
decomposition analysis of these techniques, breaking down their error into
estimation error and model error. Our analysis reveals a fundamental trade-off:
perplexity methods suffer from substantial model error due to the absence of a
proper consistency function, while self-consistency exhibits high estimation
error due to a slow error convergence rate. To overcome these limitations, we
propose Reasoning-Pruning Perplexity Consistency (RPC). This approach combines
Perplexity Consistency, which seamlessly integrates LLM perplexity with
self-consistency, and Reasoning Pruning, which eliminates low-probability
reasoning paths to effectively prevent the degeneration of estimation error
reduction. Theoretical analysis demonstrates that RPC not only accelerates the
convergence rate of estimation error to an exponential level but also holds
strong potential for further reducing model error. Extensive empirical
evaluations on seven benchmark datasets confirm that RPC can significantly
improve reasoning performance, sample efficiency, and confidence reliability.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preliminary work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building
  a Chinese-Centric LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06635v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06635v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingshui Gu, Shu Li, Tianyu Zheng, Zhaoxiang Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Steel-LLM is a Chinese-centric language model developed from scratch with the
goal of creating a high-quality, open-source model despite limited
computational resources. Launched in March 2024, the project aimed to train a
1-billion-parameter model on a large-scale dataset, prioritizing transparency
and the sharing of practical insights to assist others in the community. The
training process primarily focused on Chinese data, with a small proportion of
English data included, addressing gaps in existing open-source LLMs by
providing a more detailed and practical account of the model-building journey.
Steel-LLM has demonstrated competitive performance on benchmarks such as CEVAL
and CMMLU, outperforming early models from larger institutions. This paper
provides a comprehensive summary of the project's key contributions, including
data collection, model design, training methodologies, and the challenges
encountered along the way, offering a valuable resource for researchers and
practitioners looking to develop their own LLMs. The model checkpoints and
training script are available at https://github.com/zhanshijinwat/Steel-LLM.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement
  for Personalized Implicit Emotion Analysis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07367v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07367v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, Jianxing Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The subtlety of emotional expressions makes implicit emotion analysis (IEA)
particularly sensitive to user-specific characteristics. Current studies
personalize emotion analysis by focusing on the author but neglect the impact
of the intended reader on implicit emotional feedback. In this paper, we
introduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses
subjective variability by incorporating reader feedback. In particular, (1) we
create reader agents based on large language models to simulate reader
feedback, overcoming the issue of ``spiral of silence effect'' and data
incompleteness of real reader reaction. (2) We develop a role-aware multi-view
graph learning to model the emotion interactive propagation process in
scenarios with sparse reader information. (3) We construct two new PIEA
datasets covering English and Chinese social media with detailed user metadata,
addressing the text-centric limitation of existing datasets. Extensive
experiments show that RAPPIE significantly outperforms state-of-the-art
baselines, demonstrating the value of incorporating reader feedback in PIEA.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Loss Landscape Degeneracy Drives Stagewise Development in <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.02364v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.02364v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jesse Hoogland, George Wang, Matthew Farrugia-Roberts, Liam Carroll, Susan Wei, Daniel Murfet
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning involves navigating a high-dimensional loss landscape over the
neural network parameter space. Over the course of training, complex
computational structures form and re-form inside the neural network, leading to
shifts in input/output behavior. It is a priority for the science of deep
learning to uncover principles governing the development of neural network
structure and behavior. Drawing on the framework of singular learning theory,
we propose that model development is deeply linked to degeneracy in the local
geometry of the loss landscape. We investigate this link by monitoring loss
landscape degeneracy throughout training, as quantified by the local learning
coefficient, for a transformer language model and an in-context linear
regression transformer. We show that training can be divided into distinct
periods of change in loss landscape degeneracy, and that these changes in
degeneracy coincide with significant changes in the internal computational
structure and the input/output behavior of the transformers. This finding
underscores the potential of a degeneracy-based perspective for understanding
modern deep learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Material on essential dynamics from v1 of this preprint has been
  removed from v2 and developed in arXiv:2501.17745</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Law<span class="highlight-title">GPT</span>: Knowledge-Guided Data Generation and Its Application to Legal
  LLM 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06572v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06572v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhi Zhou, Kun-Yang Yu, Shi-Yu Tian, Xiao-Wen Yang, Jiang-Xin Shi, Pengxiao Song, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs), both proprietary and open-source, have
demonstrated remarkable capabilities across various natural language processing
tasks. However, they face significant limitations in legal reasoning tasks.
Proprietary models introduce data privacy risks and high inference costs, while
open-source models underperform due to insufficient legal domain training data.
To address these limitations, we study data generation for legal reasoning to
improve the legal reasoning performance of open-source LLMs with the help of
proprietary LLMs. This is challenging due to the lack of legal knowledge in
proprietary LLMs and the difficulty in verifying the generated data. We propose
KgDG, a knowledge-guided data generation framework for legal reasoning. Our
framework enables leveraging legal knowledge to enhance generation diversity
and introduces a refinement and verification process to ensure the quality of
generated data. Moreover, we expand the generated dataset to further enhance
the LLM reasoning capabilities. Using KgDG, we create a synthetic legal
reasoning dataset containing 50K high-quality examples. Our trained model
LawGPT outperforms existing legal-specific LLMs and achieves performance
comparable to proprietary LLMs, demonstrating the effectiveness of KgDG and
LawGPT. Our code and resources is publicly available at
https://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ How Does Knowledge Selection Help Retrieval Augmented Generation? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13258v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13258v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangci Li, Jessica Ouyang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is a powerful method for enhancing
natural language generation by integrating external knowledge into a model's
output. While prior work has demonstrated the importance of improving knowledge
retrieval for boosting generation quality, the role of knowledge selection
remains less clear. In this paper, we perform a comprehensive analysis of how
knowledge selection influences downstream generation performance in RAG
systems. By simulating different retrieval and selection conditions through a
controlled mixture of gold and distractor knowledge, we assess the impact of
these factors on generation outcomes. Our findings indicate that the downstream
generator model's capability, as well as the complexity of the task and
dataset, significantly influence the impact of knowledge selection on the
overall RAG system performance. In typical scenarios, improving the knowledge
recall score is key to enhancing generation outcomes, with the knowledge
selector providing a limited additional benefit when a strong generator model
is used on clear, well-defined tasks. For weaker generator models or more
ambiguous tasks and datasets, the knowledge F1 score becomes a critical factor,
and the knowledge selector plays a more prominent role in improving overall
performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mix Data or Merge Models? Balancing the Helpfulness, Honesty, and
  Harmlessness of Large Language Model via Model Merging 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06876v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06876v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinluan Yang, Dingnan Jin, Anke Tang, Li Shen, Didi Zhu, Zhengyu Chen, Daixin Wang, Qing Cui, Zhiqiang Zhang, Jun Zhou, Fei Wu, Kun Kuang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Achieving balanced alignment of large language models (LLMs) in terms of
Helpfulness, Honesty, and Harmlessness (3H optimization) constitutes a
cornerstone of responsible AI, with existing methods like data mixture
strategies facing limitations including reliance on expert knowledge and
conflicting optimization signals. While model merging offers a promising
alternative by integrating specialized models, its potential for 3H
optimization remains underexplored. This paper establishes the first
comprehensive benchmark for model merging in 3H-aligned LLMs, systematically
evaluating 15 methods (12 training-free merging and 3 data mixture techniques)
across 10 datasets associated with 5 annotation dimensions, 2 LLM families, and
2 training paradigms. Our analysis reveals three pivotal insights: (i)
previously overlooked collaborative/conflicting relationships among 3H
dimensions, (ii) the consistent superiority of model merging over data mixture
approaches in balancing alignment trade-offs, and (iii) the critical role of
parameter-level conflict resolution through redundant component pruning and
outlier mitigation. Building on these findings, we propose R-TSVM, a
Reweighting-enhanced Task Singular Vector Merging method that incorporates
outlier-aware parameter weighting and sparsity-adaptive rank selection
strategies adapted to the heavy-tailed parameter distribution and sparsity for
LLMs, further improving LLM alignment across multiple evaluations. We release
our trained models for further exploration.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LegalViz: Legal Text Visualization by Text To Diagram Generation <span class="chip">NAACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06147v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06147v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eri Onami, Taiki Miyanishi, Koki Maeda, Shuhei Kurita
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Legal documents including judgments and court orders require highly
sophisticated legal knowledge for understanding. To disclose expert knowledge
for non-experts, we explore the problem of visualizing legal texts with
easy-to-understand diagrams and propose a novel dataset of LegalViz with 23
languages and 7,010 cases of legal document and visualization pairs, using the
DOT graph description language of Graphviz. LegalViz provides a simple diagram
from a complicated legal corpus identifying legal entities, transactions, legal
sources, and statements at a glance, that are essential in each judgment. In
addition, we provide new evaluation metrics for the legal diagram visualization
by considering graph structures, textual similarities, and legal contents. We
conducted empirical studies on few-shot and finetuning large language models
for generating legal diagrams and evaluated them with these metrics, including
legal content-based evaluation within 23 languages. Models trained with
LegalViz outperform existing models including GPTs, confirming the
effectiveness of our dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Low-Resource Sequence Labeling with Knowledge Fusion and
  Contextual Label Explanations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.19093v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.19093v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peichao Lai, Jiaxin Gan, Feiyang Ye, Yilei Wang, Bin Cui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequence labeling remains a significant challenge in low-resource,
domain-specific scenarios, particularly for character-dense languages like
Chinese. Existing methods primarily focus on enhancing model comprehension and
improving data diversity to boost performance. However, these approaches still
struggle with inadequate model applicability and semantic distribution biases
in domain-specific contexts. To overcome these limitations, we propose a novel
framework that combines an LLM-based knowledge enhancement workflow with a
span-based Knowledge Fusion for Rich and Efficient Extraction (KnowFREE) model.
Our workflow employs explanation prompts to generate precise contextual
interpretations of target entities, effectively mitigating semantic biases and
enriching the model's contextual understanding. The KnowFREE model further
integrates extension label features, enabling efficient nested entity
extraction without relying on external knowledge during inference. Experiments
on multiple Chinese domain-specific sequence labeling datasets demonstrate that
our approach achieves state-of-the-art performance, effectively addressing the
challenges posed by low-resource settings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Analyzing Similarity Metrics for Data Selection for Language Model
  <span class="highlight-title">Pretrain</span>ing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02494v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02494v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dylan Sam, Ayan Chakrabarti, Afshin Rostamizadeh, Srikumar Ramalingam, Gui Citovsky, Sanjiv Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Similarity between training examples is used to curate pretraining datasets
for language models by many methods -- for diversification and to select
examples similar to high-quality data. However, similarity is typically
measured with off-the-shelf embedding models that are generic or trained for
tasks such as retrieval. This paper introduces a framework to analyze the
suitability of embedding models specifically for data curation in the language
model pretraining setting. We quantify the correlation between similarity in
the embedding space to similarity in pretraining loss between different
training examples, and how diversifying in the embedding space affects
pretraining quality. We analyze a variety of embedding models in our framework,
with experiments using the Pile dataset for pretraining a 1.7B parameter
decoder-only language model. We find that the embedding models we consider are
all useful for pretraining data curation. Moreover, a simple approach of
averaging per-token embeddings proves to be surprisingly competitive with more
sophisticated embedding models -- likely because the latter are not designed
specifically for pretraining data curation. Indeed, we believe our analysis and
evaluation framework can serve as a foundation for the design of embedding
models that specifically reason about similarity in pretraining datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Using Contextually Aligned Online <span class="highlight-title">Review</span>s to Measure LLMs' Performance
  Disparities Across Language Varieties <span class="chip">NAACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07058v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07058v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zixin Tang, Chieh-Yang Huang, Tsung-Chi Li, Ho Yin Sam Ng, Hen-Hsen Huang, Ting-Hao 'Kenneth' Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A language can have different varieties. These varieties can affect the
performance of natural language processing (NLP) models, including large
language models (LLMs), which are often trained on data from widely spoken
varieties. This paper introduces a novel and cost-effective approach to
benchmark model performance across language varieties. We argue that
international online review platforms, such as Booking.com, can serve as
effective data sources for constructing datasets that capture comments in
different language varieties from similar real-world scenarios, like reviews
for the same hotel with the same rating using the same language (e.g., Mandarin
Chinese) but different language varieties (e.g., Taiwan Mandarin, Mainland
Mandarin). To prove this concept, we constructed a contextually aligned dataset
comprising reviews in Taiwan Mandarin and Mainland Mandarin and tested six LLMs
in a sentiment analysis task. Our results show that LLMs consistently
underperform in Taiwan Mandarin.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by 2025 Annual Conference of the Nations of the Americas
  Chapter of the Association for Computational Linguistics (NAACL), theme track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for
  Entity Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2307.02075v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2307.02075v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qijie Ding, Jie Yin, Daokun Zhang, Junbin Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity alignment (EA) aims at identifying equivalent entity pairs across
different knowledge graphs (KGs) that refer to the same real-world identity. To
systematically combat confirmation bias for pseudo-labeling-based entity
alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment
(UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the
accuracy of entity alignment. UPL-EA consists of two complementary components:
(1) The Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling
as an effective means to enable more accurate determination of entity
correspondences across two KGs and to mitigate the adverse impact of erroneous
matches. A simple but highly effective criterion is further devised to derive
pseudo-labeled entity pairs that satisfy one-to-one correspondences at each
iteration. (2) The cross-iteration pseudo-label calibration operates across
multiple consecutive iterations to further improve the pseudo-labeling
precision rate by reducing the local pseudo-label selection variability with a
theoretical guarantee. The two components are respectively designed to
eliminate Type I and Type II pseudo-labeling errors identified through our
analyse. The calibrated pseudo-labels are thereafter used to augment prior
alignment seeds to reinforce subsequent model training for alignment inference.
The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both
theoretically supported and experimentally validated. The experimental results
show that our approach achieves competitive performance with limited prior
alignment seeds.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FineMedLM-o1: Enhancing the Medical Reasoning Ability of LLM from
  Supervised Fine-Tuning to Test-Time Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.09213v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.09213v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongzhou Yu, Tianhao Cheng, Ying Cheng, Rui Feng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in large language models (LLMs) have shown promise in
medical applications such as disease diagnosis and treatment planning. However,
most existing medical LLMs struggle with the advanced reasoning required for
complex clinical scenarios, such as differential diagnosis or personalized
treatment suggestions. We proposed FineMedLM-o1, which leverages high-quality
synthetic medical data and long-form reasoning data for Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO), enabling advanced dialogue and
deep reasoning capabilities. Additionally, we introduced Test-Time Training
(TTT) in the medical domain for the first time, facilitating domain adaptation
and ensuring reliable, accurate reasoning. Experimental results demonstrate
that FineMedLM-o1 achieves a 23% average performance improvement over prior
models on key medical benchmarks. Furthermore, the introduction of TTT provides
an additional 14% performance boost, highlighting its effectiveness in
enhancing medical reasoning capabilities. To support this process, we also
proposed a novel method for synthesizing medical dialogue. Compared to other
open-source datasets, our dataset stands out as superior in both quality and
complexity. The project and data will be released on GitHub.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Cognitive Evaluation Benchmark of Image Reasoning and Description for
  Large Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.18409v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.18409v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiujie Song, Mengyue Wu, Kenny Q. Zhu, Chunhao Zhang, Yanyi Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Vision-Language Models (LVLMs), despite their recent success, are
hardly comprehensively tested for their cognitive abilities. Inspired by the
prevalent use of the Cookie Theft task in human cognitive tests, we propose a
novel evaluation benchmark to evaluate high-level cognitive abilities of LVLMs
using images with rich semantics. The benchmark consists of 251 images along
with comprehensive annotations. It defines eight reasoning capabilities and
comprises an image description task and a visual question answering task. Our
evaluation of well-known LVLMs shows that there is still a significant gap in
cognitive abilities between LVLMs and humans.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VaiBot: Shuttle Between the Instructions and Parameters of Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02315v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02315v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wangtao Sun, Haotian Xu, Huanxuan Liao, Xuanqing Yu, Zhongtao Jiang, Shizhu He, Jun Zhao, Kang Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How to interact with LLMs through \emph{instructions} has been widely studied
by researchers. However, previous studies have treated the emergence of
instructions and the training of LLMs on task data as separate processes,
overlooking the inherent unity between the two. This paper proposes a neural
network framework, VaiBot, that integrates VAE and VIB, designed to uniformly
model, learn, and infer both deduction and induction tasks under LLMs. Through
experiments, we demonstrate that VaiBot performs on par with existing baseline
methods in terms of deductive capabilities while significantly surpassing them
in inductive capabilities. We also find that VaiBot can scale up using general
instruction-following data and exhibits excellent one-shot induction abilities.
We finally synergistically integrate the deductive and inductive processes of
VaiBot. Through T-SNE dimensionality reduction, we observe that its
inductive-deductive process significantly improves the distribution of training
parameters, enabling it to outperform baseline methods in inductive reasoning
tasks. The code and data for this paper can be found at
https://anonymous.4open.science/r/VaiBot-021F.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text
  Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02844v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02844v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubo Wang, Haoyang Li, Fei Teng, Lei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text classification is a fundamental task in data mining, pivotal to various
applications such as tabular understanding and recommendation. Although neural
network-based models, such as CNN and BERT, have demonstrated remarkable
performance in text classification, their effectiveness heavily relies on
abundant labeled training data. This dependency makes these models less
effective in dynamic few-shot text classification, where labeled data is
scarce, and new target labels frequently appear based on application needs.
Recently, large language models (LLMs) have shown promise due to their
extensive pretraining and contextual understanding ability. Current approaches
provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to classify texts. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. Rather than treating each input
independently, GORAG constructs and maintains a weighted graph by extracting
side information across all target texts. In this graph, text keywords and
labels are represented as nodes, with edges indicating the correlations between
them. To model these correlations, GORAG employs an edge weighting mechanism to
prioritize the importance and reliability of extracted information and
dynamically retrieves relevant context using a minimum-cost spanning tree
tailored for each text input. Empirical evaluations demonstrate that GORAG
outperforms existing approaches by providing more comprehensive and precise
contextual information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training Sparse Mixture Of Experts Text Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07972v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07972v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zach Nussbaum, Brandon Duderstadt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based text embedding models have improved their performance on
benchmarks like MIRACL and BEIR by increasing their parameter counts. However,
this scaling approach introduces significant deployment challenges, including
increased inference latency and memory usage. These challenges are particularly
severe in retrieval-augmented generation (RAG) applications, where large
models' increased memory requirements constrain dataset ingestion capacity, and
their higher latency directly impacts query-time performance. While causal
language models have addressed similar efficiency challenges using Mixture of
Experts (MoE) architectures, this approach hasn't been successfully adapted to
the general text embedding setting. In this paper, we introduce Nomic Embed v2,
the first general purpose MoE text embedding model. Our model outperforms
models in the same parameter class on both monolingual and multilingual
benchmarks while also maintaining competitive performance with models twice its
size. We open-source all code, models, and evaluation data to ensure full
reproducibility of our training pipeline at
\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Computer Vision and Pattern Recognition <span class="chip" style="font-size: 60%">1</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF
  Architectures 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09623v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09623v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for
representing 3D objects and scenes by encoding shape and appearance information
into the weights of a neural network. Recent works have shown how such weights
can be used as input to frameworks processing them to solve deep learning
tasks. Yet, these frameworks can only process NeRFs with a specific, predefined
architecture. In this paper, we present the first framework that can ingest
NeRFs with multiple architectures and perform inference on architectures unseen
at training time. We achieve this goal by training a Graph Meta-Network in a
representation learning framework. Moreover, we show how a contrastive
objective is conducive to obtaining an architecture-agnostic latent space. In
experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates
robust performance in classification and retrieval tasks that either matches or
exceeds that of existing frameworks constrained to single architectures, thus
providing the first architecture-agnostic method to perform tasks on NeRFs by
processing their weights.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">17</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FARM: Frequency-Aware Model for Cross-Domain Live-Streaming
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09375v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09375v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaodong Li, Ruochen Yang, Shuang Wen, Shen Wang, Yueyang Liu, Guoquan Wang, Weisong Hu, Qiang Luo, Jiawei Sheng, Tingwen Liu, Jiangxia Cao, Shuang Yang, Zhaojie Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Live-streaming services have attracted widespread popularity due to their
real-time interactivity and entertainment value. Users can engage with
live-streaming authors by participating in live chats, posting likes, or
sending virtual gifts to convey their preferences and support. However, the
live-streaming services faces serious data-sparsity problem, which can be
attributed to the following two points: (1) User's valuable behaviors are
usually sparse, e.g., like, comment and gift, which are easily overlooked by
the model, making it difficult to describe user's personalized preference. (2)
The main exposure content on our platform is short-video, which is 9 times
higher than the exposed live-streaming, leading to the inability of
live-streaming content to fully model user preference. To this end, we propose
a Frequency-Aware Model for Cross-Domain Live-Streaming Recommendation, termed
as FARM. Specifically, we first present the intra-domain frequency aware module
to enable our model to perceive user's sparse yet valuable behaviors, i.e.,
high-frequency information, supported by the Discrete Fourier Transform (DFT).
To transfer user preference across the short-video and live-streaming domains,
we propose a novel preference align before fuse strategy, which consists of two
parts: the cross-domain preference align module to align user preference in
both domains with contrastive learning, and the cross-domain preference fuse
module to further fuse user preference in both domains using a serious of
tailor-designed attention mechanisms. Extensive offline experiments and online
A/B testing on Kuaishou live-streaming services demonstrate the effectiveness
and superiority of FARM. Our FARM has been deployed in online live-streaming
services and currently serves hundreds of millions of users on Kuaishou.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Jensen Gap for Max-Min Group Fairness Optimization in
  Recommendation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Xu, Yuxin Li, Wenjie Wang, Liang Pang, Jun Xu, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group max-min fairness (MMF) is commonly used in fairness-aware recommender
systems (RS) as an optimization objective, as it aims to protect marginalized
item groups and ensures a fair competition platform. However, our theoretical
analysis indicates that integrating MMF constraint violates the assumption of
sample independence during optimization, causing the loss function to deviate
from linear additivity. Such nonlinearity property introduces the Jensen gap
between the model's convergence point and the optimal point if mini-batch
sampling is applied. Both theoretical and empirical studies show that as the
mini-batch size decreases and the group size increases, the Jensen gap will
widen accordingly. Some methods using heuristic re-weighting or debiasing
strategies have the potential to bridge the Jensen gap. However, they either
lack theoretical guarantees or suffer from heavy computational costs. To
overcome these limitations, we first theoretically demonstrate that the
MMF-constrained objective can be essentially reformulated as a group-weighted
optimization objective. Then we present an efficient and effective algorithm
named FairDual, which utilizes a dual optimization technique to minimize the
Jensen gap. Our theoretical analysis demonstrates that FairDual can achieve a
sub-linear convergence rate to the globally optimal solution and the Jensen gap
can be well bounded under a mini-batch sampling strategy with random shuffle.
Extensive experiments conducted using six large-scale RS backbone models on
three publicly available datasets demonstrate that FairDual outperforms all
baselines in terms of both accuracy and fairness. Our data and codes are shared
at https://github.com/XuChen0427/FairDual.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for
  Graph-RAG 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09304v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09304v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqian Huang, Shiqi Zhang, Xiaokui Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph-RAG constructs a knowledge graph from text chunks to improve retrieval
in Large Language Model (LLM)-based question answering. It is particularly
useful in domains such as biomedicine, law, and political science, where
retrieval often requires multi-hop reasoning over proprietary documents. Some
existing Graph-RAG systems construct KNN graphs based on text chunk relevance,
but this coarse-grained approach fails to capture entity relationships within
texts, leading to sub-par retrieval and generation quality. To address this,
recent solutions leverage LLMs to extract entities and relationships from text
chunks, constructing triplet-based knowledge graphs. However, this approach
incurs significant indexing costs, especially for large document collections.
  To ensure a good result accuracy while reducing the indexing cost, we propose
KET-RAG, a multi-granular indexing framework. KET-RAG first identifies a small
set of key text chunks and leverages an LLM to construct a knowledge graph
skeleton. It then builds a text-keyword bipartite graph from all text chunks,
serving as a lightweight alternative to a full knowledge graph. During
retrieval, KET-RAG searches both structures: it follows the local search
strategy of existing Graph-RAG systems on the skeleton while mimicking this
search on the bipartite graph to improve retrieval quality. We evaluate eight
solutions on two real-world datasets, demonstrating that KET-RAG outperforms
all competitors in indexing cost, retrieval effectiveness, and generation
quality. Notably, it achieves comparable or superior retrieval quality to
Microsoft's Graph-RAG while reducing indexing costs by over an order of
magnitude. Additionally, it improves the generation quality by up to 32.4%
while lowering indexing costs by around 20%.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Use of Air Quality Sensor Network Data for Real-time Pollution-Aware POI
  Suggestion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09155v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09155v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giuseppe Fasano, Yashar Deldjoo, Tommaso di Noia, Bianca Lau, Sina Adham-Khiabani, Eric Morris, Xia Liu, Ganga Chinna Rao Devarapu, Liam O'Faolain
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This demo paper presents AirSense-R, a privacy-preserving mobile application
that provides real-time, pollution-aware recommendations for points of interest
(POIs) in urban environments. By combining real-time air quality monitoring
data with user preferences, the proposed system aims to help users make
health-conscious decisions about the locations they visit. The application
utilizes collaborative filtering for personalized suggestions, and federated
learning for privacy protection, and integrates air pollutant readings from
AirSENCE sensor networks in cities such as Bari, Italy, and Cork, Ireland.
Additionally, the AirSENCE prediction engine can be employed to detect anomaly
readings and interpolate for air quality readings in areas with sparse sensor
coverage. This system offers a promising, health-oriented POI recommendation
solution that adapts dynamically to current urban air quality conditions while
safeguarding user privacy. The code of AirTOWN and a demonstration video is
made available at the following repo:
https://github.com/AirtownApp/Airtown-Application.git.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic Ads Retrieval at Walmart eCommerce with Language Models
  Progressively Trained on Multiple Knowledge Domains 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09089v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09089v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaodong Wang, Weizhi Du, Md Omar Faruk Rokon, Pooshpendu Adhikary, Yanbing Xue, Jiaxuan Xu, Jianghong Zhou, Kuang-chih Lee, Musen Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sponsored search in e-commerce poses several unique and complex challenges.
These challenges stem from factors such as the asymmetric language structure
between search queries and product names, the inherent ambiguity in user search
intent, and the vast volume of sparse and imbalanced search corpus data. The
role of the retrieval component within a sponsored search system is pivotal,
serving as the initial step that directly affects the subsequent ranking and
bidding systems. In this paper, we present an end-to-end solution tailored to
optimize the ads retrieval system on Walmart.com. Our approach is to pretrain
the BERT-like classification model with product category information, enhancing
the model's understanding of Walmart product semantics. Second, we design a
two-tower Siamese Network structure for embedding structures to augment
training efficiency. Third, we introduce a Human-in-the-loop Progressive Fusion
Training method to ensure robust model performance. Our results demonstrate the
effectiveness of this pipeline. It enhances the search relevance metric by up
to 16% compared to a baseline DSSM-based model. Moreover, our large-scale
online A/B testing demonstrates that our approach surpasses the ad revenue of
the existing production model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unleashing the Power of Large Language Model for Denoising
  Recommendation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09058v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09058v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuyao Wang, Zhi Zheng, Yongduo Sui, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems are crucial for personalizing user experiences but often
depend on implicit feedback data, which can be noisy and misleading. Existing
denoising studies involve incorporating auxiliary information or learning
strategies from interaction data. However, they struggle with the inherent
limitations of external knowledge and interaction data, as well as the
non-universality of certain predefined assumptions, hindering accurate noise
identification. Recently, large language models (LLMs) have gained attention
for their extensive world knowledge and reasoning abilities, yet their
potential in enhancing denoising in recommendations remains underexplored. In
this paper, we introduce LLaRD, a framework leveraging LLMs to improve
denoising in recommender systems, thereby boosting overall recommendation
performance. Specifically, LLaRD generates denoising-related knowledge by first
enriching semantic insights from observational data via LLMs and inferring
user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT)
technique over user-item interaction graphs to reveal relation knowledge for
denoising. Finally, it applies the Information Bottleneck (IB) principle to
align LLM-generated denoising knowledge with recommendation targets, filtering
out noise and irrelevant LLM knowledge. Empirical results demonstrate LLaRD's
effectiveness in enhancing denoising and recommendation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 5 figures, 4 tables. Accecpted by WWW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Leveraging Member-Group Relations via Multi-View Graph Filtering for
  Effective Group Recommendation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09050v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09050v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chae-Hyun Kim, Yoon-Ryung Choi, Jin-Duk Park, Won-Yong Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group recommendation aims at providing optimized recommendations tailored to
diverse groups, enabling groups to enjoy appropriate items. On the other hand,
most existing group recommendation methods are built upon deep neural network
(DNN) architectures designed to capture the intricate relationships between
member-level and group-level interactions. While these DNN-based approaches
have proven their effectiveness, they require complex and expensive training
procedures to incorporate group-level interactions in addition to member-level
interactions. To overcome such limitations, we introduce Group-GF, a new
approach for extremely fast recommendations of items to each group via
multi-view graph filtering (GF) that offers a holistic view of complex
member-group dynamics, without the need for costly model training.
Specifically, in Group-GF, we first construct three item similarity graphs
manifesting different viewpoints for GF. Then, we discover a distinct
polynomial graph filter for each similarity graph and judiciously aggregate the
three graph filters. Extensive experiments demonstrate the effectiveness of
Group-GF in terms of significantly reducing runtime and achieving
state-of-the-art recommendation accuracy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>5 pages, 3 figures, 4 tables; ACM Web Conference (WWW 2025) (to
  appear) (Please cite our conference version.)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate
  Multi-Criteria Recommendation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09046v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09046v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin-Duk Park, Jaemin Yoo, Won-Yong Shin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-criteria (MC) recommender systems, which utilize MC rating information
for recommendation, are increasingly widespread in various e-commerce domains.
However, the MC recommendation using training-based collaborative filtering,
requiring consideration of multiple ratings compared to single-criterion
counterparts, often poses practical challenges in achieving state-of-the-art
performance along with scalable model training. To solve this problem, we
propose CA-GF, a training-free MC recommendation method, which is built upon
criteria-aware graph filtering for efficient yet accurate MC recommendations.
Specifically, first, we construct an item-item similarity graph using an MC
user-expansion graph. Next, we design CA-GF composed of the following key
components, including 1) criterion-specific graph filtering where the optimal
filter for each criterion is found using various types of polynomial low-pass
filters and 2) criteria preference-infused aggregation where the smoothed
signals from each criterion are aggregated. We demonstrate that CA-GF is (a)
efficient: providing the computational efficiency, offering the extremely fast
runtime of less than 0.2 seconds even on the largest benchmark dataset, (b)
accurate: outperforming benchmark MC recommendation methods, achieving
substantial accuracy gains up to 24% compared to the best competitor, and (c)
interpretable: providing interpretations for the contribution of each criterion
to the model prediction based on visualizations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 8 figures, 7 tables; ACM Web Conference (WWW 2025) (to
  appear) (Please cite our conference version.)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Contextual-Aware Position Encoding for Sequential Recommendation <span class="chip">WWW'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09027v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09027v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yuan, Guohao Cai, Zhenhua Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation (SR), which encodes user activity to predict the
next action, has emerged as a widely adopted strategy in developing commercial
personalized recommendation systems. A critical component of modern SR models
is the attention mechanism, which synthesizes users' historical activities.
This mechanism is typically order-invariant and generally relies on position
encoding (PE). Conventional SR models simply assign a learnable vector to each
position, resulting in only modest gains compared to traditional recommendation
models. Moreover, limited research has been conducted on position encoding
tailored for sequential recommendation, leaving a significant gap in addressing
its unique requirements. To bridge this gap, we propose a novel
Contextual-Aware Position Encoding method for sequential recommendation,
abbreviated as CAPE. To the best of our knowledge, CAPE is the first PE method
specifically designed for sequential recommendation. Comprehensive experiments
conducted on benchmark SR datasets demonstrate that CAPE consistently enhances
multiple mainstream backbone models and achieves state-of-the-art performance,
across small and large scale model size. Furthermore, we deployed CAPE in an
industrial setting on a real-world commercial platform, clearly showcasing the
effectiveness of our approach. Our source code is available at
https://github.com/yjdy/CAPE.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW'25 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ABXI: Invariant Interest Adaptation for Task-Guided Cross-Domain
  Sequential Recommendation <span class="chip">WWW '25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15118v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15118v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qingtian Bian, Marcus Vinícius de Carvalho, Tieying Li, Jiaxing Xu, Hui Fang, Yiping Ke
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-Domain Sequential Recommendation (CDSR) has recently gained attention
for countering data sparsity by transferring knowledge across domains. A common
approach merges domain-specific sequences into cross-domain sequences, serving
as bridges to connect domains. One key challenge is to correctly extract the
shared knowledge among these sequences and appropriately transfer it. Most
existing works directly transfer unfiltered cross-domain knowledge rather than
extracting domain-invariant components and adaptively integrating them into
domain-specific modelings. Another challenge lies in aligning the
domain-specific and cross-domain sequences. Existing methods align these
sequences based on timestamps, but this approach can cause prediction
mismatches when the current tokens and their targets belong to different
domains. In such cases, the domain-specific knowledge carried by the current
tokens may degrade performance. To address these challenges, we propose the
A-B-Cross-to-Invariant Learning Recommender (ABXI). Specifically, leveraging
LoRA's effectiveness for efficient adaptation, ABXI incorporates two types of
LoRAs to facilitate knowledge adaptation. First, all sequences are processed
through a shared encoder that employs a domain LoRA for each sequence, thereby
preserving unique domain characteristics. Next, we introduce an invariant
projector that extracts domain-invariant interests from cross-domain
representations, utilizing an invariant LoRA to adapt these interests into
modeling each specific domain. Besides, to avoid prediction mismatches, all
domain-specific sequences are aligned to match the domains of the cross-domain
ground truths. Experimental results on three datasets demonstrate that our
approach outperforms other CDSR counterparts by a large margin. The codes are
available in https://github.com/DiMarzioBian/ABXI.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WebConf '25 (WWW '25)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Agent-OM: Leveraging LLM Agents for Ontology Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2312.00326v9">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2312.00326v9.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhangcheng Qiang, Weiqing Wang, Kerry Taylor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ontology matching (OM) enables semantic interoperability between different
ontologies and resolves their conceptual heterogeneity by aligning related
entities. OM systems currently have two prevailing design paradigms:
conventional knowledge-based expert systems and newer machine learning-based
predictive systems. While large language models (LLMs) and LLM agents have
revolutionised data engineering and have been applied creatively in many
domains, their potential for OM remains underexplored. This study introduces a
novel agent-powered LLM-based design paradigm for OM systems. With
consideration of several specific challenges in leveraging LLM agents for OM,
we propose a generic framework, namely Agent-OM (Agent for Ontology Matching),
consisting of two Siamese agents for retrieval and matching, with a set of OM
tools. Our framework is implemented in a proof-of-concept system. Evaluations
of three Ontology Alignment Evaluation Initiative (OAEI) tracks over
state-of-the-art OM systems show that our system can achieve results very close
to the long-standing best performance on simple OM tasks and can significantly
improve the performance on complex and few-shot OM tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 12 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RaSeRec: Retrieval-Augmented Sequential Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.18378v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.18378v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinping Zhao, Baotian Hu, Yan Zhong, Shouzheng Huang, Zihao Zheng, Meng Wang, Haofen Wang, Min Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although prevailing supervised and self-supervised learning augmented
sequential recommendation (SeRec) models have achieved improved performance
with powerful neural network architectures, we argue that they still suffer
from two limitations: (1) Preference Drift, where models trained on past data
can hardly accommodate evolving user preference; and (2) Implicit Memory, where
head patterns dominate parametric learning, making it harder to recall long
tails. In this work, we explore retrieval augmentation in SeRec, to address
these limitations. Specifically, we propose a Retrieval-Augmented Sequential
Recommendation framework, named RaSeRec, the main idea of which is to maintain
a dynamic memory bank to accommodate preference drifts and retrieve relevant
memories to augment user modeling explicitly. It consists of two stages: (i)
collaborative-based pre-training, which learns to recommend and retrieve; (ii)
retrieval-augmented fine-tuning, which learns to leverage retrieved memories.
Extensive experiments on three datasets fully demonstrate the superiority and
effectiveness of RaSeRec. The implementation code is available at
https://github.com/HITsz-TMG/RaSeRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages, 8 figures, 9 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ PeaPOD: Personalized <span class="highlight-title">Prompt</span> Distillation for Generative Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05033v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05033v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jerome Ramos, Bin Wu, Aldo Lipani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, researchers have investigated the capabilities of Large Language
Models (LLMs) for generative recommender systems. Existing LLM-based
recommender models are trained by adding user and item IDs to a discrete prompt
template. However, the disconnect between IDs and natural language makes it
difficult for the LLM to learn the relationship between users. To address this
issue, we propose a PErsonAlized PrOmpt Distillation (PeaPOD) approach, to
distill user preferences as personalized soft prompts. Considering the
complexities of user preferences in the real world, we maintain a shared set of
learnable prompts that are dynamically weighted based on the user's interests
to construct the user-personalized prompt in a compositional manner.
Experimental results on three real-world datasets demonstrate the effectiveness
of our PeaPOD model on sequential recommendation, top-n recommendation, and
explanation generation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion Model for Interest Refinement in Multi-Interest Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05561v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05561v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yankun Le, Haoran Li, Baoyuan Ou, Yingjie Qin, Zhixuan Yang, Ruilong Su, Fu Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-interest candidate matching plays a pivotal role in personalized
recommender systems, as it captures diverse user interests from their
historical behaviors. Most existing methods utilize attention mechanisms to
generate interest representations by aggregating historical item embeddings.
However, these methods only capture overall item-level relevance, leading to
coarse-grained interest representations that include irrelevant information. To
address this issue, we propose the Diffusion Multi-Interest model (DMI), a
novel framework for refining user interest representations at the dimension
level. Specifically, DMI first introduces controllable noise into
coarse-grained interest representations at the dimensional level. Then, in the
iterative reconstruction process, DMI combines a cross-attention mechanism and
an item pruning strategy to reconstruct the personalized interest vectors with
the guidance of tailored collaborative information. Extensive experiments
demonstrate the effectiveness of DMI, surpassing state-of-the-art methods on
offline evaluations and an online A/B test. Successfully deployed in the
real-world recommender system, DMI effectively enhances user satisfaction and
system performance at scale, serving the major traffic of hundreds of millions
of daily active users. \footnote{The code will be released for reproducibility
once the paper is accepted.}
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Interactive Visualization Recommendation with Hier-SUCB 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03375v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03375v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Songwen Hu, Ryan A. Rossi, Tong Yu, Junda Wu, Handong Zhao, Sungchul Kim, Shuai Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Visualization recommendation aims to enable rapid visual analysis of massive
datasets. In real-world scenarios, it is essential to quickly gather and
comprehend user preferences to cover users from diverse backgrounds, including
varying skill levels and analytical tasks. Previous approaches to personalized
visualization recommendations are non-interactive and rely on initial user data
for new users. As a result, these models cannot effectively explore options or
adapt to real-time feedback. To address this limitation, we propose an
interactive personalized visualization recommendation (PVisRec) system that
learns on user feedback from previous interactions. For more interactive and
accurate recommendations, we propose Hier-SUCB, a contextual combinatorial
semi-bandit in the PVisRec setting. Theoretically, we show an improved overall
regret bound with the same rank of time but an improved rank of action space.
We further demonstrate the effectiveness of Hier-SUCB through extensive
experiments where it is comparable to offline methods and outperforms other
bandit algorithms in the setting of visualization recommendation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text
  Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.02844v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.02844v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yubo Wang, Haoyang Li, Fei Teng, Lei Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text classification is a fundamental task in data mining, pivotal to various
applications such as tabular understanding and recommendation. Although neural
network-based models, such as CNN and BERT, have demonstrated remarkable
performance in text classification, their effectiveness heavily relies on
abundant labeled training data. This dependency makes these models less
effective in dynamic few-shot text classification, where labeled data is
scarce, and new target labels frequently appear based on application needs.
Recently, large language models (LLMs) have shown promise due to their
extensive pretraining and contextual understanding ability. Current approaches
provide LLMs with text inputs, candidate labels, and additional side
information (e.g., descriptions) to classify texts. However, their
effectiveness is hindered by the increased input size and the noise introduced
through side information processing. To address these limitations, we propose a
graph-based online retrieval-augmented generation framework, namely GORAG, for
dynamic few-shot text classification. Rather than treating each input
independently, GORAG constructs and maintains a weighted graph by extracting
side information across all target texts. In this graph, text keywords and
labels are represented as nodes, with edges indicating the correlations between
them. To model these correlations, GORAG employs an edge weighting mechanism to
prioritize the importance and reliability of extracted information and
dynamically retrieves relevant context using a minimum-cost spanning tree
tailored for each text input. Empirical evaluations demonstrate that GORAG
outperforms existing approaches by providing more comprehensive and precise
contextual information.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Training Sparse Mixture Of Experts Text Embedding Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07972v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07972v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zach Nussbaum, Brandon Duderstadt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer-based text embedding models have improved their performance on
benchmarks like MIRACL and BEIR by increasing their parameter counts. However,
this scaling approach introduces significant deployment challenges, including
increased inference latency and memory usage. These challenges are particularly
severe in retrieval-augmented generation (RAG) applications, where large
models' increased memory requirements constrain dataset ingestion capacity, and
their higher latency directly impacts query-time performance. While causal
language models have addressed similar efficiency challenges using Mixture of
Experts (MoE) architectures, this approach hasn't been successfully adapted to
the general text embedding setting. In this paper, we introduce Nomic Embed v2,
the first general purpose MoE text embedding model. Our model outperforms
models in the same parameter class on both monolingual and multilingual
benchmarks while also maintaining competitive performance with models twice its
size. We open-source all code, models, and evaluation data to ensure full
reproducibility of our training pipeline at
\href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Machine Learning <span class="chip" style="font-size: 60%">150</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Theoretical Benefit and Limitation of Diffusion Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09622v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09622v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guhao Feng, Yihan Geng, Jian Guan, Wei Wu, Liwei Wang, Di He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion language models have emerged as a promising approach for text
generation. One would naturally expect this method to be an efficient
replacement for autoregressive models since multiple tokens can be sampled in
parallel during each diffusion step. However, its efficiency-accuracy trade-off
is not yet well understood. In this paper, we present a rigorous theoretical
analysis of a widely used type of diffusion language model, the Masked
Diffusion Model (MDM), and find that its effectiveness heavily depends on the
target evaluation metric. Under mild conditions, we prove that when using
perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling
steps regardless of sequence length, demonstrating that efficiency can be
achieved without sacrificing performance. However, when using the sequence
error rate--which is important for understanding the "correctness" of a
sequence, such as a reasoning chain--we show that the required sampling steps
must scale linearly with sequence length to obtain "correct" sequences, thereby
eliminating MDM's efficiency advantage over autoregressive models. Our analysis
establishes the first theoretical foundation for understanding the benefits and
limitations of MDMs. All theoretical findings are supported by empirical
studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>32 pages, 3 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09619v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09619v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the increasing numbers of publicly available models, there are probably
pretrained, online models for most tasks users require. However, current model
search methods are rudimentary, essentially a text-based search in the
documentation, thus users cannot find the relevant models. This paper presents
ProbeLog, a method for retrieving classification models that can recognize a
target concept, such as "Dog", without access to model metadata or training
data. Differently from previous probing methods, ProbeLog computes a descriptor
for each output dimension (logit) of each model, by observing its responses on
a fixed set of inputs (probes). Our method supports both logit-based retrieval
("find more logits like this") and zero-shot, text-based retrieval ("find all
logits corresponding to dogs"). As probing-based representations require
multiple costly feedforward passes through the model, we develop a method,
based on collaborative filtering, that reduces the cost of encoding
repositories by 3x. We demonstrate that ProbeLog achieves high retrieval
accuracy, both in real-world and fine-grained search tasks and is scalable to
full-size repositories.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Variational Rectified Flow Matching 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pengsheng Guo, Alexander G. Schwing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study Variational Rectified Flow Matching, a framework that enhances
classic rectified flow matching by modeling multi-modal velocity vector-fields.
At inference time, classic rectified flow matching 'moves' samples from a
source distribution to the target distribution by solving an ordinary
differential equation via integration along a velocity vector-field. At
training time, the velocity vector-field is learnt by linearly interpolating
between coupled samples one drawn from the source and one drawn from the target
distribution randomly. This leads to ''ground-truth'' velocity vector-fields
that point in different directions at the same location, i.e., the velocity
vector-fields are multi-modal/ambiguous. However, since training uses a
standard mean-squared-error loss, the learnt velocity vector-field averages
''ground-truth'' directions and isn't multi-modal. In contrast, variational
rectified flow matching learns and samples from multi-modal flow directions. We
show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational
rectified flow matching leads to compelling results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DexTrack: Towards Generalizable Neural Tracking Control for Dexterous
  Manipulation from Human References <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09614v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09614v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the challenge of developing a generalizable neural tracking
controller for dexterous manipulation from human references. This controller
aims to manage a dexterous robot hand to manipulate diverse objects for various
purposes defined by kinematic human-object interactions. Developing such a
controller is complicated by the intricate contact dynamics of dexterous
manipulation and the need for adaptivity, generalizability, and robustness.
Current reinforcement learning and trajectory optimization methods often fall
short due to their dependence on task-specific rewards or precise system
models. We introduce an approach that curates large-scale successful robot
tracking demonstrations, comprising pairs of human references and robot
actions, to train a neural controller. Utilizing a data flywheel, we
iteratively enhance the controller's performance, as well as the number and
quality of successful tracking demonstrations. We exploit available tracking
demonstrations and carefully integrate reinforcement learning and imitation
learning to boost the controller's performance in dynamic environments. At the
same time, to obtain high-quality tracking demonstrations, we individually
optimize per-trajectory tracking by leveraging the learned tracking controller
in a homotopy optimization method. The homotopy optimization, mimicking
chain-of-thought, aids in solving challenging trajectory tracking problems to
increase demonstration diversity. We showcase our success by training a
generalizable neural controller and evaluating it in both simulation and real
world. Our method achieves over a 10% improvement in success rates compared to
leading baselines. The project website with animated results is available at
https://meowuu7.github.io/DexTrack/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICLR 2025. Website: https://meowuu7.github.io/DexTrack/
  Code: https://github.com/Meowuu7/DexTrack/ Video:
  https://youtu.be/zru1Z-DaiWE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Designing a Conditional Prior Distribution for Flow-Based Generative
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09611v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09611v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Noam Issachar, Mohammad Salama, Raanan Fattal, Sagie Benaim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Flow-based generative models have recently shown impressive performance for
conditional generation tasks, such as text-to-image generation. However,
current methods transform a general unimodal noise distribution to a specific
mode of the target data distribution. As such, every point in the initial
source distribution can be mapped to every point in the target distribution,
resulting in long average paths. To this end, in this work, we tap into a
non-utilized property of conditional flow-based models: the ability to design a
non-trivial prior distribution. Given an input condition, such as a text
prompt, we first map it to a point lying in data space, representing an
``average" data point with the minimal average distance to all data points of
the same conditional mode (e.g., class). We then utilize the flow matching
formulation to map samples from a parametric distribution centered around this
point to the conditional target distribution. Experimentally, our method
significantly improves training times and generation efficiency (FID, KID and
CLIP alignment scores) compared to baselines, producing high quality samples
using fewer sampling steps.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Score-of-Mixture Training: Training One-Step Generative Models Made
  Simple 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09609v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09609v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tejas Jayashankar, J. Jon Ryu, Gregory Wornell
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose Score-of-Mixture Training (SMT), a novel framework for training
one-step generative models by minimizing a class of divergences called the
$\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score
of mixture distributions between real and fake samples across multiple noise
levels. Similar to consistency models, our approach supports both training from
scratch (SMT) and distillation using a pretrained diffusion model, which we
call Score-of-Mixture Distillation (SMD). It is simple to implement, requires
minimal hyperparameter tuning, and ensures stable training. Experiments on
CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even
outperform existing methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human-LLM Coevolution: Evidence from Academic Writing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingmeng Geng, Roberto Trotta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With a statistical analysis of arXiv paper abstracts, we report a marked drop
in the frequency of several words previously identified as overused by ChatGPT,
such as "delve", starting soon after they were pointed out in early 2024. The
frequency of certain other words favored by ChatGPT, such as "significant", has
instead kept increasing. These phenomena suggest that some authors of academic
papers have adapted their use of large language models (LLMs), for example, by
selecting outputs or applying modifications to the LLM-generated content. Such
coevolution and cooperation of humans and LLMs thus introduce additional
challenges to the detection of machine-generated text in real-world scenarios.
Estimating the impact of LLMs on academic writing by examining word frequency
remains feasible, and more attention should be paid to words that were already
frequently employed, including those that have decreased in frequency.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SelfCite: <span class="highlight-title">Self-Supervised</span> Alignment for Context Attribution in Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09604v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09604v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce SelfCite, a novel self-supervised approach that aligns LLMs to
generate high-quality, fine-grained, sentence-level citations for the
statements in their generated responses. Instead of only relying on costly and
labor-intensive annotations, SelfCite leverages a reward signal provided by the
LLM itself through context ablation: If a citation is necessary, removing the
cited text from the context should prevent the same response; if sufficient,
retaining the cited text alone should preserve the same response. This reward
can guide the inference-time best-of-N sampling strategy to improve citation
quality significantly, as well as be used in preference optimization to
directly fine-tune the models for generating better citations. The
effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3
points on the LongBench-Cite benchmark across five long-form question answering
tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Implementation available at https://github.com/voidism/SelfCite</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Do LLMs Recognize Your Preferences? Evaluating Personalized Preference
  Following in LLMs <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09597v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09597v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly used as chatbots, yet their
ability to personalize responses to user preferences remains limited. We
introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize
and adhere to user preferences in a long-context conversational setting.
PrefEval comprises 3,000 manually curated user preference and query pairs
spanning 20 topics. PrefEval contains user personalization or preference
information in both explicit and implicit forms, and evaluates LLM performance
using a generation and a classification task. With PrefEval, we evaluated the
aforementioned preference following capabilities of 10 open-source and
proprietary LLMs in multi-session conversations with varying context lengths up
to 100k tokens. We benchmark with various prompting, iterative feedback, and
retrieval-augmented generation methods. Our benchmarking effort reveals that
state-of-the-art LLMs face significant challenges in proactively following
users' preferences during conversations. In particular, in zero-shot settings,
preference following accuracy falls below 10% at merely 10 turns (~3k tokens)
across most evaluated models. Even with advanced prompting and retrieval
methods, preference following still deteriorates in long-context conversations.
Furthermore, we show that fine-tuning on PrefEval significantly improves
performance. We believe PrefEval serves as a valuable resource for measuring,
understanding, and enhancing LLMs' preference following abilities, paving the
way for personalized conversational agents. Our code and dataset are available
at https://prefeval.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025 as oral presentation. Code and data at:
  https://prefeval.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Censor Dependent Variational Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09591v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09591v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chuanhui Liu, Xiao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper provides a comprehensive analysis of variational inference in
latent variable models for survival analysis, emphasizing the distinctive
challenges associated with applying variational methods to survival data. We
identify a critical weakness in the existing methodology, demonstrating how a
poorly designed variational distribution may hinder the objective of survival
analysis tasks--modeling time-to-event distributions. We prove that the optimal
variational distribution, which perfectly bounds the log-likelihood, may depend
on the censoring mechanism. To address this issue, we propose censor-dependent
variational inference (CDVI), tailored for latent variable models in survival
analysis. More practically, we introduce CD-CVAE, a V-structure Variational
Autoencoder (VAE) designed for the scalable implementation of CDVI. Further
discussion extends some existing theories and training techniques to survival
analysis. Extensive experiments validate our analysis and demonstrate
significant improvements in the estimation of individual survival
distributions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Rolling Ahead Diffusion for Traffic Scene Simulation <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09587v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09587v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Liu, Matthew Niedoba, William Harvey, Adam Scibior, Berend Zwartsenberg, Frank Wood
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Realistic driving simulation requires that NPCs not only mimic natural
driving behaviors but also react to the behavior of other simulated agents.
Recent developments in diffusion-based scenario generation focus on creating
diverse and realistic traffic scenarios by jointly modelling the motion of all
the agents in the scene. However, these traffic scenarios do not react when the
motion of agents deviates from their modelled trajectories. For example, the
ego-agent can be controlled by a stand along motion planner. To produce
reactive scenarios with joint scenario models, the model must regenerate the
scenario at each timestep based on new observations in a Model Predictive
Control (MPC) fashion. Although reactive, this method is time-consuming, as one
complete possible future for all NPCs is generated per simulation step.
Alternatively, one can utilize an autoregressive model (AR) to predict only the
immediate next-step future for all NPCs. Although faster, this method lacks the
capability for advanced planning. We present a rolling diffusion based traffic
scene generation model which mixes the benefits of both methods by predicting
the next step future and simultaneously predicting partially noised further
future steps at the same time. We show that such model is efficient compared to
diffusion model based AR, achieving a beneficial compromise between reactivity
and computational efficiency.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Workshop on Machine Learning for Autonomous Driving at
  AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Coordinate with Experts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09583v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09583v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamad H. Danesh, Tu Trinh, Benjamin Plaut, Nguyen X. Khanh
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When deployed in dynamic environments, AI agents will inevitably encounter
challenges that exceed their individual capabilities. Leveraging assistance
from expert agents-whether human or AI-can significantly enhance safety and
performance in such situations. However, querying experts is often costly,
necessitating the development of agents that can efficiently request and
utilize expert guidance. In this paper, we introduce a fundamental coordination
problem called Learning to Yield and Request Control (YRC), where the objective
is to learn a strategy that determines when to act autonomously and when to
seek expert assistance. We consider a challenging practical setting in which an
agent does not interact with experts during training but must adapt to novel
environmental changes and expert interventions at test time. To facilitate
empirical research, we introduce YRC-Bench, an open-source benchmark featuring
diverse domains. YRC-Bench provides a standardized Gym-like API, simulated
experts, evaluation pipeline, and implementation of competitive baselines.
Towards tackling the YRC problem, we propose a novel validation approach and
investigate the performance of various learning methods across diverse
environments, yielding insights that can guide future research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing <span class="highlight-title">GPT</span> for Video Understanding: Zero-Shot Performance and <span class="highlight-title">Prompt</span>
  Engineering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09573v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09573v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mark Beliaev, Victor Yang, Madhura Raju, Jiachen Sun, Xinghai Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this study, we tackle industry challenges in video content classification
by exploring and optimizing GPT-based models for zero-shot classification
across seven critical categories of video quality. We contribute a novel
approach to improving GPT's performance through prompt optimization and policy
refinement, demonstrating that simplifying complex policies significantly
reduces false negatives. Additionally, we introduce a new
decomposition-aggregation-based prompt engineering technique, which outperforms
traditional single-prompt methods. These experiments, conducted on real
industry problems, show that thoughtful prompt design can substantially enhance
GPT's performance without additional finetuning, offering an effective and
scalable solution for improving video classification systems across various
domains in industry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09571v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09571v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Montgomery Bohde, Mrunali Manjrekar, Runzhong Wang, Shuiwang Ji, Connor W. Coley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Mass spectrometry plays a fundamental role in elucidating the structures of
unknown molecules and subsequent scientific discoveries. One formulation of the
structure elucidation task is the conditional $\textit{de novo}$ generation of
molecular structure given a mass spectrum. Toward a more accurate and efficient
scientific discovery pipeline for small molecules, we present DiffMS, a
formula-restricted encoder-decoder generative network that achieves
state-of-the-art performance on this task. The encoder utilizes a transformer
architecture and models mass spectra domain knowledge such as peak formulae and
neutral losses, and the decoder is a discrete graph diffusion model restricted
by the heavy-atom composition of a known chemical formula. To develop a robust
decoder that bridges latent embeddings and molecular structures, we pretrain
the diffusion decoder with fingerprint-structure pairs, which are available in
virtually infinite quantities, compared to structure-spectrum pairs that number
in the tens of thousands. Extensive experiments on established benchmarks show
that DiffMS outperforms existing models on $\textit{de novo}$ molecule
generation. We provide several ablations to demonstrate the effectiveness of
our diffusion and pretraining approaches and show consistent performance
scaling with increasing pretraining dataset size. DiffMS code is publicly
available at https://github.com/coleygroup/DiffMS.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing the Utility of Higher-Order Information in Relational Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09570v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09570v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Raphael Pellegrin, Lukas Fesser, Melanie Weber
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Higher-order information is crucial for relational learning in many domains
where relationships extend beyond pairwise interactions. Hypergraphs provide a
natural framework for modeling such relationships, which has motivated recent
extensions of graph neural net- work architectures to hypergraphs. However,
comparisons between hypergraph architectures and standard graph-level models
remain limited. In this work, we systematically evaluate a selection of
hypergraph-level and graph-level architectures, to determine their
effectiveness in leveraging higher-order information in relational learning.
Our results show that graph-level architectures applied to hypergraph
expansions often outperform hypergraph- level ones, even on inputs that are
naturally parametrized as hypergraphs. As an alternative approach for
leveraging higher-order information, we propose hypergraph-level encodings
based on classical hypergraph characteristics. While these encodings do not
significantly improve hypergraph architectures, they yield substantial
performance gains when combined with graph-level models. Our theoretical
analysis shows that hypergraph-level encodings provably increase the
representational power of message-passing graph neural networks beyond that of
their graph-level counterparts.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-shot generation of synthetic neurosurgical data with large language
  models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09566v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09566v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Austin A. Barr, Eddie Guo, Emre Sezgin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Clinical data is fundamental to advance neurosurgical research, but access is
often constrained by data availability, small sample sizes, privacy
regulations, and resource-intensive preprocessing and de-identification
procedures. Synthetic data offers a potential solution to challenges associated
with accessing and using real-world data (RWD). This study aims to evaluate the
capability of zero-shot generation of synthetic neurosurgical data with a large
language model (LLM), GPT-4o, by benchmarking with the conditional tabular
generative adversarial network (CTGAN). Synthetic datasets were compared to
real-world neurosurgical data to assess fidelity (means, proportions,
distributions, and bivariate correlations), utility (ML classifier performance
on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated
datasets matched or exceeded CTGAN performance, despite no fine-tuning or
access to RWD for pre-training. Datasets demonstrated high univariate and
bivariate fidelity to RWD without directly exposing any real patient records,
even at amplified sample size. Training an ML classifier on GPT-4o-generated
data and testing on RWD for a binary prediction task showed an F1 score (0.706)
with comparable performance to training on the CTGAN data (0.705) for
predicting postoperative functional status deterioration. GPT-4o demonstrated a
promising ability to generate high-fidelity synthetic neurosurgical data. These
findings also indicate that data synthesized with GPT-4o can effectively
augment clinical data with small sample sizes, and train ML models for
prediction of neurosurgical outcomes. Further investigation is necessary to
improve the preservation of distributional characteristics and boost classifier
performance.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 4 figures, 4 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusing DeBias: a Recipe for Turning a Bug into a Feature 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09564v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09564v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Massimiliano Ciranni, Vito Paolo Pastore, Roberto Di Via, Enzo Tartaglione, Francesca Odone, Vittorio Murino
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep learning model effectiveness in classification tasks is often challenged
by the quality and quantity of training data which, whenever containing strong
spurious correlations between specific attributes and target labels, can result
in unrecoverable biases in model predictions. Tackling these biases is crucial
in improving model generalization and trust, especially in real-world
scenarios. This paper presents Diffusing DeBias (DDB), a novel approach acting
as a plug-in for common methods in model debiasing while exploiting the
inherent bias-learning tendency of diffusion models. Our approach leverages
conditional diffusion models to generate synthetic bias-aligned images, used to
train a bias amplifier model, to be further employed as an auxiliary method in
different unsupervised debiasing approaches. Our proposed method, which also
tackles the common issue of training set memorization typical of this type of
tech- niques, beats current state-of-the-art in multiple benchmark datasets by
significant margins, demonstrating its potential as a versatile and effective
tool for tackling dataset bias in deep learning applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 Pages, 12 Figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SyntheticPop: Attacking Speaker Verification Systems With Synthetic
  VoicePops 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09553v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09553v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Eshaq Jamdar, Amith Kamath Belman
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Voice Authentication (VA), also known as Automatic Speaker Verification
(ASV), is a widely adopted authentication method, particularly in automated
systems like banking services, where it serves as a secondary layer of user
authentication. Despite its popularity, VA systems are vulnerable to various
attacks, including replay, impersonation, and the emerging threat of deepfake
audio that mimics the voice of legitimate users. To mitigate these risks,
several defense mechanisms have been proposed. One such solution, Voice Pops,
aims to distinguish an individual's unique phoneme pronunciations during the
enrollment process. While promising, the effectiveness of VA+VoicePop against a
broader range of attacks, particularly logical or adversarial attacks, remains
insufficiently explored. We propose a novel attack method, which we refer to as
SyntheticPop, designed to target the phoneme recognition capabilities of the
VA+VoicePop system. The SyntheticPop attack involves embedding synthetic "pop"
noises into spoofed audio samples, significantly degrading the model's
performance. We achieve an attack success rate of over 95% while poisoning 20%
of the training dataset. Our experiments demonstrate that VA+VoicePop achieves
69% accuracy under normal conditions, 37% accuracy when subjected to a baseline
label flipping attack, and just 14% accuracy under our proposed SyntheticPop
attack, emphasizing the effectiveness of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fast Tensor Completion via Approximate Richardson Iteration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09534v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09534v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mehrdad Ghadiri, Matthew Fahrbach, Yunbum Kook, Ali Jadbabaie
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study tensor completion (TC) through the lens of low-rank tensor
decomposition (TD). Many TD algorithms use fast alternating minimization
methods, which solve highly structured linear regression problems at each step
(e.g., for CP, Tucker, and tensor-train decompositions). However, such
algebraic structure is lost in TC regression problems, making direct extensions
unclear. To address this, we propose a lifting approach that approximately
solves TC regression problems using structured TD regression algorithms as
blackbox subroutines, enabling sublinear-time methods. We theoretically analyze
the convergence rate of our approximate Richardson iteration based algorithm,
and we demonstrate on real-world tensors that its running time can be 100x
faster than direct methods for CP completion.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robust Learning of Multi-index Models via Iterative Subspace
  Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09525v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09525v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Nikos Zarifis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the task of learning Multi-Index Models (MIMs) with label noise
under the Gaussian distribution. A $K$-MIM is any function $f$ that only
depends on a $K$-dimensional subspace. We focus on well-behaved MIMs with
finite ranges that satisfy certain regularity properties. Our main contribution
is a general robust learner that is qualitatively optimal in the Statistical
Query (SQ) model. Our algorithm iteratively constructs better approximations to
the defining subspace by computing low-degree moments conditional on the
projection to the subspace computed thus far, and adding directions with
relatively large empirical moments. This procedure efficiently finds a subspace
$V$ so that $f(\mathbf{x})$ is close to a function of the projection of
$\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional
moments do not help, we prove an SQ lower bound suggesting that no efficient
learner exists.
  As applications, we provide faster robust learners for the following concept
classes:
  * {\bf Multiclass Linear Classifiers} We give a constant-factor approximate
agnostic learner with sample complexity $N = O(d)
2^{\mathrm{poly}(K/\epsilon)}$ and computational complexity $\mathrm{poly}(N
,d)$. This is the first constant-factor agnostic learner for this class whose
complexity is a fixed-degree polynomial in $d$.
  * {\bf Intersections of Halfspaces} We give an approximate agnostic learner
for this class achieving 0-1 error $K \tilde{O}(\mathrm{OPT}) + \epsilon$ with
sample complexity $N=O(d^2) 2^{\mathrm{poly}(K/\epsilon)}$ and computational
complexity $\mathrm{poly}(N ,d)$. This is the first agnostic learner for this
class with near-linear error dependence and complexity a fixed-degree
polynomial in $d$.
  Furthermore, we show that in the presence of random classification noise, the
complexity of our algorithm scales polynomially with $1/\epsilon$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Diffusion Models for Molecules: A <span class="highlight-title">Survey</span> of Methods and Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09511v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09511v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liang Wang, Chao Song, Zhiyuan Liu, Yu Rong, Qiang Liu, Shu Wu, Liang Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative tasks about molecules, including but not limited to molecule
generation, are crucial for drug discovery and material design, and have
consistently attracted significant attention. In recent years, diffusion models
have emerged as an impressive class of deep generative models, sparking
extensive research and leading to numerous studies on their application to
molecular generative tasks. Despite the proliferation of related work, there
remains a notable lack of up-to-date and systematic surveys in this area.
Particularly, due to the diversity of diffusion model formulations, molecular
data modalities, and generative task types, the research landscape is
challenging to navigate, hindering understanding and limiting the area's
growth. To address this, this paper conducts a comprehensive survey of
diffusion model-based molecular generative methods. We systematically review
the research from the perspectives of methodological formulations, data
modalities, and task types, offering a novel taxonomy. This survey aims to
facilitate understanding and further flourishing development in this area. The
relevant papers are summarized at:
https://github.com/AzureLeon1/awesome-molecular-diffusion-models.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EQ-VAE: Equivariance Regularized Latent Space for Improved Generative
  Image Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09509v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09509v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Theodoros Kouzelis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Latent generative models have emerged as a leading approach for high-quality
image synthesis. These models rely on an autoencoder to compress images into a
latent space, followed by a generative model to learn the latent distribution.
We identify that existing autoencoders lack equivariance to semantic-preserving
transformations like scaling and rotation, resulting in complex latent spaces
that hinder generative performance. To address this, we propose EQ-VAE, a
simple regularization approach that enforces equivariance in the latent space,
reducing its complexity without degrading reconstruction quality. By finetuning
pre-trained autoencoders with EQ-VAE, we enhance the performance of several
state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT,
achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning.
EQ-VAE is compatible with both continuous and discrete autoencoders, thus
offering a versatile enhancement for a wide range of latent generative models.
Project page and code: https://eq-vae.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When and How Does CLIP Enable Domain and Compositional Generalization? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09507v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09507v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elias Kempf, Simon Schrodi, Max Argus, Thomas Brox
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The remarkable generalization performance of contrastive vision-language
models like CLIP is often attributed to the diversity of their training
distributions. However, key questions remain unanswered: Can CLIP generalize to
an entirely unseen domain when trained on a diverse mixture of domains (domain
generalization)? Can it generalize to unseen classes within partially seen
domains (compositional generalization)? What factors affect such
generalization? To answer these questions, we trained CLIP models on
systematically constructed training distributions with controlled domain
diversity and object class exposure. Our experiments show that domain diversity
is essential for both domain and compositional generalization, yet
compositional generalization can be surprisingly weaker than domain
generalization when the training distribution contains a suboptimal subset of
the test domain. Through data-centric and mechanistic analyses, we find that
successful generalization requires learning of shared representations already
in intermediate layers and shared circuitry.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AttentionSmithy: A Modular Framework for Rapid <span class="highlight-title">Transformer</span> Development
  and Customization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09503v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09503v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Caleb Cranney, Jesse G. Meyer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformer architectures have transformed AI applications but remain complex
to customize for domain experts lacking low-level implementation expertise. We
introduce AttentionSmithy, a modular software package that simplifies
transformer innovation by breaking down key components into reusable building
blocks: attention modules, feed-forward networks, normalization layers, and
positional encodings. Users can rapidly prototype and evaluate transformer
variants without extensive coding. Our framework supports four positional
encoding strategies and integrates with neural architecture search for
automated design. We validate AttentionSmithy by replicating the original
transformer under resource constraints and optimizing translation performance
by combining positional encodings. Additionally, we demonstrate its
adaptability in gene-specific modeling, achieving over 95% accuracy in cell
type classification. These case studies highlight AttentionSmithy's potential
to accelerate research across diverse fields by removing framework
implementation barriers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scalable First-order Method for Certifying Optimal k-Sparse GLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09502v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09502v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiachang Liu, Soroosh Shafiee, Andrea Lodi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper investigates the problem of certifying optimality for sparse
generalized linear models (GLMs), where sparsity is enforced through an
$\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can
certify optimality by pruning nodes using dual bounds, existing methods for
computing these bounds are either computationally intensive or exhibit slow
convergence, limiting their scalability to large-scale problems. To address
this challenge, we propose a first-order proximal gradient algorithm designed
to solve the perspective relaxation of the problem within a BnB framework.
Specifically, we formulate the relaxed problem as a composite optimization
problem and demonstrate that the proximal operator of the non-smooth component
can be computed exactly in log-linear time complexity, eliminating the need to
solve a computationally expensive second-order cone program. Furthermore, we
introduce a simple restart strategy that enhances convergence speed while
maintaining low per-iteration complexity. Extensive experiments on synthetic
and real-world datasets show that our approach significantly accelerates dual
bound computations and is highly effective in providing optimality certificates
for large-scale problems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Eidetic Learning: an Efficient and Provable Solution to Catastrophic
  Forgetting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09500v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09500v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicholas Dronen, Randall Balestriero
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Catastrophic forgetting -- the phenomenon of a neural network learning a task
t1 and losing the ability to perform it after being trained on some other task
t2 -- is a long-standing problem for neural networks [McCloskey and Cohen,
1989]. We present a method, Eidetic Learning, that provably solves catastrophic
forgetting. A network trained with Eidetic Learning -- here, an EideticNet --
requires no rehearsal or replay. We consider successive discrete tasks and show
how at inference time an EideticNet automatically routes new instances without
auxiliary task information. An EideticNet bears a family resemblance to the
sparsely-gated Mixture-of-Experts layer Shazeer et al. [2016] in that network
capacity is partitioned across tasks and the network itself performs
data-conditional routing. An EideticNet is easy to implement and train, is
efficient, and has time and space complexity linear in the number of
parameters. The guarantee of our method holds for normalization layers of
modern neural networks during both pre-training and fine-tuning. We show with a
variety of network architectures and sets of tasks that EideticNets are immune
to forgetting. While the practical benefits of EideticNets are substantial, we
believe they can be benefit practitioners and theorists alike. The code for
training EideticNets is available at
\href{https://github.com/amazon-science/eideticnet-training}{this https URL}.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 6 figures; code is available at
  https://github.com/amazon-science/eideticnet-training</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On Agnostic PAC Learning in the Small Error Regime 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Asilis, Mikael Møller Høgsgaard, Grigoris Velegkas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Binary classification in the classic PAC model exhibits a curious phenomenon:
Empirical Risk Minimization (ERM) learners are suboptimal in the realizable
case yet optimal in the agnostic case. Roughly speaking, this owes itself to
the fact that non-realizable distributions $\mathcal{D}$ are simply more
difficult to learn than realizable distributions -- even when one discounts a
learner's error by $\mathrm{err}(h^*_{\mathcal{D}})$, the error of the best
hypothesis in $\mathcal{H}$ for $\mathcal{D}$. Thus, optimal agnostic learners
are permitted to incur excess error on (easier-to-learn) distributions
$\mathcal{D}$ for which $\tau = \mathrm{err}(h^*_{\mathcal{D}})$ is small.
  Recent work of Hanneke, Larsen, and Zhivotovskiy (FOCS `24) addresses this
shortcoming by including $\tau$ itself as a parameter in the agnostic error
term. In this more fine-grained model, they demonstrate tightness of the error
lower bound $\tau + \Omega \left(\sqrt{\frac{\tau (d + \log(1 / \delta))}{m}} +
\frac{d + \log(1 / \delta)}{m} \right)$ in a regime where $\tau > d/m$, and
leave open the question of whether there may be a higher lower bound when $\tau
\approx d/m$, with $d$ denoting $\mathrm{VC}(\mathcal{H})$. In this work, we
resolve this question by exhibiting a learner which achieves error $c \cdot
\tau + O \left(\sqrt{\frac{\tau (d + \log(1 / \delta))}{m}} + \frac{d + \log(1
/ \delta)}{m} \right)$ for a constant $c \leq 2.1$, thus matching the lower
bound when $\tau \approx d/m$. Further, our learner is computationally
efficient and is based upon careful aggregations of ERM classifiers, making
progress on two other questions of Hanneke, Larsen, and Zhivotovskiy (FOCS
`24). We leave open the interesting question of whether our approach can be
refined to lower the constant from 2.1 to 1, which would completely settle the
complexity of agnostic learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>44 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cracking the Code: Enhancing Development finance understanding with
  artificial intelligence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09495v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09495v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pierre Beaucoral
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Analyzing development projects is crucial for understanding donors aid
strategies, recipients priorities, and to assess development finance capacity
to adress development issues by on-the-ground actions. In this area, the
Organisation for Economic Co-operation and Developments (OECD) Creditor
Reporting System (CRS) dataset is a reference data source. This dataset
provides a vast collection of project narratives from various sectors
(approximately 5 million projects). While the OECD CRS provides a rich source
of information on development strategies, it falls short in informing project
purposes due to its reporting process based on donors self-declared main
objectives and pre-defined industrial sectors. This research employs a novel
approach that combines Machine Learning (ML) techniques, specifically Natural
Language Processing (NLP), an innovative Python topic modeling technique called
BERTopic, to categorise (cluster) and label development projects based on their
narrative descriptions. By revealing existing yet hidden topics of development
finance, this application of artificial intelligence enables a better
understanding of donor priorities and overall development funding and provides
methods to analyse public and private projects narratives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Communicating Likelihoods with Normalising Flows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09494v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09494v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jack Y. Araz, Anja Beck, Méril Reboud, Michael Spannowsky, Danny van Dyk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a machine-learning-based workflow to model an unbinned likelihood
from its samples. A key advancement over existing approaches is the validation
of the learned likelihood using rigorous statistical tests of the joint
distribution, such as the Kolmogorov-Smirnov test of the joint distribution.
Our method enables the reliable communication of experimental and
phenomenological likelihoods for subsequent analyses. We demonstrate its
effectiveness through three case studies in high-energy physics. To support
broader adoption, we provide an open-source reference implementation, nabu.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages + references, 1 figure</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Inverse Design with Dynamic Mode Decomposition 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunpeng Zhu, Liangliang Cheng, Anping Jing, Hanyu Huo, Ziqiang Lang, Bo Zhang, J. Nathan Kutz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a computationally efficient method for the automation of inverse
design in science and engineering. Based on simple least-square regression, the
underlying dynamic mode decomposition algorithm can be used to construct a
low-rank subspace spanning multiple experiments in parameter space. The
proposed inverse design dynamic mode composition (ID-DMD) algorithm leverages
the computed low-dimensional subspace to enable fast digital design and
optimization on laptop-level computing, including the potential to prescribe
the dynamics themselves. Moreover, the method is robust to noise, physically
interpretable, and can provide uncertainty quantification metrics. The
architecture can also efficiently scale to large-scale design problems using
randomized algorithms in the ID-DMD. The simplicity of the method and its
implementation are highly attractive in practice, and the ID-DMD has been
demonstrated to be an order of magnitude more accurate than competing methods
while simultaneously being 3-5 orders faster on challenging engineering design
problems ranging from structural vibrations to fluid dynamics. Due to its
speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with
other leading machine learning methods represents a significant advancement in
data-driven methods for inverse design and optimization, promising a paradigm
shift in how to approach inverse design in practice.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>29 pages, 19 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Objective quantification of mood states using large language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09487v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09487v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jakub Onysk, Quentin Huys
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Emotional states influence human behaviour and cognition, leading to diverse
thought trajectories. Similarly, Large Language Models (LLMs) showcase an
excellent level of response consistency across wide-ranging contexts (prompts).
We leverage these parallels to establish a framework for quantifying mental
states. Our approach utilises self-report questionnaires that reliably assess
these states due to their inherent sensitivity to patterns of co-occurring
responses. Specifically, we recruited a large sample of participants (N=422) to
investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set
of depressive mood states measured with participants' open-ended responses to a
depression questionnaire. We show LLM responses to held-out multiple-choice
questions, given participants' open-ended answers, correlate strongly (r:
0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation
from mood representations. We explore a link between these representations and
factor analysis. Using ridge regression, we find depression-related subspaces
within LLM hidden states. We show these subspaces to be predictive of
participants' "Depression" and "Somatic & Emotional Distress" factor scores, as
well as suicidality severity. Overall, LLMs can provide quantitative measures
of mental states. The reliability of these hinges upon how informative the
questions we ask participants are. Used correctly, this approach could
supplement mental state assessment in a variety of settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>main text - 9 pages, 5 figures;</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Assessing Generative AI value in a public sector context: evidence from
  a field experiment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09479v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09479v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trevor Fitzpatrick, Seamus Kelly, Patrick Carey, David Walsh, Ruairi Nugent
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The emergence of Generative AI (Gen AI) has motivated an interest in
understanding how it could be used to enhance productivity across various
tasks. We add to research results for the performance impact of Gen AI on
complex knowledge-based tasks in a public sector setting. In a pre-registered
experiment, after establishing a baseline level of performance, we find mixed
evidence for two types of composite tasks related to document understanding and
data analysis. For the Documents task, the treatment group using Gen AI had a
17% improvement in answer quality scores (as judged by human evaluators) and a
34% improvement in task completion time compared to a control group. For the
Data task, we find the Gen AI treatment group experienced a 12% reduction in
quality scores and no significant difference in mean completion time compared
to the control group. These results suggest that the benefits of Gen AI may be
task and potentially respondent dependent. We also discuss field notes and
lessons learned, as well as supplementary insights from a post-trial survey and
feedback workshop with participants.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ DiffRenderGAN: Addressing Training Data Scarcity in Deep Segmentation
  Networks for Quantitative Nanomaterial Analysis through Differentiable
  Rendering and Generative Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09477v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09477v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dennis Possart, Leonid Mill, Florian Vollnhals, Tor Hildebrand, Peter Suter, Mathis Hoffmann, Jonas Utz, Daniel Augsburger, Mareike Thies, Mingxuan Wu, Fabian Wagner, George Sarau, Silke Christiansen, Katharina Breininger
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Nanomaterials exhibit distinctive properties governed by parameters such as
size, shape, and surface characteristics, which critically influence their
applications and interactions across technological, biological, and
environmental contexts. Accurate quantification and understanding of these
materials are essential for advancing research and innovation. In this regard,
deep learning segmentation networks have emerged as powerful tools that enable
automated insights and replace subjective methods with precise quantitative
analysis. However, their efficacy depends on representative annotated datasets,
which are challenging to obtain due to the costly imaging of nanoparticles and
the labor-intensive nature of manual annotations. To overcome these
limitations, we introduce DiffRenderGAN, a novel generative model designed to
produce annotated synthetic data. By integrating a differentiable renderer into
a Generative Adversarial Network (GAN) framework, DiffRenderGAN optimizes
textural rendering parameters to generate realistic, annotated nanoparticle
images from non-annotated real microscopy images. This approach reduces the
need for manual intervention and enhances segmentation performance compared to
existing synthetic data methods by generating diverse and realistic data.
Tested on multiple ion and electron microscopy cases, including titanium
dioxide (TiO$_2$), silicon dioxide (SiO$_2$)), and silver nanowires (AgNW),
DiffRenderGAN bridges the gap between synthetic and real data, advancing the
quantification and understanding of complex nanomaterial systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning to Predict Global Atrial Fibrillation Dynamics from Sparse
  Measurements 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09473v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09473v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexander Jenkins, Andrea Cini, Joseph Barker, Alexander Sharp, Arunashis Sau, Varun Valentine, Srushti Valasang, Xinyang Li, Tom Wong, Timothy Betts, Danilo Mandic, Cesare Alippi, Fu Siong Ng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all
treatment with limited success in persistent AF. This may be due to our
inability to map the dynamics of AF with the limited resolution and coverage
provided by sequential contact mapping catheters, preventing effective patient
phenotyping for personalised, targeted ablation. Here we introduce FibMap, a
graph recurrent neural network model that reconstructs global AF dynamics from
sparse measurements. Trained and validated on 51 non-contact whole atria
recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage,
achieving a 210% lower mean absolute error and an order of magnitude higher
performance in tracking phase singularities compared to baseline methods.
Clinical utility of FibMap is demonstrated on real-world contact mapping
recordings, achieving reconstruction fidelity comparable to non-contact
mapping. FibMap's state-spaces and patient-specific parameters offer insights
for electrophenotyping AF. Integrating FibMap into clinical practice could
enable personalised AF care and improve outcomes.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Differentiable Rank-Based Objective For Better Feature Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09445v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09445v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Krunoslav Lehman Pavasovic, David Lopez-Paz, Giulio Biroli, Levent Sagun
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we leverage existing statistical methods to better understand
feature learning from data. We tackle this by modifying the model-free variable
selection method, Feature Ordering by Conditional Independence (FOCI), which is
introduced in \cite{azadkia2021simple}. While FOCI is based on a non-parametric
coefficient of conditional dependence, we introduce its parametric,
differentiable approximation. With this approximate coefficient of correlation,
we present a new algorithm called difFOCI, which is applicable to a wider range
of machine learning problems thanks to its differentiable nature and learnable
parameters. We present difFOCI in three contexts: (1) as a variable selection
method with baseline comparisons to FOCI, (2) as a trainable model parametrized
with a neural network, and (3) as a generic, widely applicable neural network
regularizer, one that improves feature learning with better management of
spurious correlations. We evaluate difFOCI on increasingly complex problems
ranging from basic variable selection in toy examples to saliency map
comparisons in convolutional networks. We then show how difFOCI can be
incorporated in the context of fairness to facilitate classifications without
relying on sensitive data.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Relational Conformal Prediction for Correlated Time Series 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09443v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09443v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrea Cini, Alexander Jenkins, Danilo Mandic, Cesare Alippi, Filippo Maria Bianchi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the problem of uncertainty quantification in time series
forecasting by exploiting observations at correlated sequences. Relational deep
learning methods leveraging graph representations are among the most effective
tools for obtaining point estimates from spatiotemporal data and correlated
time series. However, the problem of exploiting relational structures to
estimate the uncertainty of such predictions has been largely overlooked in the
same context. To this end, we propose a novel distribution-free approach based
on the conformal prediction framework and quantile regression. Despite the
recent applications of conformal prediction to sequential data, existing
methods operate independently on each target time series and do not account for
relationships among them when constructing the prediction interval. We fill
this void by introducing a novel conformal prediction method based on graph
deep learning operators. Our method, named Conformal Relational Prediction
(CoRel), does not require the relational structure (graph) to be known as a
prior and can be applied on top of any pre-trained time series predictor.
Additionally, CoRel includes an adaptive component to handle non-exchangeable
data and changes in the input time series. Our approach provides accurate
coverage and archives state-of-the-art uncertainty quantification in relevant
benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09432v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09432v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Navdeep Kumar, Adarsh Gupta, Maxence Mohamed Elfatihi, Giorgia Ramponi, Kfir Yehuda Levy, Shie Mannor
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study robust Markov decision processes (RMDPs) with non-rectangular
uncertainty sets, which capture interdependencies across states unlike
traditional rectangular models. While non-rectangular robust policy evaluation
is generally NP-hard, even in approximation, we identify a powerful class of
$L_p$-bounded uncertainty sets that avoid these complexity barriers due to
their structural simplicity. We further show that this class can be decomposed
into infinitely many \texttt{sa}-rectangular $L_p$-bounded sets and leverage
its structural properties to derive a novel dual formulation for $L_p$ RMDPs.
This formulation provides key insights into the adversary's strategy and
enables the development of the first robust policy evaluation algorithms for
non-rectangular RMDPs. Empirical results demonstrate that our approach
significantly outperforms brute-force methods, establishing a promising
foundation for future investigation into non-rectangular robust MDPs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On multi-token prediction for efficient LLM inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09419v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09419v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Somesh Mehra, Javier Alonso Garcia, Lukas Mauch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We systematically investigate multi-token prediction (MTP) capabilities
within LLMs pre-trained for next-token prediction (NTP). We first show that
such models inherently possess MTP capabilities via numerical marginalization
over intermediate token probabilities, though performance is data-dependent and
improves with model scale. Furthermore, we explore the challenges of
integrating MTP heads into frozen LLMs and find that their hidden layers are
strongly specialized for NTP, making adaptation non-trivial. Finally, we show
that while joint training of MTP heads with the backbone improves performance,
it cannot fully overcome this barrier, prompting further research in this
direction. Our findings provide a deeper understanding of MTP applied to
pretrained LLMs, informing strategies for accelerating inference through
parallel token prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A <span class="highlight-title">Survey</span> of Reinforcement Learning for Optimization in Automation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09417v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09417v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmad Farooq, Kamran Iqbal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reinforcement Learning (RL) has become a critical tool for optimization
challenges within automation, leading to significant advancements in several
areas. This review article examines the current landscape of RL within
automation, with a particular focus on its roles in manufacturing, energy
systems, and robotics. It discusses state-of-the-art methods, major challenges,
and upcoming avenues of research within each sector, highlighting RL's capacity
to solve intricate optimization challenges. The paper reviews the advantages
and constraints of RL-driven optimization methods in automation. It points out
prevalent challenges encountered in RL optimization, including issues related
to sample efficiency and scalability; safety and robustness; interpretability
and trustworthiness; transfer learning and meta-learning; and real-world
deployment and integration. It further explores prospective strategies and
future research pathways to navigate these challenges. Additionally, the survey
includes a comprehensive list of relevant research papers, making it an
indispensable guide for scholars and practitioners keen on exploring this
domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 tables, and 1 figure. Accepted at IEEE 20th International
  Conference on Automation Science and Engineering (CASE) 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A hierarchical approach for assessing the vulnerability of tree-based
  classification models to membership inference attack 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09396v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09396v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Richard J. Preen, Jim Smith
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning models can inadvertently expose confidential properties of
their training data, making them vulnerable to membership inference attacks
(MIA). While numerous evaluation methods exist, many require computationally
expensive processes, such as training multiple shadow models. This article
presents two new complementary approaches for efficiently identifying
vulnerable tree-based models: an ante-hoc analysis of hyperparameter choices
and a post-hoc examination of trained model structure. While these new methods
cannot certify whether a model is safe from MIA, they provide practitioners
with a means to significantly reduce the number of models that need to undergo
expensive MIA assessment through a hierarchical filtering approach.
  More specifically, it is shown that the rank order of disclosure risk for
different hyperparameter combinations remains consistent across datasets,
enabling the development of simple, human-interpretable rules for identifying
relatively high-risk models before training. While this ante-hoc analysis
cannot determine absolute safety since this also depends on the specific
dataset, it allows the elimination of unnecessarily risky configurations during
hyperparameter tuning. Additionally, computationally inexpensive structural
metrics serve as indicators of MIA vulnerability, providing a second filtering
stage to identify risky models after training but before conducting expensive
attacks. Empirical results show that hyperparameter-based risk prediction rules
can achieve high accuracy in predicting the most at risk combinations of
hyperparameters across different tree-based model types, while requiring no
model training. Moreover, target model accuracy is not seen to correlate with
privacy risk, suggesting opportunities to optimise model configurations for
both performance and privacy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Robot Pouring: Identifying Causes of Spillage and Selecting Alternative
  Action Parameters Using Probabilistic Actual Causation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09395v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09395v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaime Maldonado, Jonas Krumme, Christoph Zetzsche, Vanessa Didelez, Kerstin Schill
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In everyday life, we perform tasks (e.g., cooking or cleaning) that involve a
large variety of objects and goals. When confronted with an unexpected or
unwanted outcome, we take corrective actions and try again until achieving the
desired result. The reasoning performed to identify a cause of the observed
outcome and to select an appropriate corrective action is a crucial aspect of
human reasoning for successful task execution. Central to this reasoning is the
assumption that a factor is responsible for producing the observed outcome. In
this paper, we investigate the use of probabilistic actual causation to
determine whether a factor is the cause of an observed undesired outcome.
Furthermore, we show how the actual causation probabilities can be used to find
alternative actions to change the outcome. We apply the probabilistic actual
causation analysis to a robot pouring task. When spillage occurs, the analysis
indicates whether a task parameter is the cause and how it should be changed to
avoid spillage. The analysis requires a causal graph of the task and the
corresponding conditional probability distributions. To fulfill these
requirements, we perform a complete causal modeling procedure (i.e., task
analysis, definition of variables, determination of the causal graph structure,
and estimation of conditional probability distributions) using data from a
realistic simulation of the robot pouring task, covering a large combinatorial
space of task parameters. Based on the results, we discuss the implications of
the variables' representation and how the alternative actions suggested by the
actual causation analysis would compare to the alternative solutions proposed
by a human observer. The practical use of the analysis of probabilistic actual
causation to select alternative action parameters is demonstrated.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 13 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SQuARE: Sequential Question Answering Reasoning Engine for Enhanced
  Chain-of-Thought in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09390v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09390v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the rapidly evolving field of Natural Language Processing, Large Language
Models (LLMs) are tasked with increasingly complex reasoning challenges.
Traditional methods like chain-of-thought prompting have shown promise but
often fall short in fully leveraging a model's reasoning capabilities. This
paper introduces SQuARE (Sequential Question Answering Reasoning Engine), a
novel prompting technique designed to improve reasoning through a
self-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts
models to generate and resolve multiple auxiliary questions before tackling the
main query, promoting a more thorough exploration of various aspects of a
topic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models
across multiple question-answering datasets, demonstrate that SQuARE
significantly surpasses traditional CoT prompts and existing
rephrase-and-respond methods. By systematically decomposing queries, SQuARE
advances LLM capabilities in reasoning tasks. The code is publicly available at
https://github.com/IntelLabs/RAG-FiT/tree/square.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LoRA Training Provably Converges to a Low-Rank Global Minimum or It
  Fails Loudly (But it Probably Won't Fail) 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09376v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09376v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junsu Kim, Jaeyeon Kim, Ernest K. Ryu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Low-rank adaptation (LoRA) has become a standard approach for fine-tuning
large foundation models. However, our theoretical understanding of LoRA remains
limited as prior analyses of LoRA's training dynamics either rely on
linearization arguments or consider highly simplified setups. In this work, we
analyze the LoRA loss landscape without such restrictive assumptions. We define
two regimes: a ``special regime'', which includes idealized setups where
linearization arguments hold, and a ``generic regime'' representing more
realistic setups where linearization arguments do not hold. In the generic
regime, we show that LoRA training converges to a global minimizer with low
rank and small magnitude, or a qualitatively distinct solution with high rank
and large magnitude. Finally, we argue that the zero-initialization and weight
decay in LoRA training induce an implicit bias toward the low-rank,
small-magnitude region of the parameter space -- where global minima lie --
thus shedding light on why LoRA training usually succeeds in finding global
minima.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Mitigating multiple single-event upsets during deep neural network
  inference using fault-aware training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09374v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09374v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Toon Vinck, Naïn Jonckers, Gert Dekkers, Jeffrey Prinzie, Peter Karsmakers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep neural networks (DNNs) are increasingly used in safety-critical
applications. Reliable fault analysis and mitigation are essential to ensure
their functionality in harsh environments that contain high radiation levels.
This study analyses the impact of multiple single-bit single-event upsets in
DNNs by performing fault injection at the level of a DNN model. Additionally, a
fault aware training (FAT) methodology is proposed that improves the DNNs'
robustness to faults without any modification to the hardware. Experimental
results show that the FAT methodology improves the tolerance to faults up to a
factor 3.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>7 pages, 4 figures, Topical Workshop on Electronics for Particle
  Physics</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Language Agents as Digital Representatives in Collective Decision-Making 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09369v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09369v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Jarrett, Miruna Pîslar, Michiel A. Bakker, Michael Henry Tessler, Raphael Köster, Jan Balaguer, Romuald Elie, Christopher Summerfield, Andrea Tacchetti
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Consider the process of collective decision-making, in which a group of
individuals interactively select a preferred outcome from among a universe of
alternatives. In this context, "representation" is the activity of making an
individual's preferences present in the process via participation by a proxy
agent -- i.e. their "representative". To this end, learned models of human
behavior have the potential to fill this role, with practical implications for
multi-agent scenario studies and mechanism design. In this work, we investigate
the possibility of training \textit{language agents} to behave in the capacity
of representatives of human agents, appropriately expressing the preferences of
those individuals whom they stand for. First, we formalize the setting of
\textit{collective decision-making} -- as the episodic process of interaction
between a group of agents and a decision mechanism. On this basis, we then
formalize the problem of \textit{digital representation} -- as the simulation
of an agent's behavior to yield equivalent outcomes from the mechanism.
Finally, we conduct an empirical case study in the setting of
\textit{consensus-finding} among diverse humans, and demonstrate the
feasibility of fine-tuning large language models to act as digital
representatives.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Simple Path Structural Encoding for Graph <span class="highlight-title">Transformer</span>s 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09365v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09365v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Louis Airale, Antonio Longa, Mattia Rigon, Andrea Passerini, Roberto Passerone
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph transformers extend global self-attention to graph-structured data,
achieving notable success in graph learning. Recently, random walk structural
encoding (RWSE) has been found to further enhance their predictive power by
encoding both structural and positional information into the edge
representation. However, RWSE cannot always distinguish between edges that
belong to different local graph patterns, which reduces its ability to capture
the full structural complexity of graphs. This work introduces Simple Path
Structural Encoding (SPSE), a novel method that utilizes simple path counts for
edge encoding. We show theoretically and experimentally that SPSE overcomes the
limitations of RWSE, providing a richer representation of graph structures,
particularly for capturing local cyclic patterns. To make SPSE computationally
tractable, we propose an efficient approximate algorithm for simple path
counting. SPSE demonstrates significant performance improvements over RWSE on
various benchmarks, including molecular and long-range graph datasets,
achieving statistically significant gains in discriminative tasks. These
results pose SPSE as a powerful edge encoding alternative for enhancing the
expressivity of graph transformers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The Accuracy Cost of Weakness: A Theoretical Analysis of Fixed-Segment
  Weak Labeling for Events in Time 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09363v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09363v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Martinsson, Olof Mogren, Tuomas Virtanen, Maria Sandsten
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Accurate labels are critical for deriving robust machine learning models.
Labels are used to train supervised learning models and to evaluate most
machine learning paradigms. In this paper, we model the accuracy and cost of a
common weak labeling process where annotators assign presence or absence labels
to fixed-length data segments for a given event class. The annotator labels a
segment as "present" if it sufficiently covers an event from that class, e.g.,
a birdsong sound event in audio data. We analyze how the segment length affects
the label accuracy and the required number of annotations, and compare this
fixed-length labeling approach with an oracle method that uses the true event
activations to construct the segments. Furthermore, we quantify the gap between
these methods and verify that in most realistic scenarios the oracle method is
better than the fixed-length labeling method in both accuracy and cost. Our
findings provide a theoretical justification for adaptive weak labeling
strategies that mimic the oracle process, and a foundation for optimizing weak
labeling processes in sequence labeling tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to TMLR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wasserstein distributional adversarial training for deep neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09352v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09352v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Design of adversarial attacks for deep neural networks, as well as methods of
adversarial training against them, are subject of intense research. In this
paper, we propose methods to train against distributional attack threats,
extending the TRADES method used for pointwise attacks. Our approach leverages
recent contributions and relies on sensitivity analysis for Wasserstein
distributionally robust optimization problems. We introduce an efficient
fine-tuning method which can be deployed on a previously trained model. We test
our methods on a range of pre-trained models on RobustBench. These experimental
results demonstrate the additional training enhances Wasserstein distributional
robustness, while maintaining original levels of pointwise robustness, even for
already very successful networks. The improvements are less marked for models
pre-trained using huge synthetic datasets of 20-100M images. However,
remarkably, sometimes our methods are still able to improve their performance
even when trained using only the original training dataset (50k images).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>15 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Machine learning for modelling unstructured grid data in computational
  physics: a <span class="highlight-title">review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unstructured grid data are essential for modelling complex geometries and
dynamics in computational physics. Yet, their inherent irregularity presents
significant challenges for conventional machine learning (ML) techniques. This
paper provides a comprehensive review of advanced ML methodologies designed to
handle unstructured grid data in high-dimensional dynamical systems. Key
approaches discussed include graph neural networks, transformer models with
spatial attention mechanisms, interpolation-integrated ML methods, and meshless
techniques such as physics-informed neural networks. These methodologies have
proven effective across diverse fields, including fluid dynamics and
environmental simulations. This review is intended as a guidebook for
computational scientists seeking to apply ML approaches to unstructured grid
data in their domains, as well as for ML researchers looking to address
challenges in computational physics. It places special focus on how ML methods
can overcome the inherent limitations of traditional numerical techniques and,
conversely, how insights from computational physics can inform ML development.
To support benchmarking, this review also provides a summary of open-access
datasets of unstructured grid data in computational physics. Finally, emerging
directions such as generative models with unstructured data, reinforcement
learning for mesh generation, and hybrid physics-data-driven paradigms are
discussed to inspire future advancements in this evolving field.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neural Spatiotemporal Point Processes: Trends and Challenges 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09341v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09341v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sumantrak Mukherjee, Mouad Elhamdi, George Mohler, David A. Selby, Yao Xie, Sebastian Vollmer, Gerrit Grossmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Spatiotemporal point processes (STPPs) are probabilistic models for events
occurring in continuous space and time. Real-world event data often exhibit
intricate dependencies and heterogeneous dynamics. By incorporating modern deep
learning techniques, STPPs can model these complexities more effectively than
traditional approaches. Consequently, the fusion of neural methods with STPPs
has become an active and rapidly evolving research area. In this review, we
categorize existing approaches, unify key design choices, and explain the
challenges of working with this data modality. We further highlight emerging
trends and diverse application domains. Finally, we identify open challenges
and gaps in the literature.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ This looks like what? Challenges and Future Research Directions for
  Part-Prototype Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09340v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09340v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Khawla Elhadri, Tomasz Michalski, Adam Wróbel, Jörg Schlötterer, Bartosz Zieliński, Christin Seifert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The growing interest in eXplainable Artificial Intelligence (XAI) has
prompted research into models with built-in interpretability, the most
prominent of which are part-prototype models. Part-Prototype Models (PPMs) make
decisions by comparing an input image to a set of learned prototypes, providing
human-understandable explanations in the form of ``this looks like that''.
Despite their inherent interpretability, PPMS are not yet considered a valuable
alternative to post-hoc models. In this survey, we investigate the reasons for
this and provide directions for future research. We analyze papers from 2019 to
2024, and derive a taxonomy of the challenges that current PPMS face. Our
analysis shows that the open challenges are quite diverse. The main concern is
the quality and quantity of prototypes. Other concerns are the lack of
generalization to a variety of tasks and contexts, and general methodological
issues, including non-standardized evaluation. We provide ideas for future
research in five broad directions: improving predictive performance, developing
novel architectures grounded in theory, establishing frameworks for human-AI
collaboration, aligning models with humans, and establishing metrics and
benchmarks for evaluation. We hope that this survey will stimulate research and
promote intrinsically interpretable models for application domains. Our list of
surveyed papers is available at https://github.com/aix-group/ppm-survey.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph Diffusion Network for Drug-Gene Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09335v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09335v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiayang Wu, Wensheng Gan, Philip S. Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting drug-gene associations is crucial for drug development and disease
treatment. While graph neural networks (GNN) have shown effectiveness in this
task, they face challenges with data sparsity and efficient contrastive
learning implementation. We introduce a graph diffusion network for drug-gene
prediction (GDNDGP), a framework that addresses these limitations through two
key innovations. First, it employs meta-path-based homogeneous graph learning
to capture drug-drug and gene-gene relationships, ensuring similar entities
share embedding spaces. Second, it incorporates a parallel diffusion network
that generates hard negative samples during training, eliminating the need for
exhaustive negative sample retrieval. Our model achieves superior performance
on the DGIdb 4.0 dataset and demonstrates strong generalization capability on
tripartite drug-gene-disease networks. Results show significant improvements
over existing methods in drug-gene prediction tasks, particularly in handling
complex heterogeneous relationships. The source code is publicly available at
https://github.com/csjywu1/GDNDGP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE/ACM TCBB. 14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Full Swap Regret and Discretized Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09332v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09332v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maxwell Fishelson, Robert Kleinberg, Princewill Okoroafor, Renato Paes Leme, Jon Schneider, Yifeng Teng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of minimizing swap regret in structured normal-form
games. Players have a very large (potentially infinite) number of pure actions,
but each action has an embedding into $d$-dimensional space and payoffs are
given by bilinear functions of these embeddings. We provide an efficient
learning algorithm for this setting that incurs at most
$\tilde{O}(T^{(d+1)/(d+3)})$ swap regret after $T$ rounds.
  To achieve this, we introduce a new online learning problem we call
\emph{full swap regret minimization}. In this problem, a learner repeatedly
takes a (randomized) action in a bounded convex $d$-dimensional action set
$\mathcal{K}$ and then receives a loss from the adversary, with the goal of
minimizing their regret with respect to the \emph{worst-case} swap function
mapping $\mathcal{K}$ to $\mathcal{K}$. For varied assumptions about the
convexity and smoothness of the loss functions, we design algorithms with full
swap regret bounds ranging from $O(T^{d/(d+2)})$ to $O(T^{(d+1)/(d+2)})$.
  Finally, we apply these tools to the problem of online forecasting to
minimize calibration error, showing that several notions of calibration can be
viewed as specific instances of full swap regret. In particular, we design
efficient algorithms for online forecasting that guarantee at most $O(T^{1/3})$
$\ell_2$-calibration error and $O(\max(\sqrt{\epsilon T}, T^{1/3}))$
\emph{discretized-calibration} error (when the forecaster is restricted to
predicting multiples of $\epsilon$).
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bayesian Optimization for Simultaneous Selection of Machine Learning
  Algorithms and Hyperparameters on Shared Latent Space 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09329v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09329v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kazuki Ishikawa, Ryota Ozaki, Yohei Kanzaki, Ichiro Takeuchi, Masayuki Karasuyama
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Selecting the optimal combination of a machine learning (ML) algorithm and
its hyper-parameters is crucial for the development of high-performance ML
systems. However, since the combination of ML algorithms and hyper-parameters
is enormous, the exhaustive validation requires a significant amount of time.
Many existing studies use Bayesian optimization (BO) for accelerating the
search. On the other hand, a significant difficulty is that, in general, there
exists a different hyper-parameter space for each one of candidate ML
algorithms. BO-based approaches typically build a surrogate model independently
for each hyper-parameter space, by which sufficient observations are required
for all candidate ML algorithms. In this study, our proposed method embeds
different hyper-parameter spaces into a shared latent space, in which a
surrogate multi-task model for BO is estimated. This approach can share
information of observations from different ML algorithms by which efficient
optimization is expected with a smaller number of total observations. We
further propose the pre-training of the latent space embedding with an
adversarial regularization, and a ranking model for selecting an effective
pre-trained embedding for a given target dataset. Our empirical study
demonstrates effectiveness of the proposed method through datasets from OpenML.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Depth-Bounds for Neural Networks via the Braid Arrangement 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09324v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09324v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Moritz Grillo, Christoph Hertrich, Georg Loho
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We contribute towards resolving the open question of how many hidden layers
are required in ReLU networks for exactly representing all continuous and
piecewise linear functions on $\mathbb{R}^d$. While the question has been
resolved in special cases, the best known lower bound in general is still 2. We
focus on neural networks that are compatible with certain polyhedral complexes,
more precisely with the braid fan. For such neural networks, we prove a
non-constant lower bound of $\Omega(\log\log d)$ hidden layers required to
exactly represent the maximum of $d$ numbers. Additionally, under our
assumption, we provide a combinatorial proof that 3 hidden layers are necessary
to compute the maximum of 5 numbers; this had only been verified with an
excessive computation so far. Finally, we show that a natural generalization of
the best known upper bound to maxout networks is not tight, by demonstrating
that a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to
represent the maximum of 7 numbers.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bridging Jensen Gap for Max-Min Group Fairness Optimization in
  Recommendation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09319v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09319v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chen Xu, Yuxin Li, Wenjie Wang, Liang Pang, Jun Xu, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Group max-min fairness (MMF) is commonly used in fairness-aware recommender
systems (RS) as an optimization objective, as it aims to protect marginalized
item groups and ensures a fair competition platform. However, our theoretical
analysis indicates that integrating MMF constraint violates the assumption of
sample independence during optimization, causing the loss function to deviate
from linear additivity. Such nonlinearity property introduces the Jensen gap
between the model's convergence point and the optimal point if mini-batch
sampling is applied. Both theoretical and empirical studies show that as the
mini-batch size decreases and the group size increases, the Jensen gap will
widen accordingly. Some methods using heuristic re-weighting or debiasing
strategies have the potential to bridge the Jensen gap. However, they either
lack theoretical guarantees or suffer from heavy computational costs. To
overcome these limitations, we first theoretically demonstrate that the
MMF-constrained objective can be essentially reformulated as a group-weighted
optimization objective. Then we present an efficient and effective algorithm
named FairDual, which utilizes a dual optimization technique to minimize the
Jensen gap. Our theoretical analysis demonstrates that FairDual can achieve a
sub-linear convergence rate to the globally optimal solution and the Jensen gap
can be well bounded under a mini-batch sampling strategy with random shuffle.
Extensive experiments conducted using six large-scale RS backbone models on
three publicly available datasets demonstrate that FairDual outperforms all
baselines in terms of both accuracy and fairness. Our data and codes are shared
at https://github.com/XuChen0427/FairDual.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted in ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SigGate: Enhancing Recurrent Neural Networks with Signature-Based Gating
  Mechanisms 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09318v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09318v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rémi Genet, Hugo Inzirillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we propose a novel approach that enhances recurrent neural
networks (RNNs) by incorporating path signatures into their gating mechanisms.
Our method modifies both Long Short-Term Memory (LSTM) and Gated Recurrent Unit
(GRU) architectures by replacing their forget and reset gates, respectively,
with learnable path signatures. These signatures, which capture the geometric
features of the entire path history, provide a richer context for controlling
information flow through the network's memory. This modification allows the
networks to make memory decisions based on the full historical context rather
than just the current input and state. Through experimental studies, we
demonstrate that our Signature-LSTM (SigLSTM) and Signature-GRU (SigGRU) models
outperform their traditional counterparts across various sequential learning
tasks. By leveraging path signatures in recurrent architectures, this method
offers new opportunities to enhance performance in time series analysis and
forecasting applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Non-asymptotic Analysis of Diffusion Annealed Langevin Monte Carlo for
  Generative Modelling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09306v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09306v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Paula Cordero-Encinar, O. Deniz Akyildiz, Andrew B. Duncan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We investigate the theoretical properties of general diffusion
(interpolation) paths and their Langevin Monte Carlo implementation, referred
to as diffusion annealed Langevin Monte Carlo (DALMC), under weak conditions on
the data distribution. Specifically, we analyse and provide non-asymptotic
error bounds for the annealed Langevin dynamics where the path of distributions
is defined as Gaussian convolutions of the data distribution as in diffusion
models. We then extend our results to recently proposed heavy-tailed (Student's
t) diffusion paths, demonstrating their theoretical properties for heavy-tailed
data distributions for the first time. Our analysis provides theoretical
guarantees for a class of score-based generative models that interpolate
between a simple distribution (Gaussian or Student's t) and the data
distribution in finite time. This approach offers a broader perspective
compared to standard score-based diffusion approaches, which are typically
based on a forward Ornstein-Uhlenbeck (OU) noising process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Seamless Hierarchical Federated Learning under Intermittent
  Client Participation: A Stagewise Decision-Making Methodology 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09303v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09303v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minghong Wu, Minghui Liwang, Yuhan Su, Li Li, Seyyedali Hosseinalipour, Xianbin Wang, Huaiyu Dai, Zhenzhen Jiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Federated Learning (FL) offers a pioneering distributed learning paradigm
that enables devices/clients to build a shared global model. This global model
is obtained through frequent model transmissions between clients and a central
server, which may cause high latency, energy consumption, and congestion over
backhaul links. To overcome these drawbacks, Hierarchical Federated Learning
(HFL) has emerged, which organizes clients into multiple clusters and utilizes
edge nodes (e.g., edge servers) for intermediate model aggregations between
clients and the central server. Current research on HFL mainly focus on
enhancing model accuracy, latency, and energy consumption in scenarios with a
stable/fixed set of clients. However, addressing the dynamic availability of
clients -- a critical aspect of real-world scenarios -- remains underexplored.
This study delves into optimizing client selection and client-to-edge
associations in HFL under intermittent client participation so as to minimize
overall system costs (i.e., delay and energy), while achieving fast model
convergence. We unveil that achieving this goal involves solving a complex
NP-hard problem. To tackle this, we propose a stagewise methodology that splits
the solution into two stages, referred to as Plan A and Plan B. Plan A focuses
on identifying long-term clients with high chance of participation in
subsequent model training rounds. Plan B serves as a backup, selecting
alternative clients when long-term clients are unavailable during model
training rounds. This stagewise methodology offers a fresh perspective on
client selection that can enhance both HFL and conventional FL via enabling
low-overhead decision-making processes. Through evaluations on MNIST and
CIFAR-10 datasets, we show that our methodology outperforms existing benchmarks
in terms of model accuracy and system costs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages, 8 figures,5 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep
  Reinforcement Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09298v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09298v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Daniel Koutas, Daniel Hettegger, Kostas G. Papakonstantinou, Daniel Straub
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a novel method for Deep Reinforcement Learning (DRL),
incorporating the convex property of the value function over the belief space
in Partially Observable Markov Decision Processes (POMDPs). We introduce hard-
and soft-enforced convexity as two different approaches, and compare their
performance against standard DRL on two well-known POMDP environments, namely
the Tiger and FieldVisionRockSample problems. Our findings show that including
the convexity feature can substantially increase performance of the agents, as
well as increase robustness over the hyperparameter space, especially when
testing on out-of-distribution domains. The source code for this work can be
found at https://github.com/Dakout/Convex_DRL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ When do neural networks learn world models? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09297v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09297v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianren Zhang, Guanyu Chen, Feng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Humans develop world models that capture the underlying generation process of
data. Whether neural networks can learn similar world models remains an open
problem. In this work, we provide the first theoretical results for this
problem, showing that in a multi-task setting, models with a low-degree bias
provably recover latent data-generating variables under mild assumptions --
even if proxy tasks involve complex, non-linear functions of the latents.
However, such recovery is also sensitive to model architecture. Our analysis
leverages Boolean models of task solutions via the Fourier-Walsh transform and
introduces new techniques for analyzing invertible Boolean transforms, which
may be of independent interest. We illustrate the algorithmic implications of
our results and connect them to related research areas, including
self-supervised learning, out-of-distribution generalization, and the linear
representation hypothesis in large language models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>28 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Joint Attention Mechanism Learning to Facilitate Opto-physiological
  Monitoring during Physical Activity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09291v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09291v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaoyu Zheng, Sijung Hu, Vincent Dwyer, Mahsa Derakhshani, Laura Barrett
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Opto-physiological monitoring is a non-contact technique for measuring
cardiac signals, i.e., photoplethysmography (PPG). Quality PPG signals directly
lead to reliable physiological readings. However, PPG signal acquisition
procedures are often accompanied by spurious motion artefacts (MAs), especially
during low-to-high-intensity physical activity. This study proposes a practical
adversarial learning approach for opto-physiological monitoring by using a
generative adversarial network with an attention mechanism (AM-GAN) to model
motion noise and to allow MA removal. The AM-GAN learns an MA-resistant mapping
from raw and noisy signals to clear PPG signals in an adversarial manner,
guided by an attention mechanism to directly translate the motion reference of
triaxial acceleration to the MAs appearing in the raw signal. The AM-GAN was
experimented with three various protocols engaged with 39 subjects in various
physical activities. The average absolute error for heart rate (HR) derived
from the MA-free PPG signal via the AM-GAN, is 1.81 beats/min for the IEEE-SPC
dataset and 3.86 beats/min for the PPGDalia dataset. The same procedure applied
to an in-house LU dataset resulted in average absolute errors for HR and
respiratory rate (RR) of less than 1.37 beats/min and 2.49 breaths/min,
respectively. The study demonstrates the robustness and resilience of AM-GAN,
particularly during low-to-high-intensity physical activities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Dynamic Rolling Horizon Optimization for Network-Constrained V2X Value
  Stacking of Electric Vehicles Under Uncertainties 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09290v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09290v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Canchen Jiang, Ariel Liebman, Bo Jie, Hao Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Electric vehicle (EV) coordination can provide significant benefits through
vehicle-to-everything (V2X) by interacting with the grid, buildings, and other
EVs. This work aims to develop a V2X value-stacking framework, including
vehicle-to-building (V2B), vehicle-to-grid (V2G), and energy trading, to
maximize economic benefits for residential communities while maintaining
distribution voltage. This work also seeks to quantify the impact of prediction
errors related to building load, renewable energy, and EV arrivals. A dynamic
rolling-horizon optimization (RHO) method is employed to leverage multiple
revenue streams and maximize the potential of EV coordination. To address
energy uncertainties, including hourly local building load, local photovoltaic
(PV) generation, and EV arrivals, this work develops a Transformer-based
forecasting model named Gated Recurrent Units-Encoder-Temporal Fusion Decoder
(GRU-EN-TFD). The simulation results, using real data from Australia's National
Electricity Market, and the Independent System Operators in New England and New
York in the US, reveal that V2X value stacking can significantly reduce energy
costs. The proposed GRU-EN-TFD model outperforms the benchmark forecast model.
Uncertainties in EV arrivals have a more substantial impact on value-stacking
performance, highlighting the significance of its accurate forecast. This work
provides new insights into the dynamic interactions among residential
communities, unlocking the full potential of EV batteries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, accepted by Renewable Energy</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ An Uncertainty Principle for Linear Recurrent Neural Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09287v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09287v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Alexandre François, Antonio Orvieto, Francis Bach
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider linear recurrent neural networks, which have become a key
building block of sequence modeling due to their ability for stable and
effective long-range modeling. In this paper, we aim at characterizing this
ability on a simple but core copy task, whose goal is to build a linear filter
of order $S$ that approximates the filter that looks $K$ time steps in the past
(which we refer to as the shift-$K$ filter), where $K$ is larger than $S$.
Using classical signal models and quadratic cost, we fully characterize the
problem by providing lower bounds of approximation, as well as explicit filters
that achieve this lower bound up to constants. The optimal performance
highlights an uncertainty principle: the optimal filter has to average values
around the $K$-th time step in the past with a range~(width) that is
proportional to $K/S$.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FE-LWS: Refined Image-Text Representations via Decoder Stacking and
  Fused Encodings for Remote Sensing Image Captioning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09282v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09282v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Swadhin Das, Raksha Sharma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remote sensing image captioning aims to generate descriptive text from remote
sensing images, typically employing an encoder-decoder framework. In this
setup, a convolutional neural network (CNN) extracts feature representations
from the input image, which then guide the decoder in a sequence-to-sequence
caption generation process. Although much research has focused on refining the
decoder, the quality of image representations from the encoder remains crucial
for accurate captioning. This paper introduces a novel approach that integrates
features from two distinct CNN based encoders, capturing complementary
information to enhance caption generation. Additionally, we propose a weighted
averaging technique to combine the outputs of all GRUs in the stacked decoder.
Furthermore, a comparison-based beam search strategy is incorporated to refine
caption selection. The results demonstrate that our fusion-based approach,
along with the enhanced stacked decoder, significantly outperforms both the
transformer-based state-of-the-art model and other LSTM-based baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via
  Subgraph Injection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenlun Zhang, Enyan Dai, Kentaro Yoshioka
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
modeling data with graph structures, yet recent research reveals their
susceptibility to adversarial attacks. Traditional attack methodologies, which
rely on manipulating the original graph or adding links to artificially created
nodes, often prove impractical in real-world settings. This paper introduces a
novel adversarial scenario involving the injection of an isolated subgraph to
deceive both the link recommender and the node classifier within a GNN system.
Specifically, the link recommender is mislead to propose links between targeted
victim nodes and the subgraph, encouraging users to unintentionally establish
connections and that would degrade the node classification accuracy, thereby
facilitating a successful attack. To address this, we present the LiSA
framework, which employs a dual surrogate model and bi-level optimization to
simultaneously meet two adversarial objectives. Extensive experiments on
real-world datasets demonstrate the effectiveness of our method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ GEVRM: Goal-Expressive Video Generation Model For Robust Visual
  Manipulation <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09268v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09268v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hongyin Zhang, Pengxiang Ding, Shangke Lyu, Ying Peng, Donglin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of embodied artificial intelligence, significant
progress has been made in vision-language-action (VLA) models for general robot
decision-making. However, the majority of existing VLAs fail to account for the
inevitable external perturbations encountered during deployment. These
perturbations introduce unforeseen state information to the VLA, resulting in
inaccurate actions and consequently, a significant decline in generalization
performance. The classic internal model control (IMC) principle demonstrates
that a closed-loop system with an internal model that includes external input
signals can accurately track the reference input and effectively offset the
disturbance. We propose a novel closed-loop VLA method GEVRM that integrates
the IMC principle to enhance the robustness of robot visual manipulation. The
text-guided video generation model in GEVRM can generate highly expressive
future visual planning goals. Simultaneously, we evaluate perturbations by
simulating responses, which are called internal embeddings and optimized
through prototype contrastive learning. This allows the model to implicitly
infer and distinguish perturbations from the external environment. The proposed
GEVRM achieves state-of-the-art performance on both standard and perturbed
CALVIN benchmarks and shows significant improvements in realistic robot tasks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlocking the Potential of Classic GNNs for Graph-level Tasks: Simple
  Architectures Meet Excellence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09263v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09263v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuankai Luo, Lei Shi, Xiao-Ming Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Message-passing Graph Neural Networks (GNNs) are often criticized for their
limited expressiveness, issues like over-smoothing and over-squashing, and
challenges in capturing long-range dependencies, while Graph Transformers (GTs)
are considered superior due to their global attention mechanisms. Literature
frequently suggests that GTs outperform GNNs, particularly in graph-level tasks
such as graph classification and regression. In this study, we explore the
untapped potential of GNNs through an enhanced framework, GNN+, which
integrates six widely used techniques: edge feature integration, normalization,
dropout, residual connections, feed-forward networks, and positional encoding,
to effectively tackle graph-level tasks. We conduct a systematic evaluation of
three classic GNNs, namely GCN, GIN, and GatedGCN, enhanced by the GNN+
framework across 14 well-known graph-level datasets. Our results show that,
contrary to the prevailing belief, classic GNNs excel in graph-level tasks,
securing top three rankings across all datasets and achieving first place in
eight, while also demonstrating greater efficiency than GTs. This highlights
the potential of simple GNN architectures, challenging the belief that complex
mechanisms in GTs are essential for superior graph-level performance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Bandit Multiclass List Classification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09257v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09257v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Liad Erez, Tomer Koren
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study the problem of multiclass list classification with (semi-)bandit
feedback, where input examples are mapped into subsets of size $m$ of a
collection of $K$ possible labels, and the feedback consists of the predicted
labels which lie in the set of true labels of the given example. Our main
result is for the $(\varepsilon,\delta)$-PAC variant of the problem for which
we design an algorithm that returns an $\varepsilon$-optimal hypothesis with
high probability using a sample complexity of $O \big( (\mathrm{poly}(K/m) + sm
/ \varepsilon^2) \log (|H|/\delta) \big)$ where $H$ is the underlying (finite)
hypothesis class and $s$ is an upper bound on the number of true labels for a
given example. This bound improves upon known bounds for combinatorial
semi-bandits whenever $s \ll K$. Moreover, in the regime where $s = O(1)$ the
leading terms in our bound match the corresponding full-information rates,
implying that bandit feedback essentially comes at no cost. Our PAC learning
algorithm is also computationally efficient given access to an ERM oracle for
$H$. Additionally, we consider the regret minimization setting where data can
be generated adversarially, and establish a regret bound of $\widetilde O(|H| +
\sqrt{smT \log |H|})$. Our results generalize and extend those of Erez et al.
(2024) who consider the simpler single-label setting corresponding to $s=m=1$,
and in fact hold for the more general contextual combinatorial semi-bandit
problem with $s$-sparse rewards.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ AnomalyGFM: Graph Foundation Model for Zero/Few-shot Anomaly Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09254v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09254v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hezhe Qiao, Chaoxi Niu, Ling Chen, Guansong Pang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph anomaly detection (GAD) aims to identify abnormal nodes that differ
from the majority of the nodes in a graph, which has been attracting
significant attention in recent years. Existing generalist graph models have
achieved remarkable success in different graph tasks but struggle to generalize
to the GAD task. This limitation arises from their difficulty in learning
generalized knowledge for capturing the inherently infrequent, irregular and
heterogeneous abnormality patterns in graphs from different domains. To address
this challenge, we propose AnomalyGFM, a GAD-oriented graph foundation model
that supports zero-shot inference and few-shot prompt tuning for GAD in diverse
graph datasets. One key insight is that graph-agnostic representations for
normal and abnormal classes are required to support effective zero/few-shot GAD
across different graphs. Motivated by this, AnomalyGFM is pre-trained to align
data-independent, learnable normal and abnormal class prototypes with node
representation residuals (i.e., representation deviation of a node from its
neighbors). The residual features essentially project the node information into
a unified feature space where we can effectively measure the abnormality of
nodes from different graphs in a consistent way. This provides a driving force
for the learning of graph-agnostic, discriminative prototypes for the normal
and abnormal classes, which can be used to enable zero-shot GAD on new graphs,
including very large-scale graphs. If there are few-shot labeled normal nodes
available in the new graphs, AnomalyGFM can further support prompt tuning to
leverage these nodes for better adaptation. Comprehensive experiments on 11
widely-used GAD datasets with real anomalies, demonstrate that AnomalyGFM
significantly outperforms state-of-the-art competing methods under both zero-
and few-shot GAD settings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>14 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ On the Importance of Embedding Norms in <span class="highlight-title">Self-Supervised</span> Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrew Draganov, Sharvaree Vadgama, Sebastian Damrich, Jan Niklas Böhm, Lucas Maes, Dmitry Kobak, Erik Bekkers
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Self-supervised learning (SSL) allows training data representations without a
supervised signal and has become an important paradigm in machine learning.
Most SSL methods employ the cosine similarity between embedding vectors and
hence effectively embed data on a hypersphere. While this seemingly implies
that embedding norms cannot play any role in SSL, a few recent works have
suggested that embedding norms have properties related to network convergence
and confidence. In this paper, we resolve this apparent contradiction and
systematically establish the embedding norm's role in SSL training. Using
theoretical analysis, simulations, and experiments, we show that embedding
norms (i) govern SSL convergence rates and (ii) encode network confidence, with
smaller norms corresponding to unexpected samples. Additionally, we show that
manipulating embedding norms can have large effects on convergence speed. Our
findings demonstrate that SSL embedding norms are integral to understanding and
optimizing network behavior.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ You Do Not Fully Utilize <span class="highlight-title">Transformer</span>'s Representation Capacity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09245v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09245v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gleb Gerasimov, Yaroslav Aksenov, Nikita Balagansky, Viacheslav Sinii, Daniil Gavrilov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In contrast to RNNs, which compress previous tokens into a single hidden
state, Transformers can attend to all previous tokens directly. However,
standard Transformers only use representations from the immediately preceding
layer. In this paper, we show that this design choice causes representation
collapse and leads to suboptimal performance. To address this issue, we
introduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that
preserves the model's overall memory footprint while expanding its
representational capacity by allowing access to hidden states from earlier
layers. Through extensive experiments across various architectures and
different lookup mechanisms, we demonstrate consistent performance improvements
on a wide range of tasks. Moreover, our analysis of the learned representation
dynamics and our exploration of depthwise circuits reveal how LIMe integrates
information across layers, pointing to promising directions for future
research.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Abduction of Domain Relationships from Data for VQA 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09219v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09219v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Al Mehdi Saadat Chowdhury, Paulo Shakarian, Gerardo I. Simari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we study the problem of visual question answering (VQA) where
the image and query are represented by ASP programs that lack domain data. We
provide an approach that is orthogonal and complementary to existing knowledge
augmentation techniques where we abduce domain relationships of image
constructs from past examples. After framing the abduction problem, we provide
a baseline approach, and an implementation that significantly improves the
accuracy of query answering yet requires few examples.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Neuro-Symbolic Contrastive Learning for Cross-domain Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09213v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09213v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingyue Liu, Ryo Ueda, Zhen Wan, Katsumi Inoue, Chris G. Willcocks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Pre-trained language models (PLMs) have made significant advances in natural
language inference (NLI) tasks, however their sensitivity to textual
perturbations and dependence on large datasets indicate an over-reliance on
shallow heuristics. In contrast, inductive logic programming (ILP) excels at
inferring logical relationships across diverse, sparse and limited datasets,
but its discrete nature requires the inputs to be precisely specified, which
limits their application. This paper proposes a bridge between the two
approaches: neuro-symbolic contrastive learning. This allows for smooth and
differentiable optimisation that improves logical accuracy across an otherwise
discrete, noisy, and sparse topological space of logical functions. We show
that abstract logical relationships can be effectively embedded within a
neuro-symbolic paradigm, by representing data as logic programs and sets of
logic rules. The embedding space captures highly varied textual information
with similar semantic logical relations, but can also separate similar textual
relations that have dissimilar logical relations. Experimental results
demonstrate that our approach significantly improves the inference capabilities
of the models in terms of generalisation and reasoning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Revisiting Euclidean Alignment for Transfer Learning in EEG-Based
  Brain-Computer Interfaces 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09203v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09203v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongrui Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to the non-stationarity and large individual differences of EEG signals,
EEG-based brain-computer interfaces (BCIs) usually need subject-specific
calibration to tailor the decoding algorithm for each new subject, which is
time-consuming and user-unfriendly, hindering their real-world applications.
Transfer learning (TL) has been extensively used to expedite the calibration,
by making use of EEG data from other subjects/sessions. An important
consideration in TL for EEG-based BCIs is to reduce the data distribution
discrepancies among different subjects/session, to avoid negative transfer.
Euclidean alignment (EA) was proposed in 2020 to address this challenge.
Numerous experiments from 10 different BCI paradigms demonstrated its
effectiveness and efficiency. This paper revisits the EA, explaining its
procedure and correct usage, introducing its applications and extensions, and
pointing out potential new research directions. It should be very helpful to
BCI researchers, especially those who are working on EEG signal decoding.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Understanding High-Dimensional Bayesian Optimization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09198v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09198v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leonard Papenmeier, Matthias Poloczek, Luigi Nardi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent work reported that simple Bayesian optimization methods perform well
for high-dimensional real-world tasks, seemingly contradicting prior work and
tribal knowledge. This paper investigates the 'why'. We identify fundamental
challenges that arise in high-dimensional Bayesian optimization and explain why
recent methods succeed. Our analysis shows that vanishing gradients caused by
Gaussian process initialization schemes play a major role in the failures of
high-dimensional Bayesian optimization and that methods that promote local
search behaviors are better suited for the task. We find that maximum
likelihood estimation of Gaussian process length scales suffices for
state-of-the-art performance. Based on this, we propose a simple variant of
maximum likelihood estimation called MSR that leverages these findings to
achieve state-of-the-art performance on a comprehensive set of real-world
applications. We also present targeted experiments to illustrate and confirm
our findings.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>19 pages, 20 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generalizability through Explainability: Countering Overfitting with
  Counterfactual Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09193v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09193v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Flavio Giorgi, Fabiano Veglianti, Fabrizio Silvestri, Gabriele Tolomei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Overfitting is a well-known issue in machine learning that occurs when a
model struggles to generalize its predictions to new, unseen data beyond the
scope of its training set. Traditional techniques to mitigate overfitting
include early stopping, data augmentation, and regularization. In this work, we
demonstrate that the degree of overfitting of a trained model is correlated
with the ability to generate counterfactual examples. The higher the
overfitting, the easier it will be to find a valid counterfactual example for a
randomly chosen input data point. Therefore, we introduce CF-Reg, a novel
regularization term in the training loss that controls overfitting by ensuring
enough margin between each instance and its corresponding counterfactual.
Experiments conducted across multiple datasets and models show that our
counterfactual regularizer generally outperforms existing regularization
techniques.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Two-Stage Representation Learning for Analyzing Movement Behavior
  Dynamics in People Living with Dementia <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09173v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09173v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Cui, Alexander Capstick, Payam Barnaghi, Gregory Scott
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In remote healthcare monitoring, time series representation learning reveals
critical patient behavior patterns from high-frequency data. This study
analyzes home activity data from individuals living with dementia by proposing
a two-stage, self-supervised learning approach tailored to uncover low-rank
structures. The first stage converts time-series activities into text sequences
encoded by a pre-trained language model, providing a rich, high-dimensional
latent state space using a PageRank-based method. This PageRank vector captures
latent state transitions, effectively compressing complex behaviour data into a
succinct form that enhances interpretability. This low-rank representation not
only enhances model interpretability but also facilitates clustering and
transition analysis, revealing key behavioral patterns correlated with
clinicalmetrics such as MMSE and ADAS-COG scores. Our findings demonstrate the
framework's potential in supporting cognitive status prediction, personalized
care interventions, and large-scale health monitoring.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>AAAI 2025 Workshop on Large Language Models and Generative AI for
  Health</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LOB-Bench: Benchmarking Generative AI for Finance - an Application to
  Limit Order Book Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09172v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09172v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Peer Nagy, Sascha Frey, Kang Li, Bidipta Sarkar, Svitlana Vyetrenko, Stefan Zohren, Ani Calinescu, Jakob Foerster
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  While financial data presents one of the most challenging and interesting
sequence modelling tasks due to high noise, heavy tails, and strategic
interactions, progress in this area has been hindered by the lack of consensus
on quantitative evaluation paradigms. To address this, we present LOB-Bench, a
benchmark, implemented in python, designed to evaluate the quality and realism
of generative message-by-order data for limit order books (LOB) in the LOBSTER
format. Our framework measures distributional differences in conditional and
unconditional statistics between generated and real LOB data, supporting
flexible multivariate statistical evaluation. The benchmark also includes
features commonly used LOB statistics such as spread, order book volumes, order
imbalance, and message inter-arrival times, along with scores from a trained
discriminator network. Lastly, LOB-Bench contains "market impact metrics", i.e.
the cross-correlations and price response functions for specific events in the
data. We benchmark generative autoregressive state-space models, a (C)GAN, as
well as a parametric LOB model and find that the autoregressive GenAI approach
beats traditional model classes.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ E-MD3C: Taming Masked Diffusion <span class="highlight-title">Transformer</span>s for Efficient Zero-Shot
  Object Customization 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09164v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09164v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Trung X. Pham, Zhang Kang, Ji Woo Hong, Xuran Zheng, Chang D. Yoo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose E-MD3C ($\underline{E}$fficient $\underline{M}$asked
$\underline{D}$iffusion Transformer with Disentangled $\underline{C}$onditions
and $\underline{C}$ompact $\underline{C}$ollector), a highly efficient
framework for zero-shot object image customization. Unlike prior works reliant
on resource-intensive Unet architectures, our approach employs lightweight
masked diffusion transformers operating on latent patches, offering
significantly improved computational efficiency. The framework integrates three
core components: (1) an efficient masked diffusion transformer for processing
autoencoder latents, (2) a disentangled condition design that ensures
compactness while preserving background alignment and fine details, and (3) a
learnable Conditions Collector that consolidates multiple inputs into a compact
representation for efficient denoising and learning. E-MD3C outperforms the
existing approach on the VITON-HD dataset across metrics such as PSNR, FID,
SSIM, and LPIPS, demonstrating clear advantages in parameters, memory
efficiency, and inference speed. With only $\frac{1}{4}$ of the parameters, our
Transformer-based 468M model delivers $2.5\times$ faster inference and uses
$\frac{2}{3}$ of the GPU memory compared to an 1720M Unet-based latent
diffusion model.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 14 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Vertical Federated Continual Learning via Evolving Prototype Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09152v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09152v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuo Wang, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vertical Federated Learning (VFL) has garnered significant attention as a
privacy-preserving machine learning framework for sample-aligned feature
federation. However, traditional VFL approaches do not address the challenges
of class and feature continual learning, resulting in catastrophic forgetting
of knowledge from previous tasks. To address the above challenge, we propose a
novel vertical federated continual learning method, named Vertical Federated
Continual Learning via Evolving Prototype Knowledge (V-LETO), which primarily
facilitates the transfer of knowledge from previous tasks through the evolution
of prototypes. Specifically, we propose an evolving prototype knowledge method,
enabling the global model to retain both previous and current task knowledge.
Furthermore, we introduce a model optimization technique that mitigates the
forgetting of previous task knowledge by restricting updates to specific
parameters of the local model, thereby enhancing overall performance. Extensive
experiments conducted in both CIL and FIL settings demonstrate that our method,
V-LETO, outperforms the other state-of-the-art methods. For example, our method
outperforms the state-of-the-art method by 10.39% and 35.15% for CIL and FIL
tasks, respectively. Our code is available at
https://anonymous.4open.science/r/V-LETO-0108/README.md.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Regularization can make diffusion models more efficient 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09151v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09151v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mahsa Taheri, Johannes Lederer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models are one of the key architectures of generative AI. Their
main drawback, however, is the computational costs. This study indicates that
the concept of sparsity, well known especially in statistics, can provide a
pathway to more efficient diffusion pipelines. Our mathematical guarantees
prove that sparsity can reduce the input dimension's influence on the
computational complexity to that of a much smaller intrinsic dimension of the
data. Our empirical findings confirm that inducing sparsity can indeed lead to
better samples at a lower cost.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Shortcut Learning Susceptibility in Vision Classifiers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09150v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09150v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Pirzada Suhail, Amit Sethi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Shortcut learning, where machine learning models exploit spurious
correlations in data instead of capturing meaningful features, poses a
significant challenge to building robust and generalizable models. This
phenomenon is prevalent across various machine learning applications, including
vision, natural language processing, and speech recognition, where models may
find unintended cues that minimize training loss but fail to capture the
underlying structure of the data. Vision classifiers such as Convolutional
Neural Networks (CNNs), Multi-Layer Perceptrons (MLPs), and Vision Transformers
(ViTs) leverage distinct architectural principles to process spatial and
structural information, making them differently susceptible to shortcut
learning. In this study, we systematically evaluate these architectures by
introducing deliberate shortcuts into the dataset that are positionally
correlated with class labels, creating a controlled setup to assess whether
models rely on these artificial cues or learn actual distinguishing features.
We perform both quantitative evaluation by training on the shortcut-modified
dataset and testing them on two different test sets -- one containing the same
shortcuts and another without them -- to determine the extent of reliance on
shortcuts. Additionally, qualitative evaluation is performed by using network
inversion-based reconstruction techniques to analyze what the models
internalize in their weights, aiming to reconstruct the training data as
perceived by the classifiers. We evaluate shortcut learning behavior across
multiple benchmark datasets, including MNIST, Fashion-MNIST, SVHN, and
CIFAR-10, to compare the susceptibility of different vision classifier
architectures to shortcut reliance and assess their varying degrees of
sensitivity to spurious correlations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Feature-based Graph Attention Networks Improve Online Continual Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09143v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09143v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Adjovi Sim, Zhengkui Wang, Aik Beng Ng, Shalini De Mello, Simon See, Wonmin Byeon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online continual learning for image classification is crucial for models to
adapt to new data while retaining knowledge of previously learned tasks. This
capability is essential to address real-world challenges involving dynamic
environments and evolving data distributions. Traditional approaches
predominantly employ Convolutional Neural Networks, which are limited to
processing images as grids and primarily capture local patterns rather than
relational information. Although the emergence of transformer architectures has
improved the ability to capture relationships, these models often require
significantly larger resources. In this paper, we present a novel online
continual learning framework based on Graph Attention Networks (GATs), which
effectively capture contextual relationships and dynamically update the
task-specific representation via learned attention weights. Our approach
utilizes a pre-trained feature extractor to convert images into graphs using
hierarchical feature maps, representing information at varying levels of
granularity. These graphs are then processed by a GAT and incorporate an
enhanced global pooling strategy to improve classification performance for
continual learning. In addition, we propose the rehearsal memory duplication
technique that improves the representation of the previous tasks while
maintaining the memory budget. Comprehensive evaluations on benchmark datasets,
including SVHN, CIFAR10, CIFAR100, and MiniImageNet, demonstrate the
superiority of our method compared to the state-of-the-art methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Replay-free Online Continual Learning with <span class="highlight-title">Self-Supervised</span> MultiPatches 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09140v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09140v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giacomo Cignoni, Andrea Cossu, Alex Gomez-Villa, Joost van de Weijer, Antonio Carta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Online Continual Learning (OCL) methods train a model on a non-stationary
data stream where only a few examples are available at a time, often leveraging
replay strategies. However, usage of replay is sometimes forbidden, especially
in applications with strict privacy regulations. Therefore, we propose
Continual MultiPatches (CMP), an effective plug-in for existing OCL
self-supervised learning strategies that avoids the use of replay samples. CMP
generates multiple patches from a single example and projects them into a
shared feature space, where patches coming from the same example are pushed
together without collapsing into a single point. CMP surpasses replay and other
SSL-based strategies on OCL streams, challenging the role of replay as a go-to
solution for self-supervised OCL.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ESANN 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Trust Me, I Know the Way: Predictive Uncertainty in the Presence of
  Shortcut Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09137v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09137v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lisa Wimmer, Bernd Bischl, Ludwig Bothmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The correct way to quantify predictive uncertainty in neural networks remains
a topic of active discussion. In particular, it is unclear whether the
state-of-the art entropy decomposition leads to a meaningful representation of
model, or epistemic, uncertainty (EU) in the light of a debate that pits
ignorance against disagreement perspectives. We aim to reconcile the
conflicting viewpoints by arguing that both are valid but arise from different
learning situations. Notably, we show that the presence of shortcuts is
decisive for EU manifesting as disagreement.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Preprint. Under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Interpreting and Steering Protein Language Models through Sparse
  Autoencoders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09135v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09135v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Edith Natalia Villegas Garcia, Alessio Ansuini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancements in transformer-based language models have
revolutionized natural language processing, yet understanding the internal
mechanisms of these models remains a significant challenge. This paper explores
the application of sparse autoencoders (SAE) to interpret the internal
representations of protein language models, specifically focusing on the ESM-2
8M parameter model. By performing a statistical analysis on each latent
component's relevance to distinct protein annotations, we identify potential
interpretations linked to various protein characteristics, including
transmembrane regions, binding sites, and specialized motifs.
  We then leverage these insights to guide sequence generation, shortlisting
the relevant latent components that can steer the model towards desired targets
such as zinc finger domains. This work contributes to the emerging field of
mechanistic interpretability in biological sequence models, offering new
perspectives on model steering for sequence design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Finite-Time Analysis of Discrete-Time Stochastic Interpolants 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuhao Liu, Yu Chen, Rui Hu, Longbo Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The stochastic interpolant framework offers a powerful approach for
constructing generative models based on ordinary differential equations (ODEs)
or stochastic differential equations (SDEs) to transform arbitrary data
distributions. However, prior analyses of this framework have primarily focused
on the continuous-time setting, assuming a perfect solution of the underlying
equations. In this work, we present the first discrete-time analysis of the
stochastic interpolant framework, where we introduce an innovative
discrete-time sampler and derive a finite-time upper bound on its distribution
estimation error. Our result provides a novel quantification of how different
factors, including the distance between source and target distributions and
estimation accuracy, affect the convergence rate and also offers a new
principled way to design efficient schedules for convergence acceleration.
Finally, numerical experiments are conducted on the discrete-time sampler to
corroborate our theoretical findings.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Novel Dialect-Aware Framework for the Classification of Arabic
  Dialects and Emotions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nasser A Alsadhan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Arabic is one of the oldest languages still in use today. As a result,
several Arabic-speaking regions have developed dialects that are unique to
them. Dialect and emotion recognition have various uses in Arabic text
analysis, such as determining an online customer's origin based on their
comments. Furthermore, intelligent chatbots that are aware of a user's emotions
can respond appropriately to the user. Current research in emotion detection in
the Arabic language lacks awareness of how emotions are exhibited in different
dialects, which motivates the work found in this study. This research addresses
the problems of dialect and emotion classification in Arabic. Specifically,
this is achieved by building a novel framework that can identify and predict
Arabic dialects and emotions from a given text. The framework consists of three
modules: A text-preprocessing module, a classification module, and a clustering
module with the novel capability of building new dialect-aware emotion
lexicons. The proposed framework generated a new emotional lexicon for
different dialects. It achieved an accuracy of 88.9% in classifying Arabic
dialects, which outperforms the state-of-the-art results by 6.45 percentage
points. Furthermore, the framework achieved 89.1-79% accuracy in detecting
emotions in the Egyptian and Gulf dialects, respectively.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Improving Deep Regression with Tightness <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09122v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09122v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shihao Zhang, Yuguang Yan, Angela Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  For deep regression, preserving the ordinality of the targets with respect to
the feature representation improves performance across various tasks. However,
a theoretical explanation for the benefits of ordinality is still lacking. This
work reveals that preserving ordinality reduces the conditional entropy
$H(Z|Y)$ of representation $Z$ conditional on the target $Y$. However, our
findings reveal that typical regression losses do little to reduce $H(Z|Y)$,
even though it is vital for generalization performance. With this motivation,
we introduce an optimal transport-based regularizer to preserve the similarity
relationships of targets in the feature space to reduce $H(Z|Y)$. Additionally,
we introduce a simple yet efficient strategy of duplicating the regressor
targets, also with the aim of reducing $H(Z|Y)$. Experiments on three
real-world regression tasks verify the effectiveness of our strategies to
improve deep regression. Code:
https://github.com/needylove/Regression_tightness.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025, Code: https://github.com/needylove/Regression_tightness</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Scaling Law for Stochastic Gradient Descent in Quadratically
  Parameterized Linear Regression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.09106v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.09106v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shihong Ding, Haihan Zhang, Hanzhen Zhao, Cong Fang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In machine learning, the scaling law describes how the model performance
improves with the model and data size scaling up. From a learning theory
perspective, this class of results establishes upper and lower generalization
bounds for a specific learning algorithm. Here, the exact algorithm running
using a specific model parameterization often offers a crucial implicit
regularization effect, leading to good generalization. To characterize the
scaling law, previous theoretical studies mainly focus on linear models,
whereas, feature learning, a notable process that contributes to the remarkable
empirical success of neural networks, is regretfully vacant. This paper studies
the scaling law over a linear regression with the model being quadratically
parameterized. We consider infinitely dimensional data and slope ground truth,
both signals exhibiting certain power-law decay rates. We study convergence
rates for Stochastic Gradient Descent and demonstrate the learning rates for
variables will automatically adapt to the ground truth. As a result, in the
canonical linear regression, we provide explicit separations for generalization
curves between SGD with and without feature learning, and the
information-theoretical lower bound that is agnostic to parametrization method
and the algorithm. Our analysis for decaying ground truth provides a new
characterization for the learning dynamic of the model.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Opening Articulated Objects in the Real World 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.17767v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.17767v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Arjun Gupta, Michelle Zhang, Rishik Sathua, Saurabh Gupta
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  What does it take to build mobile manipulation systems that can competently
operate on previously unseen objects in previously unseen environments? This
work answers this question using opening of articulated objects as a mobile
manipulation testbed. Specifically, our focus is on the end-to-end performance
on this task without any privileged information, i.e. the robot starts at a
location with the novel target articulated object in view, and has to approach
the object and successfully open it. We first develop a system for this task,
and then conduct 100+ end-to-end system tests across 13 real world test sites.
Our large-scale study reveals a number of surprising findings: a) modular
systems outperform end-to-end learned systems for this task, even when the
end-to-end learned systems are trained on 1000+ demonstrations, b) perception,
and not precise end-effector control, is the primary bottleneck to task
success, and c) state-of-the-art articulation parameter estimation models
developed in isolation struggle when faced with robot-centric viewpoints.
Overall, our findings highlight the limitations of developing components of the
pipeline in isolation and underscore the need for system-level research,
providing a pragmatic roadmap for building generalizable mobile manipulation
systems. Videos, code, and models are available on the project website:
https://arjung128.github.io/opening-articulated-objects/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Project webpage:
  https://arjung128.github.io/opening-articulated-objects/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span>s Learn Low Sensitivity Functions: Investigations and
  Implications <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.06925v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.06925v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhavya Vasudeva, Deqing Fu, Tianyi Zhou, Elliott Kau, Youqi Huang, Vatsal Sharan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Transformers achieve state-of-the-art accuracy and robustness across many
tasks, but an understanding of their inductive biases and how those biases
differ from other neural network architectures remains elusive. In this work,
we identify the sensitivity of the model to token-wise random perturbations in
the input as a unified metric which explains the inductive bias of transformers
across different data modalities and distinguishes them from other
architectures. We show that transformers have lower sensitivity than MLPs,
CNNs, ConvMixers and LSTMs, across both vision and language tasks. We also show
that this low-sensitivity bias has important implications: i) lower sensitivity
correlates with improved robustness; it can also be used as an efficient
intervention to further improve the robustness of transformers; ii) it
corresponds to flatter minima in the loss landscape; and iii) it can serve as a
progress measure for grokking. We support these findings with theoretical
results showing (weak) spectral bias of transformers in the NTK regime, and
improved robustness due to the lower sensitivity. The code is available at
https://github.com/estija/sensitivity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025. 24 pages, 19 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy-Preserving Personalized Federated <span class="highlight-title">Prompt</span> Learning for Multimodal
  Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.13904v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.13904v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Linh Tran, Wei Sun, Stacy Patterson, Ana Milanova
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (LLMs) are pivotal in revolutionizing
customer support and operations by integrating multiple modalities such as
text, images, and audio. Federated Prompt Learning (FPL) is a recently proposed
approach that combines pre-trained multimodal LLMs such as vision-language
models with federated learning to create personalized, privacy-preserving AI
systems. However, balancing the competing goals of personalization,
generalization, and privacy remains a significant challenge.
Over-personalization can lead to overfitting, reducing generalizability, while
stringent privacy measures, such as differential privacy, can hinder both
personalization and generalization. In this paper, we propose a Differentially
Private Federated Prompt Learning (DP-FPL) approach to tackle this challenge by
leveraging a low-rank factorization scheme to capture generalization while
maintaining a residual term that preserves expressiveness for personalization.
To ensure privacy, we introduce a novel method where we apply local
differential privacy to the two low-rank components of the local prompt, and
global differential privacy to the global prompt. Our approach mitigates the
impact of privacy noise on the model performance while balancing the tradeoff
between personalization and generalization. Extensive experiments demonstrate
the effectiveness of our approach over other benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OGBench: Benchmarking Offline Goal-Conditioned RL <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20092v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20092v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Seohong Park, Kevin Frans, Benjamin Eysenbach, Sergey Levine
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Offline goal-conditioned reinforcement learning (GCRL) is a major problem in
reinforcement learning (RL) because it provides a simple, unsupervised, and
domain-agnostic way to acquire diverse behaviors and representations from
unlabeled data without rewards. Despite the importance of this setting, we lack
a standard benchmark that can systematically evaluate the capabilities of
offline GCRL algorithms. In this work, we propose OGBench, a new, high-quality
benchmark for algorithms research in offline goal-conditioned RL. OGBench
consists of 8 types of environments, 85 datasets, and reference implementations
of 6 representative offline GCRL algorithms. We have designed these challenging
and realistic environments and datasets to directly probe different
capabilities of algorithms, such as stitching, long-horizon reasoning, and the
ability to handle high-dimensional inputs and stochasticity. While
representative algorithms may rank similarly on prior benchmarks, our
experiments reveal stark strengths and weaknesses in these different
capabilities, providing a strong foundation for building new algorithms.
Project page: https://seohong.me/projects/ogbench
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Toward Universal Laws of Outlier Propagation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08593v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08593v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Aram Ebtekar, Yuhao Wang, Dominik Janzing
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We argue that Algorithmic Information Theory (AIT) admits a principled way to
quantify outliers in terms of so-called randomness deficiency. For the
probability distribution generated by a causal Bayesian network, we show that
the randomness deficiency of the joint state decomposes into randomness
deficiencies of each causal mechanism, subject to the Independence of
Mechanisms Principle. Accordingly, anomalous joint observations can be
quantitatively attributed to their root causes, i.e., the mechanisms that
behaved anomalously. As an extension of Levin's law of randomness conservation,
we show that weak outliers cannot cause strong ones when Independence of
Mechanisms holds. We show how these information theoretic laws provide a better
understanding of the behaviour of outliers defined with respect to existing
scores.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asymptotic Normality of Generalized Low-Rank Matrix Sensing via
  Riemannian Geometry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.10238v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.10238v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Osbert Bastani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We prove an asymptotic normality guarantee for generalized low-rank matrix
sensing -- i.e., matrix sensing under a general convex loss $\bar\ell(\langle
X,M\rangle,y^*)$, where $M\in\mathbb{R}^{d\times d}$ is the unknown rank-$k$
matrix, $X$ is a measurement matrix, and $y^*$ is the corresponding
measurement. Our analysis relies on tools from Riemannian geometry to handle
degeneracy of the Hessian of the loss due to rotational symmetry in the
parameter space. In particular, we parameterize the manifold of low-rank
matrices by $\bar\theta\bar\theta^\top$, where
$\bar\theta\in\mathbb{R}^{d\times k}$. Then, assuming the minimizer of the
empirical loss $\bar\theta^0\in\mathbb{R}^{d\times k}$ is in a constant size
ball around the true parameters $\bar\theta^*$, we prove
$\sqrt{n}(\phi^0-\phi^*)\xrightarrow{D}N(0,(H^*)^{-1})$ as $n\to\infty$, where
$\phi^0$ and $\phi^*$ are representations of $\bar\theta^*$ and $\bar\theta^0$
in the horizontal space of the Riemannian quotient manifold
$\mathbb{R}^{d\times k}/\text{O}(k)$, and $H^*$ is the Hessian of the true loss
in the same representation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TransMLA: Multi-Head Latent Attention Is All You Need 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07864v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07864v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanxu Meng, Zengwei Yao, Muhan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern large language models (LLMs) often encounter communication bottlenecks
on current hardware, rather than purely computational constraints. Multi-head
Latent Attention (MLA) tackles this challenge by using low-rank matrices in the
key-value (KV) layers, thereby allowing compressed latent KV states to be
cached. This approach significantly reduces the KV cache size relative to
traditional multi-head attention, leading to faster inference. Moreover, MLA
employs an up-projection matrix to increase expressiveness, trading additional
computation for reduced communication overhead. Although MLA has demonstrated
efficiency and effectiveness in Deepseek V2/V3/R1, many major model providers
still rely on Group Query Attention (GQA) and have not announced any plans to
adopt MLA. In this paper, we show that GQA can always be represented by MLA
while maintaining the same KV cache overhead, but the converse does not hold.
To encourage broader use of MLA, we introduce TransMLA, a post-training method
that converts widely used GQA-based pre-trained models (e.g., LLaMA, Qwen,
Mixtral) into MLA-based models. After conversion, the model can undergo
additional training to boost expressiveness without increasing the KV cache
size. Furthermore, we plan to develop MLA-specific inference acceleration
techniques to preserve low latency in transformed models, thus enabling more
efficient distillation of Deepseek R1.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>https://github.com/fxmeng/TransMLA</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WASP: A Weight-Space Approach to Detecting Learned Spuriousness 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18970v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18970v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cristian Daniel Păduraru, Antonio Bărbălau, Radu Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  It is of crucial importance to train machine learning models such that they
clearly understand what defines each class in a given task. Though there is a
sum of works dedicated to identifying the spurious correlations featured by a
dataset that may impact the model's understanding of the classes, all current
approaches rely solely on data or error analysis. That is, they cannot point
out spurious correlations learned by the model that are not already pointed out
by the counterexamples featured in the validation or training sets. We propose
a method that transcends this limitation, switching the focus from analyzing a
model's predictions to analyzing the model's weights, the mechanism behind the
making of the decisions, which proves to be more insightful. Our proposed
Weight-space Approach to detecting Spuriousness (WASP) relies on analyzing the
weights of foundation models as they drift towards capturing various (spurious)
correlations while being fine-tuned on a given dataset. We demonstrate that
different from previous works, our method (i) can expose spurious correlations
featured by a dataset even when they are not exposed by training or validation
counterexamples, (ii) it works for multiple modalities such as image and text,
and (iii) it can uncover previously untapped spurious correlations learned by
ImageNet-1k classifiers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, 6 tables, under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HorNets: Learning from Discrete and Continuous Signals with Routing
  Neural Networks <span class="chip">ACML</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.14346v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.14346v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Boshko Koloski, Nada Lavrač, Blaž Škrlj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Construction of neural network architectures suitable for learning from both
continuous and discrete tabular data is a challenging research endeavor.
Contemporary high-dimensional tabular data sets are often characterized by a
relatively small instance count, requiring data-efficient learning. We propose
HorNets (Horn Networks), a neural network architecture with state-of-the-art
performance on synthetic and real-life data sets from scarce-data tabular
domains. HorNets are based on a clipped polynomial-like activation function,
extended by a custom discrete-continuous routing mechanism that decides which
part of the neural network to optimize based on the input's cardinality. By
explicitly modeling parts of the feature combination space or combining whole
space in a linear attention-like manner, HorNets dynamically decide which mode
of operation is the most suitable for a given piece of data with no explicit
supervision. This architecture is one of the few approaches that reliably
retrieves logical clauses (including noisy XNOR) and achieves state-of-the-art
classification performance on 14 real-life biomedical high-dimensional data
sets. HorNets are made freely available under a permissive license alongside a
synthetic generator of categorical benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to the ACML conference journal track with the Machine
  Learning journal. The first and the last authors share an equal contribution</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mixed-curvature decision trees and random forests <span class="chip">ICML 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13879v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13879v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Philippe Chlenski, Quentin Chu, Raiyan R. Khan, Kaizhu Du, Antonio Khalil Moretti, Itsik Pe'er
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Decision trees (DTs) and their random forest (RF) extensions are workhorses
of classification and regression in Euclidean spaces. However, algorithms for
learning in non-Euclidean spaces are still limited. We extend DT and RF
algorithms to product manifolds: Cartesian products of several hyperbolic,
hyperspherical, or Euclidean components. Such manifolds handle heterogeneous
curvature while still factorizing neatly into simpler components, making them
compelling embedding spaces for complex datasets. Our novel angular
reformulation of DTs respects the geometry of the product manifold, yielding
splits that are geodesically convex, maximum-margin, and composable. In the
special cases of single-component manifolds, our method simplifies to its
Euclidean or hyperbolic counterparts, or introduces hyperspherical DT
algorithms, depending on the curvature. We benchmark our method on various
classification, regression, and link prediction tasks on synthetic data, graph
embeddings, mixed-curvature variational autoencoder latent spaces, and
empirical data. Compared to 7 other classifiers, product RFs ranked first on 25
out of 57 benchmarks, and placed in the top 2 for 46 out of 57. This highlights
the value of product RFs as straightforward yet powerful new tools for data
analysis in product manifolds. Code for our paper is available at
https://github.com/pchlenski/manify.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>27 pages, 11 figures. Submitted to ICML 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Conformal Predictive Portfolio Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.16333v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.16333v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Masahiro Kato
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study examines portfolio selection using predictive models for portfolio
returns. Portfolio selection is a fundamental task in finance, and a variety of
methods have been developed to achieve this goal. For instance, the
mean-variance approach constructs portfolios by balancing the trade-off between
the mean and variance of asset returns, while the quantile-based approach
optimizes portfolios by considering tail risk. These methods often depend on
distributional information estimated from historical data using predictive
models, each of which carries its own uncertainty. To address this, we propose
a framework for predictive portfolio selection via conformal prediction ,
called \emph{Conformal Predictive Portfolio Selection} (CPPS). Our approach
forecasts future portfolio returns, computes the corresponding prediction
intervals, and selects the portfolio of interest based on these intervals. The
framework is flexible and can accommodate a wide range of predictive models,
including autoregressive (AR) models, random forests, and neural networks. We
demonstrate the effectiveness of the CPPS framework by applying it to an AR
model and validate its performance through empirical studies, showing that it
delivers superior returns compared to simpler strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Optimism in the Face of Ambiguity Principle for Multi-Armed Bandits 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2409.20440v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2409.20440v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mengmeng Li, Daniel Kuhn, Bahar Taşkesen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Follow-The-Regularized-Leader (FTRL) algorithms often enjoy optimal regret
for adversarial as well as stochastic bandit problems and allow for a
streamlined analysis. Nonetheless, FTRL algorithms require the solution of an
optimization problem in every iteration and are thus computationally
challenging. In contrast, Follow-The-Perturbed-Leader (FTPL) algorithms achieve
computational efficiency by perturbing the estimates of the rewards of the
arms, but their regret analysis is cumbersome. We propose a new FTPL algorithm
that generates optimal policies for both adversarial and stochastic multi-armed
bandits. Like FTRL, our algorithm admits a unified regret analysis, and similar
to FTPL, it offers low computational costs. Unlike existing FTPL algorithms
that rely on independent additive disturbances governed by a \textit{known}
distribution, we allow for disturbances governed by an \textit{ambiguous}
distribution that is only known to belong to a given set and propose a
principle of optimism in the face of ambiguity. Consequently, our framework
generalizes existing FTPL algorithms. It also encapsulates a broad range of
FTRL methods as special cases, including several optimal ones, which appears to
be impossible with current FTPL methods. Finally, we use techniques from
discrete choice theory to devise an efficient bisection algorithm for computing
the optimistic arm sampling probabilities. This algorithm is up to $10^4$ times
faster than standard FTRL algorithms that solve an optimization problem in
every iteration. Our results not only settle existing conjectures but also
provide new insights into the impact of perturbations by mapping FTRL to FTPL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep
  Graph Networks <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.17163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.17163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Simon Heilig, Alessio Gravina, Alessandro Trenta, Claudio Gallicchio, Davide Bacciu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The dynamics of information diffusion within graphs is a critical open issue
that heavily influences graph representation learning, especially when
considering long-range propagation. This calls for principled approaches that
control and regulate the degree of propagation and dissipation of information
throughout the neural flow. Motivated by this, we introduce (port-)Hamiltonian
Deep Graph Networks, a novel framework that models neural information flow in
graphs by building on the laws of conservation of Hamiltonian dynamical
systems. We reconcile under a single theoretical and practical framework both
non-dissipative long-range propagation and non-conservative behaviors,
introducing tools from mechanical systems to gauge the equilibrium between the
two components. Our approach can be applied to general message-passing
architectures, and it provides theoretical guarantees on information
conservation in time. Empirical results prove the effectiveness of our
port-Hamiltonian scheme in pushing simple graph convolutional architectures to
state-of-the-art performance in long-range benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025 (https://openreview.net/forum?id=03EkqSCKuO)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Proxy-informed Bayesian transfer learning with unknown sources 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.03263v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.03263v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sabina J. Sloman, Julien Martinelli, Samuel Kaski
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generalization outside the scope of one's training data requires leveraging
prior knowledge about the effects that transfer, and the effects that don't,
between different data sources. Transfer learning is a framework for specifying
and refining this knowledge about sets of source (training) and target
(prediction) data. A challenging open problem is addressing the empirical
phenomenon of negative transfer, whereby the transfer learner performs worse on
the target data after taking the source data into account than before. We first
introduce a Bayesian perspective on negative transfer, and then a method to
address it. The key insight from our formulation is that negative transfer can
stem from misspecified prior information about non-transferable causes of the
source data. Our proposed method, proxy-informed robust method for
probabilistic transfer learning (PROMPT), does not require prior knowledge of
the source data (the data sources may be "unknown"). PROMPT is thus applicable
when differences between tasks are unobserved, such as in the presence of
latent confounders. Moreover, the learner need not have access to observations
in the target task (cannot "fine-tune"), and instead makes use of proxy
(indirect) information. Our theoretical results show that the threat of
negative transfer does not depend on the informativeness of the proxy
information, highlighting the usefulness of PROMPT in cases where only noisy
indirect information, such as human feedback, is available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Bias-Correction Decentralized Stochastic Gradient Algorithm with
  Momentum Acceleration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.19082v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.19082v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuchen Hu, Xi Chen, Weidong Liu, Xiaojun Mao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Distributed stochastic optimization algorithms can simultaneously process
large-scale datasets, significantly accelerating model training. However, their
effectiveness is often hindered by the sparsity of distributed networks and
data heterogeneity. In this paper, we propose a momentum-accelerated
distributed stochastic gradient algorithm, termed Exact-Diffusion with Momentum
(EDM), which mitigates the bias from data heterogeneity and incorporates
momentum techniques commonly used in deep learning to enhance convergence rate.
Our theoretical analysis demonstrates that the EDM algorithm converges
sub-linearly to the neighborhood of the optimal solution, the radius of which
is irrespective of data heterogeneity, when applied to non-convex objective
functions; under the Polyak-Lojasiewicz condition, which is a weaker assumption
than strong convexity, it converges linearly to the target region. Our analysis
techniques employed to handle momentum in complex distributed parameter update
structures yield a sufficiently tight convergence upper bound, offering a new
perspective for the theoretical analysis of other momentum-based distributed
algorithms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Importance of Backbone to the Adversarial Robustness of Object
  Detectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.17438v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.17438v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Li, Hang Chen, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Object detection is a critical component of various security-sensitive
applications, such as autonomous driving and video surveillance. However,
existing object detectors are vulnerable to adversarial attacks, which poses a
significant challenge to their reliability and security. Through experiments,
first, we found that existing works on improving the adversarial robustness of
object detectors give a false sense of security. Second, we found that
adversarially pre-trained backbone networks were essential for enhancing the
adversarial robustness of object detectors. We then proposed a simple yet
effective recipe for fast adversarial fine-tuning on object detectors with
adversarially pre-trained backbones. Without any modifications to the structure
of object detectors, our recipe achieved significantly better adversarial
robustness than previous works. Finally, we explored the potential of different
modern object detector designs for improving adversarial robustness with our
recipe and demonstrated interesting findings, which inspired us to design
state-of-the-art (SOTA) robust detectors. Our empirical results set a new
milestone for adversarially robust object detection. Code and trained
checkpoints are available at https://github.com/thu-ml/oddefense.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by IEEE TIFS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ KLay: Accelerating Arithmetic Circuits for Neurosymbolic AI 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.11415v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.11415v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jaron Maene, Vincent Derkinderen, Pedro Zuidberg Dos Martires
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A popular approach to neurosymbolic AI involves mapping logic formulas to
arithmetic circuits (computation graphs consisting of sums and products) and
passing the outputs of a neural network through these circuits. This approach
enforces symbolic constraints onto a neural network in a principled and
end-to-end differentiable way. Unfortunately, arithmetic circuits are
challenging to run on modern AI accelerators as they exhibit a high degree of
irregular sparsity. To address this limitation, we introduce knowledge layers
(KLay), a new data structure to represent arithmetic circuits that can be
efficiently parallelized on GPUs. Moreover, we contribute two algorithms used
in the translation of traditional circuit representations to KLay and a further
algorithm that exploits parallelization opportunities during circuit
evaluations. We empirically show that KLay achieves speedups of multiple orders
of magnitude over the state of the art, thereby paving the way towards scaling
neurosymbolic AI to larger real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Galois theorem for machine learning: Functions on symmetric matrices
  and point clouds via lightweight invariant features 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.08097v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.08097v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ben Blum-Smith, Ningyuan Huang, Marco Cuturi, Soledad Villar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this work, we present a mathematical formulation for machine learning of
(1) functions on symmetric matrices that are invariant with respect to the
action of permutations by conjugation, and (2) functions on point clouds that
are invariant with respect to rotations, reflections, and permutations of the
points. To achieve this, we provide a general construction of generically
separating invariant features using ideas inspired by Galois theory. We
construct $O(n^2)$ invariant features derived from generators for the field of
rational functions on $n\times n$ symmetric matrices that are invariant under
joint permutations of rows and columns. We show that these invariant features
can separate all distinct orbits of symmetric matrices except for a measure
zero set; such features can be used to universally approximate invariant
functions on almost all weighted graphs. For point clouds in a fixed dimension,
we prove that the number of invariant features can be reduced, generically
without losing expressivity, to $O(n)$, where $n$ is the number of points. We
combine these invariant features with DeepSets to learn functions on symmetric
matrices and point clouds with varying sizes. We empirically demonstrate the
feasibility of our approach on molecule property regression and point cloud
distance prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ADBM: Adversarial diffusion bridge model for reliable adversarial
  purification <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.00315v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.00315v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently Diffusion-based Purification (DiffPure) has been recognized as an
effective defense method against adversarial examples. However, we find
DiffPure which directly employs the original pre-trained diffusion models for
adversarial purification, to be suboptimal. This is due to an inherent
trade-off between noise purification performance and data recovery quality.
Additionally, the reliability of existing evaluations for DiffPure is
questionable, as they rely on weak adaptive attacks. In this work, we propose a
novel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs
a reverse bridge from the diffused adversarial data back to its original clean
examples, enhancing the purification capabilities of the original diffusion
models. Through theoretical analysis and experimental validation across various
scenarios, ADBM has proven to be a superior and robust defense mechanism,
offering significant promise for practical applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sable: a Performant, Efficient and Scalable Sequence Model for MARL 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.01706v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.01706v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Omayma Mahjoub, Sasha Abramowitz, Ruan de Kock, Wiem Khlifi, Simon du Toit, Jemma Daniel, Louay Ben Nessir, Louise Beyers, Claude Formanek, Liam Clark, Arnu Pretorius
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As multi-agent reinforcement learning (MARL) progresses towards solving
larger and more complex problems, it becomes increasingly important that
algorithms exhibit the key properties of (1) strong performance, (2) memory
efficiency and (3) scalability. In this work, we introduce Sable, a performant,
memory efficient and scalable sequence modeling approach to MARL. Sable works
by adapting the retention mechanism in Retentive Networks to achieve
computationally efficient processing of multi-agent observations with long
context memory for temporal reasoning. Through extensive evaluations across six
diverse environments, we demonstrate how Sable is able to significantly
outperform existing state-of-the-art methods in a large number of diverse tasks
(34 out of 45 tested). Furthermore, Sable maintains performance as we scale the
number of agents, handling environments with more than a thousand agents while
exhibiting a linear increase in memory usage. Finally, we conduct ablation
studies to isolate the source of Sable's performance gains and confirm its
efficient computational memory usage.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Zero-Shot Offline Imitation Learning via Optimal Transport 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08751v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08751v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thomas Rupf, Marco Bagatella, Nico Gürtler, Jonas Frey, Georg Martius
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Zero-shot imitation learning algorithms hold the promise of reproducing
unseen behavior from as little as a single demonstration at test time. Existing
practical approaches view the expert demonstration as a sequence of goals,
enabling imitation with a high-level goal selector, and a low-level
goal-conditioned policy. However, this framework can suffer from myopic
behavior: the agent's immediate actions towards achieving individual goals may
undermine long-term objectives. We introduce a novel method that mitigates this
issue by directly optimizing the occupancy matching objective that is intrinsic
to imitation learning. We propose to lift a goal-conditioned value function to
a distance between occupancies, which are in turn approximated via a learned
world model. The resulting method can learn from offline, suboptimal data, and
is capable of non-myopic, zero-shot imitation, as we demonstrate in complex,
continuous benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Better Embeddings with Coupled Adam 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Felix Stollenwerk, Tobias Stollenwerk
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their remarkable capabilities, LLMs learn word representations that
exhibit the undesirable yet poorly understood feature of anisotropy. In this
paper, we argue that the second moment in Adam is a cause of anisotropic
embeddings, and suggest a modified optimizer called Coupled Adam to mitigate
the problem. Our experiments demonstrate that Coupled Adam significantly
improves the quality of embeddings, while also leading to better upstream and
downstream performance on large enough datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures; figures corrected</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The LLM Language Network: A Neuroscientific Approach for Identifying
  Causally Task-Relevant Units <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02280v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02280v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Badr AlKhamissi, Greta Tuckute, Antoine Bosselut, Martin Schrimpf
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) exhibit remarkable capabilities on not just
language tasks, but also various tasks that are not linguistic in nature, such
as logical reasoning and social inference. In the human brain, neuroscience has
identified a core language system that selectively and causally supports
language processing. We here ask whether similar specialization for language
emerges in LLMs. We identify language-selective units within 18 popular LLMs,
using the same localization approach that is used in neuroscience. We then
establish the causal role of these units by demonstrating that ablating LLM
language-selective units -- but not random units -- leads to drastic deficits
in language tasks. Correspondingly, language-selective LLM units are more
aligned to brain recordings from the human language system than random units.
Finally, we investigate whether our localization method extends to other
cognitive domains: while we find specialized networks in some LLMs for
reasoning and social capabilities, there are substantial differences among
models. These findings provide functional and causal evidence for
specialization in large language models, and highlight parallels with the
functional organization in the brain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Impact of Batch Normalization on Convolutional Network Representations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.14441v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.14441v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hermanus L. Potgieter, Coenraad Mouton, Marelie H. Davel
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Batch normalization (BatchNorm) is a popular layer normalization technique
used when training deep neural networks. It has been shown to enhance the
training speed and accuracy of deep learning models. However, the mechanics by
which BatchNorm achieves these benefits is an active area of research, and
different perspectives have been proposed. In this paper, we investigate the
effect of BatchNorm on the resulting hidden representations, that is, the
vectors of activation values formed as samples are processed at each hidden
layer. Specifically, we consider the sparsity of these representations, as well
as their implicit clustering -- the creation of groups of representations that
are similar to some extent. We contrast image classification models trained
with and without batch normalization and highlight consistent differences
observed. These findings highlight that BatchNorm's effect on representational
sparsity is not a significant factor affecting generalization, while the
representations of models trained with BatchNorm tend to show more advantageous
clustering characteristics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Crime Forecasting: A Spatio-temporal Analysis with Deep Learning Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07465v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07465v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Mao, Wei Du, Shuo Wen, Qi Li, Tong Zhang, Wei Zhong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This study uses deep-learning models to predict city partition crime counts
on specific days. It helps police enhance surveillance, gather intelligence,
and proactively prevent crimes. We formulate crime count prediction as a
spatiotemporal sequence challenge, where both input data and prediction targets
are spatiotemporal sequences. In order to improve the accuracy of crime
forecasting, we introduce a new model that combines Convolutional Neural
Networks (CNN) and Long Short-Term Memory (LSTM) networks. We conducted a
comparative analysis to access the effects of various data sequences, including
raw and binned data, on the prediction errors of four deep learning forecasting
models. Directly inputting raw crime data into the forecasting model causes
high prediction errors, making the model unsuitable for real - world use. The
findings indicate that the proposed CNN-LSTM model achieves optimal performance
when crime data is categorized into 10 or 5 groups. Data binning can enhance
forecasting model performance, but poorly defined intervals may reduce map
granularity. Compared to dividing into 5 bins, binning into 10 intervals
strikes an optimal balance, preserving data characteristics and surpassing raw
data in predictive modelling efficacy.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The paper was submitted without the consent of all co-authors. The
  content of the paper is incomplete and requires substantial additional work
  before it can be considered a complete and coherent submission</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Privacy-Preserving Federated Unsupervised Domain Adaptation for
  Regression on Small-Scale and High-Dimensional Biological Data 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.17287v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.17287v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cem Ata Baykara, Ali Burak Ünal, Nico Pfeifer, Mete Akgün
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning models often struggle with generalization in small,
heterogeneous datasets due to domain shifts caused by variations in data
collection and population differences. This challenge is particularly
pronounced in biological data, where data is high-dimensional, small-scale, and
decentralized across institutions. While federated domain adaptation methods
(FDA) aim to address these challenges, most existing approaches rely on deep
learning and focus on classification tasks, making them unsuitable for
small-scale, high-dimensional applications. In this work, we propose freda, a
privacy-preserving federated method for unsupervised domain adaptation in
regression tasks. Unlike deep learning-based FDA approaches, freda is the first
method to enable the federated training of Gaussian Processes to model complex
feature relationships while ensuring complete data privacy through randomized
encoding and secure aggregation. This allows for effective domain adaptation
without direct access to raw data, making it well-suited for applications
involving high-dimensional, heterogeneous datasets. We evaluate freda on the
challenging task of age prediction from DNA methylation data, demonstrating
that it achieves performance comparable to the centralized state-of-the-art
method while preserving complete data privacy.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Regret Bounds for Episodic Risk-Sensitive Linear Quadratic Regulator 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.05366v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.05366v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhao Xu, Xuefeng Gao, Xuedong He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Risk-sensitive linear quadratic regulator is one of the most fundamental
problems in risk-sensitive optimal control. In this paper, we study online
adaptive control of risk-sensitive linear quadratic regulator in the finite
horizon episodic setting. We propose a simple least-squares greedy algorithm
and show that it achieves $\widetilde{\mathcal{O}}(\log N)$ regret under a
specific identifiability assumption, where $N$ is the total number of episodes.
If the identifiability assumption is not satisfied, we propose incorporating
exploration noise into the least-squares-based algorithm, resulting in an
algorithm with $\widetilde{\mathcal{O}}(\sqrt{N})$ regret. To our best
knowledge, this is the first set of regret bounds for episodic risk-sensitive
linear quadratic regulator. Our proof relies on perturbation analysis of
less-standard Riccati equations for risk-sensitive linear quadratic control,
and a delicate analysis of the loss in the risk-sensitive performance criterion
due to applying the suboptimal controller in the online learning process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04708v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04708v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengxin Hu, Hao Li, Yihe Yuan, Jing Li, Ivor Tsang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Following the milestones in large language models (LLMs) and multimodal
models, we have seen a surge in applying LLMs to biochemical tasks. Leveraging
graph features and molecular text representations, LLMs can tackle various
tasks, such as predicting chemical reaction outcomes and describing molecular
properties. However, most current work overlooks the *multi-level nature* of
the graph modality, even though different chemistry tasks may benefit from
different feature levels. In this work, we first study the effect of feature
granularity and reveal that even reducing all GNN-generated feature tokens to a
single one does not significantly impact model performance. We then investigate
the effect of various graph feature levels and demonstrate that both the
quality of LLM-generated molecules and model performance across different tasks
depend on different graph feature levels. Therefore, we conclude with two key
insights: (1) current molecular-related multimodal LLMs lack a comprehensive
understanding of graph features, and (2) static processing is not sufficient
for hierarchical graph feature. We share our findings in detail, with the hope
of paving the way for the community to develop more advanced multimodal LLMs
for incorporating molecular graphs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages, 4 tables, 1 figure, paper under review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Diffusion-LAM: Probabilistic Limited Area Weather Forecasting with
  Diffusion 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07532v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07532v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Larsson, Joel Oskarsson, Tomas Landelius, Fredrik Lindsten
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning methods have been shown to be effective for weather
forecasting, based on the speed and accuracy compared to traditional numerical
models. While early efforts primarily concentrated on deterministic
predictions, the field has increasingly shifted toward probabilistic
forecasting to better capture the forecast uncertainty. Most machine
learning-based models have been designed for global-scale predictions, with
only limited work targeting regional or limited area forecasting, which allows
more specialized and flexible modeling for specific locations. This work
introduces Diffusion-LAM, a probabilistic limited area weather model leveraging
conditional diffusion. By conditioning on boundary data from surrounding
regions, our approach generates forecasts within a defined area. Experimental
results on the MEPS limited area dataset demonstrate the potential of
Diffusion-LAM to deliver accurate probabilistic forecasts, highlighting its
promise for limited-area weather prediction.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Noise Matters: Diffusion Model-based Urban Mobility Generation with
  Collaborative Noise Priors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.05000v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.05000v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuheng Zhang, Yuan Yuan, Jingtao Ding, Jian Yuan, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With global urbanization, the focus on sustainable cities has largely grown,
driving research into equity, resilience, and urban planning, which often
relies on mobility data. The rise of web-based apps and mobile devices has
provided valuable user data for mobility-related research. However, real-world
mobility data is costly and raises privacy concerns. To protect privacy while
retaining key features of real-world movement, the demand for synthetic data
has steadily increased. Recent advances in diffusion models have shown great
potential for mobility trajectory generation due to their ability to model
randomness and uncertainty. However, existing approaches often directly apply
identically distributed (i.i.d.) noise sampling from image generation
techniques, which fail to account for the spatiotemporal correlations and
social interactions that shape urban mobility patterns. In this paper, we
propose CoDiffMob, a diffusion model for urban mobility generation with
collaborative noise priors, we emphasize the critical role of noise in
diffusion models for generating mobility data. By leveraging both individual
movement characteristics and population-wide dynamics, we construct novel
collaborative noise priors that provide richer and more informative guidance
throughout the generation process. Extensive experiments demonstrate the
superiority of our method, with generated data accurately capturing both
individual preferences and collective patterns, achieving an improvement of
over 32%. Furthermore, it can effectively replace web-derived mobility data to
better support downstream applications, while safeguarding user privacy and
fostering a more secure and ethical web. This highlights its tremendous
potential for applications in sustainable city-related research. The code and
data are available at https://github.com/tsinghua-fib-lab/CoDiffMob.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16839v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16839v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christian Wald, Gabriele Steidl
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Among generative neural models, flow matching techniques stand out for their
simple applicability and good scaling properties. Here, velocity fields of
curves connecting a simple latent and a target distribution are learned. Then
the corresponding ordinary differential equation can be used to sample from a
target distribution, starting in samples from the latent one. This paper
reviews from a mathematical point of view different techniques to learn the
velocity fields of absolutely continuous curves in the Wasserstein geometry. We
show how the velocity fields can be characterized and learned via i) transport
plans (couplings) between latent and target distributions, ii) Markov kernels
and iii) stochastic processes, where the latter two include the coupling
approach, but are in general broader. Besides this main goal, we show how flow
matching can be used for solving Bayesian inverse problems, where the
definition of conditional Wasserstein distances plays a central role. Finally,
we briefly address continuous normalizing flows and score matching techniques,
which approach the learning of velocity fields of curves from other directions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tighter sparse variational Gaussian processes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04750v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04750v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Thang D. Bui, Matthew Ashman, Richard E. Turner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sparse variational Gaussian process (GP) approximations based on inducing
points have become the de facto standard for scaling GPs to large datasets,
owing to their theoretical elegance, computational efficiency, and ease of
implementation. This paper introduces a provably tighter variational
approximation by relaxing the standard assumption that the conditional
approximate posterior given the inducing points must match that in the prior.
The key innovation is to modify the conditional posterior to have smaller
variances than that of the prior at the training points. We derive the
collapsed bound for the regression case, describe how to use the proposed
approximation in large data settings, and discuss its application to handle
orthogonally structured inducing points and GP latent variable models.
Extensive experiments on regression benchmarks, classification, and latent
variable models demonstrate that the proposed approximation consistently
matches or outperforms standard sparse variational GPs while maintaining the
same computational cost. An implementation will be made available in all
popular GP packages.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Feature contamination: Neural networks learn uncorrelated features and
  fail to generalize <span class="chip">ICML 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.03345v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.03345v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianren Zhang, Chujie Zhao, Guanyu Chen, Yizhou Jiang, Feng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning representations that generalize under distribution shifts is
critical for building robust machine learning models. However, despite
significant efforts in recent years, algorithmic advances in this direction
have been limited. In this work, we seek to understand the fundamental
difficulty of out-of-distribution generalization with deep neural networks. We
first empirically show that perhaps surprisingly, even allowing a neural
network to explicitly fit the representations obtained from a teacher network
that can generalize out-of-distribution is insufficient for the generalization
of the student network. Then, by a theoretical study of two-layer ReLU networks
optimized by stochastic gradient descent (SGD) under a structured feature
model, we identify a fundamental yet unexplored feature learning proclivity of
neural networks, feature contamination: neural networks can learn uncorrelated
features together with predictive features, resulting in generalization failure
under distribution shifts. Notably, this mechanism essentially differs from the
prevailing narrative in the literature that attributes the generalization
failure to spurious correlations. Overall, our results offer new insights into
the non-linear feature learning dynamics of neural networks and highlight the
necessity of considering inductive biases in out-of-distribution
generalization.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ICML 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A method of supervised learning from conflicting data with hidden
  contexts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2108.12113v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2108.12113v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianren Zhang, Yizhou Jiang, Feng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conventional supervised learning assumes a stable input-output relationship.
However, this assumption fails in open-ended training settings where the
input-output relationship depends on hidden contexts. In this work, we
formulate a more general supervised learning problem in which training data is
drawn from multiple unobservable domains, each potentially exhibiting distinct
input-output maps. This inherent conflict in data renders standard empirical
risk minimization training ineffective. To address this challenge, we propose a
method LEAF that introduces an allocation function, which learns to assign
conflicting data to different predictive models. We establish a connection
between LEAF and a variant of the Expectation-Maximization algorithm, allowing
us to derive an analytical expression for the allocation function. Finally, we
provide a theoretical analysis of LEAF and empirically validate its
effectiveness on both synthetic and real-world tasks involving conflicting
data.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>35 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Statistical Inference for Temporal Difference Learning with Linear
  Function Approximation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.16106v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.16106v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weichen Wu, Gen Li, Yuting Wei, Alessandro Rinaldo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Statistical inference with finite-sample validity for the value function of a
given policy in Markov decision processes (MDPs) is crucial for ensuring the
reliability of reinforcement learning. Temporal Difference (TD) learning,
arguably the most widely used algorithm for policy evaluation, serves as a
natural framework for this purpose. In this paper, we study the consistency
properties of TD learning with Polyak-Ruppert averaging and linear function
approximation, and obtain three significant improvements over existing results.
First, we derive a novel sharp high-dimensional probability convergence
guarantee that depends explicitly on the asymptotic variance and holds under
weak conditions. We further establish refined high-dimensional Berry-Esseen
bounds over the class of convex sets that guarantee faster rates than those in
the literature. Finally, we propose a plug-in estimator for the asymptotic
covariance matrix, designed for efficient online computation. These results
enable the construction of confidence regions and simultaneous confidence
intervals for the linear parameters of the value function, with guaranteed
finite-sample coverage. We demonstrate the applicability of our theoretical
findings through numerical experiments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Online Scheduling for LLM Inference with KV Cache Constraints 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07115v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07115v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Patrick Jaillet, Jiashuo Jiang, Chara Podimata, Zijie Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Model (LLM) inference, where a trained model generates text
one word at a time in response to user prompts, is a computationally intensive
process requiring efficient scheduling to optimize latency and resource
utilization. A key challenge in LLM inference is the management of the
Key-Value (KV) cache, which reduces redundant computations but introduces
memory constraints. In this work, we model LLM inference with KV cache
constraints theoretically and propose novel batching and scheduling algorithms
that minimize inference latency while effectively managing the KV cache's
memory.
  We analyze both semi-online and fully online scheduling models, and our
results are threefold. First, we provide a polynomial-time algorithm that
achieves exact optimality in terms of average latency in the semi-online prompt
arrival model. Second, in the fully online case with a stochastic prompt
arrival, we introduce an efficient online scheduling algorithm with constant
regret. Third, we prove that no algorithm (deterministic or randomized) can
achieve a constant competitive ratio in fully online adversarial settings. Our
empirical evaluations on a public LLM inference dataset, using the Llama-70B
model on A100 GPUs, show that our approach significantly outperforms benchmark
algorithms used currently in practice, achieving lower latency while reducing
energy consumption. Overall, our results offer a path toward more sustainable
and cost-effective LLM deployment.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ WGFormer: An SE(3)-<span class="highlight-title">Transformer</span> Driven by Wasserstein Gradient Flows for
  Molecular Ground-State Conformation Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.09795v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.09795v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Fanmeng Wang, Minjie Cheng, Hongteng Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Predicting molecular ground-state conformation (i.e., energy-minimized
conformation) is crucial for many chemical applications such as molecular
docking and property prediction. Classic energy-based simulation is
time-consuming when solving this problem while existing learning-based methods
have advantages in computational efficiency but sacrifice accuracy and
interpretability. In this work, we propose a novel and effective method to
bridge the energy-based simulation and the learning-based strategy, which
designs and learns a Wasserstein gradient flow-driven SE(3)-Transformer, called
WGFormer, for molecular ground-state conformation prediction. Specifically, our
method tackles this task within an auto-encoding framework, which encodes
low-quality conformations by the proposed WGFormer and decodes corresponding
ground-state conformations by an MLP. The architecture of WGFormer corresponds
to Wasserstein gradient flows -- it optimizes molecular conformations by
minimizing an energy function defined on the latent mixture models of atoms,
thereby significantly improving performance and interpretability. Extensive
experiments show that our method consistently outperforms state-of-the-art
competitors, providing a new and insightful paradigm to predict molecular
ground-state conformation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rendering Wireless Environments Useful for Gradient Estimators: A
  Zero-Order Stochastic Federated Learning Method 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.17460v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.17460v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elissa Mhanna, Mohamad Assaad
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Cross-device federated learning (FL) is a growing machine learning setting
whereby multiple edge devices collaborate to train a model without disclosing
their raw data. With the great number of mobile devices participating in more
FL applications via the wireless environment, the practical implementation of
these applications will be hindered due to the limited uplink capacity of
devices, causing critical bottlenecks. In this work, we propose a novel doubly
communication-efficient zero-order (ZO) method with a one-point gradient
estimator that replaces communicating long vectors with scalar values and that
harnesses the nature of the wireless communication channel, overcoming the need
to know the channel state coefficient. It is the first method that includes the
wireless channel in the learning algorithm itself instead of wasting resources
to analyze it and remove its impact. We then offer a thorough analysis of the
proposed zero-order federated learning (ZOFL) framework and prove that our
method converges \textit{almost surely}, which is a novel result in nonconvex
ZO optimization. We further prove a convergence rate of
$O(\frac{1}{\sqrt[3]{K}})$ in the nonconvex setting. We finally demonstrate the
potential of our algorithm with experimental results.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Copyright in Generative Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2105.09266v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2105.09266v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giorgio Franceschelli, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine-generated artworks are now part of the contemporary art scene: they
are attracting significant investments and they are presented in exhibitions
together with those created by human artists. These artworks are mainly based
on generative deep learning techniques, which have seen a formidable
development and remarkable refinement in the very recent years. Given the
inherent characteristics of these techniques, a series of novel legal problems
arise. In this article, we consider a set of key questions in the area of
generative deep learning for the arts, including the following: is it possible
to use copyrighted works as training set for generative models? How do we
legally store their copies in order to perform the training process? Who (if
someone) will own the copyright on the generated data? We try to answer these
questions considering the law in force in both the United States of America and
the European Union, and potential future alternatives. We then extend our
analysis to code generation, which is an emerging area of generative deep
learning. Finally, we also formulate a set of practical guidelines for artists
and developers working on deep learning generated art, as well as some policy
suggestions for policymakers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in Data & Policy at
  https://www.cambridge.org/core/journals/data-and-policy/article/copyright-in-generative-deep-learning/C401539FDF79A6AC6CEE8C5256508B5E</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Creativity and Machine Learning: A <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2104.02726v7">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2104.02726v7.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Giorgio Franceschelli, Mirco Musolesi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a growing interest in the area of machine learning and creativity.
This survey presents an overview of the history and the state of the art of
computational creativity theories, key machine learning techniques (including
generative deep learning), and corresponding automatic evaluation methods.
After presenting a critical discussion of the key contributions in this area,
we outline the current research challenges and emerging opportunities in this
field.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published in ACM Computing Surveys at
  https://dl.acm.org/doi/10.1145/3664595</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Geometry-aware RL for Manipulation of Varying Shapes and Deformable
  Objects <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07005v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07005v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tai Hoang, Huy Le, Philipp Becker, Vien Anh Ngo, Gerhard Neumann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Manipulating objects with varying geometries and deformable objects is a
major challenge in robotics. Tasks such as insertion with different objects or
cloth hanging require precise control and effective modelling of complex
dynamics. In this work, we frame this problem through the lens of a
heterogeneous graph that comprises smaller sub-graphs, such as actuators and
objects, accompanied by different edge types describing their interactions.
This graph representation serves as a unified structure for both rigid and
deformable objects tasks, and can be extended further to tasks comprising
multiple actuators. To evaluate this setup, we present a novel and challenging
reinforcement learning benchmark, including rigid insertion of diverse objects,
as well as rope and cloth manipulation with multiple end-effectors. These tasks
present a large search space, as both the initial and target configurations are
uniformly sampled in 3D space. To address this issue, we propose a novel
graph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi),
utilizing $SE(3)$ equivariant message passing networks as the main backbone to
exploit the geometric symmetry. In addition, by modeling explicit
heterogeneity, HEPi can outperform Transformer-based and non-heterogeneous
equivariant policies in terms of average returns, sample efficiency, and
generalization to unseen objects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at ICLR 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Progressive-Resolution Policy Distillation: Leveraging Coarse-Resolution
  Simulations for Time-Efficient Fine-Resolution Policy Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.07477v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.07477v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuki Kadokawa, Hirotaka Tahara, Takamitsu Matsubara
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In earthwork and construction, excavators often encounter large rocks mixed
with various soil conditions, requiring skilled operators. This paper presents
a framework for achieving autonomous excavation using reinforcement learning
(RL) through a rock excavation simulator. In the simulation, resolution can be
defined by the particle size/number in the whole soil space. Fine-resolution
simulations closely mimic real-world behavior but demand significant
calculation time and challenging sample collection, while coarse-resolution
simulations enable faster sample collection but deviate from real-world
behavior. To combine the advantages of both resolutions, we explore using
policies developed in coarse-resolution simulations for pre-training in
fine-resolution simulations. To this end, we propose a novel policy learning
framework called Progressive-Resolution Policy Distillation (PRPD), which
progressively transfers policies through some middle-resolution simulations
with conservative policy transfer to avoid domain gaps that could lead to
policy transfer failure. Validation in a rock excavation simulator and nine
real-world rock environments demonstrated that PRPD reduced sampling time to
less than 1/7 while maintaining task success rates comparable to those achieved
through policy learning in a fine-resolution simulation.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Asymmetrical estimator for training encapsulated deep photonic neural
  networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.18458v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.18458v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yizhi Wang, Minjia Chen, Chunhui Yao, Jie Ma, Ting Yan, Richard Penty, Qixiang Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Photonic neural networks (PNNs) are fast in-propagation and high bandwidth
paradigms that aim to popularize reproducible NN acceleration with higher
efficiency and lower cost. However, the training of PNN is known to be
challenging, where the device-to-device and system-to-system variations create
imperfect knowledge of the PNN. Despite backpropagation (BP)-based training
algorithms being the industry standard for their robustness, generality, and
fast gradient convergence for digital training, existing PNN-BP methods rely
heavily on accurate intermediate state extraction or extensive computational
resources for deep PNNs (DPNNs). The truncated photonic signal propagation and
the computation overhead bottleneck DPNN's operation efficiency and increase
system construction cost. Here, we introduce the asymmetrical training (AsyT)
method, tailored for encapsulated DPNNs, where the signal is preserved in the
analogue photonic domain for the entire structure. AsyT offers a lightweight
solution for DPNNs with minimum readouts, fast and energy-efficient operation,
and minimum system footprint. AsyT's ease of operation, error tolerance, and
generality aim to promote PNN acceleration in a widened operational scenario
despite the fabrication variations and imperfect controls. We demonstrated AsyT
for encapsulated DPNN with integrated photonic chips, repeatably enhancing the
performance from in-silico BP for different network structures and datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Exogenous Matching: Learning Good Proposals for Tractable Counterfactual
  Estimation <span class="chip">NeurIPS 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.13914v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.13914v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yikang Chen, Dehui Du, Lili Tian
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We propose an importance sampling method for tractable and efficient
estimation of counterfactual expressions in general settings, named Exogenous
Matching. By minimizing a common upper bound of counterfactual estimators, we
transform the variance minimization problem into a conditional distribution
learning problem, enabling its integration with existing conditional
distribution modeling approaches. We validate the theoretical results through
experiments under various types and settings of Structural Causal Models (SCMs)
and demonstrate the outperformance on counterfactual estimation tasks compared
to other existing importance sampling methods. We also explore the impact of
injecting structural prior knowledge (counterfactual Markov boundaries) on the
results. Finally, we apply this method to identifiable proxy SCMs and
demonstrate the unbiasedness of the estimates, empirically illustrating the
applicability of the method to practical scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>51 pages, 15 figures. Accepted at NeurIPS 2024, see
  https://papers.nips.cc/paper_files/paper/2024/hash/ee94bf235482e4c1f689c04c81656dbf-Abstract-Conference.html</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Geospatial Trajectory Generation via Efficient Abduction: Deployment for
  Independent Testing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.06447v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.06447v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Divyagna Bavikadi, Dyuman Aditya, Devendra Parkar, Paulo Shakarian, Graham Mueller, Chad Parvis, Gerardo I. Simari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The ability to generate artificial human movement patterns while meeting
location and time constraints is an important problem in the security
community, particularly as it enables the study of the analog problem of
detecting such patterns while maintaining privacy. We frame this problem as an
instance of abduction guided by a novel parsimony function represented as an
aggregate truth value over an annotated logic program. This approach has the
added benefit of affording explainability to an analyst user. By showing that
any subset of such a program can provide a lower bound on this parsimony
requirement, we are able to abduce movement trajectories efficiently through an
informed (i.e., A*) search. We describe how our implementation was enhanced
with the application of multiple techniques in order to be scaled and
integrated with a cloud-based software stack that included bottom-up rule
learning, geolocated knowledge graph retrieval/management, and interfaces with
government systems for independently conducted government-run tests for which
we provide results. We also report on our own experiments showing that we not
only provide exact results but also scale to very large scenarios and provide
realistic agent trajectories that can go undetected by machine learning anomaly
detectors.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In Proceedings ICLP 2024, arXiv:2502.08453</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Simple yet Effective DDG Predictor is An Unsupervised Antibody
  Optimizer and Explainer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06913v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06913v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Guojiang Zhao, Zhifeng Gao, Stan Z. Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The proteins that exist today have been optimized over billions of years of
natural evolution, during which nature creates random mutations and selects
them. The discovery of functionally promising mutations is challenged by the
limited evolutionary accessible regions, i.e., only a small region on the
fitness landscape is beneficial. There have been numerous priors used to
constrain protein evolution to regions of landscapes with high-fitness
variants, among which the change in binding free energy (DDG) of protein
complexes upon mutations is one of the most commonly used priors. However, the
huge mutation space poses two challenges: (1) how to improve the efficiency of
DDG prediction for fast mutation screening; and (2) how to explain mutation
preferences and efficiently explore accessible evolutionary regions. To address
these challenges, we propose a lightweight DDG predictor (Light-DDG), which
adopts a structure-aware Transformer as the backbone and enhances it by
knowledge distilled from existing powerful but computationally heavy DDG
predictors. Additionally, we augmented, annotated, and released a large-scale
dataset containing millions of mutation data for pre-training Light-DDG. We
find that such a simple yet effective Light-DDG can serve as a good
unsupervised antibody optimizer and explainer. For the target antibody, we
propose a novel Mutation Explainer to learn mutation preferences, which
accounts for the marginal benefit of each mutation per residue. To further
explore accessible evolutionary regions, we conduct preference-guided antibody
optimization and evaluate antibody candidates quickly using Light-DDG to
identify desirable mutations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Data-driven Modeling of Combined Sewer Systems for Urban Sustainability:
  An Empirical Evaluation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11619v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11619v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vipin Singh, Tianheng Ling, Teodor Chiaburu, Felix Biessmann
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Climate change poses complex challenges, with extreme weather events becoming
increasingly frequent and difficult to model. Examples include the dynamics of
Combined Sewer Systems (CSS). Overburdened CSS during heavy rainfall will
overflow untreated wastewater into surface water bodies. Classical approaches
to modeling the impact of extreme rainfall events rely on physical simulations,
which are particularly challenging to create for large urban infrastructures.
Deep Learning (DL) models offer a cost-effective alternative for modeling the
complex dynamics of sewer systems. In this study, we present a comprehensive
empirical evaluation of several state-of-the-art DL time series models for
predicting sewer system dynamics in a large urban infrastructure, utilizing
three years of measurement data. We especially investigate the potential of DL
models to maintain predictive precision during network outages by comparing
global models, which have access to all variables within the sewer system, and
local models, which are limited to data from a restricted set of local sensors.
Our findings demonstrate that DL models can accurately predict the dynamics of
sewer system load, even under network outage conditions. These results suggest
that DL models can effectively aid in balancing the load redistribution in CSS,
thereby enhancing the sustainability and resilience of urban infrastructures.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages, 4 figures, accepted at 2nd Workshop on 'Public Interest AI'
  co-located with 47th German Conference on Artificial Intelligence, Wuerzburg
  23rd September 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Predicting Safety Misbehaviours in Autonomous Driving Systems using
  Uncertainty Quantification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.18573v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.18573v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruben Grewal, Paolo Tonella, Andrea Stocco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The automated real-time recognition of unexpected situations plays a crucial
role in the safety of autonomous vehicles, especially in unsupported and
unpredictable scenarios. This paper evaluates different Bayesian uncertainty
quantification methods from the deep learning domain for the anticipatory
testing of safety-critical misbehaviours during system-level simulation-based
testing. Specifically, we compute uncertainty scores as the vehicle executes,
following the intuition that high uncertainty scores are indicative of
unsupported runtime conditions that can be used to distinguish safe from
failure-inducing driving behaviors. In our study, we conducted an evaluation of
the effectiveness and computational overhead associated with two Bayesian
uncertainty quantification methods, namely MC- Dropout and Deep Ensembles, for
misbehaviour avoidance. Overall, for three benchmarks from the Udacity
simulator comprising both out-of-distribution and unsafe conditions introduced
via mutation testing, both methods successfully detected a high number of
out-of-bounds episodes providing early warnings several seconds in advance,
outperforming two state-of-the-art misbehaviour prediction methods based on
autoencoders and attention maps in terms of effectiveness and efficiency.
Notably, Deep Ensembles detected most misbehaviours without any false alarms
and did so even when employing a relatively small number of models, making them
computationally feasible for real-time detection. Our findings suggest that
incorporating uncertainty quantification methods is a viable approach for
building fail-safe mechanisms in deep neural network-based autonomous vehicles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>In proceedings of the 17th IEEE International Conference on Software
  Testing, Verification and Validation 2024 (ICST '24)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ On the Regularization of Learnable Embeddings for Time Series
  Forecasting 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.14630v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.14630v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Luca Butera, Giovanni De Felice, Andrea Cini, Cesare Alippi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In forecasting multiple time series, accounting for the individual features
of each sequence can be challenging. To address this, modern deep learning
methods for time series analysis combine a shared (global) model with local
layers, specific to each time series, often implemented as learnable
embeddings. Ideally, these local embeddings should encode meaningful
representations of the unique dynamics of each sequence. However, when these
are learned end-to-end as parameters of a forecasting model, they may end up
acting as mere sequence identifiers. Shared processing blocks may then become
reliant on such identifiers, limiting their transferability to new contexts. In
this paper, we address this issue by investigating methods to regularize the
learning of local learnable embeddings for time series processing.
Specifically, we perform the first extensive empirical study on the subject and
show how such regularizations consistently improve performance in widely
adopted architectures. Furthermore, we show that methods attempting to prevent
the co-adaptation of local and global parameters by means of embeddings
perturbation are particularly effective in this context. In this regard, we
include in the comparison several perturbation-based regularization methods,
going as far as periodically resetting the embeddings during training. The
obtained results provide an important contribution to understanding the
interplay between learnable local parameters and shared processing layers: a
key challenge in modern time series processing models and a step toward
developing effective foundation models for time series.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at TMLR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Learning convolution operators on compact Abelian groups 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.05279v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.05279v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emilia Magnani, Ernesto De Vito, Philipp Hennig, Lorenzo Rosasco
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We consider the problem of learning convolution operators associated to
compact Abelian groups. We study a regularization-based approach and provide
corresponding learning guarantees, discussing natural regularity condition on
the convolution kernel. More precisely, we assume the convolution kernel is a
function in a translation invariant Hilbert space and analyze a natural ridge
regression (RR) estimator. Building on existing results for RR, we characterize
the accuracy of the estimator in terms of finite sample bounds. Interestingly,
regularity assumptions which are classical in the analysis of RR, have a novel
and natural interpretation in terms of space/frequency localization.
Theoretical results are illustrated by numerical simulations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Model-free reinforcement learning with noisy actions for automated
  experimental control in optics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2405.15421v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2405.15421v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lea Richtmann, Viktoria-S. Schmiesing, Dennis Wilken, Jan Heine, Aaron Tranter, Avishek Anand, Tobias J. Osborne, Michèle Heurs
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Setting up and controlling optical systems is often a challenging and tedious
task. The high number of degrees of freedom to control mirrors, lenses, or
phases of light makes automatic control challenging, especially when the
complexity of the system cannot be adequately modeled due to noise or
non-linearities. Here, we show that reinforcement learning (RL) can overcome
these challenges when coupling laser light into an optical fiber, using a
model-free RL approach that trains directly on the experiment without
pre-training. By utilizing the sample-efficient algorithms Soft Actor-Critic
(SAC) or Truncated Quantile Critics (TQC), our agent learns to couple with 90%
efficiency, comparable to the human expert. We demonstrate that direct training
on an experiment can replace extensive system modeling. Our result exemplifies
RL's potential to tackle problems in optics, paving the way for more complex
applications where full noise modeling is not feasible.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages + 12 pages appendices, 2 + 12 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An <span class="highlight-title">Overview</span> of Prototype Formulations for Interpretable Deep Learning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.08925v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.08925v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Maximilian Xiling Li, Korbinian Franz Rudolf, Nils Blank, Rudolf Lioutikov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Prototypical part networks offer interpretable alternatives to black-box deep
learning models. However, many of these networks rely on Euclidean prototypes,
which may limit their flexibility. This work provides a comprehensive overview
of various prototype formulations. Experiments conducted on the CUB-200-2011,
Stanford Cars, and Oxford Flowers datasets demonstrate the effectiveness and
versatility of these different formulations.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Equal Contribution of M.X.Li and K.F.Rudolf</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multi-modal Multi-kernel Graph Learning for Autism Prediction and
  Biomarker Discovery 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.03388v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.03388v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jin Liu, Junbin Mao, Hanhe Lin, Hulin Kuang, Shirui Pan, Xusheng Wu, Shan Xie, Fei Liu, Yi Pan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Due to its complexity, graph learning-based multi-modal integration and
classification is one of the most challenging obstacles for disease prediction.
To effectively offset the negative impact between modalities in the process of
multi-modal integration and extract heterogeneous information from graphs, we
propose a novel method called MMKGL (Multi-modal Multi-Kernel Graph Learning).
For the problem of negative impact between modalities, we propose a multi-modal
graph embedding module to construct a multi-modal graph. Different from
conventional methods that manually construct static graphs for all modalities,
each modality generates a separate graph by adaptive learning, where a function
graph and a supervision graph are introduced for optimization during the
multi-graph fusion embedding process. We then propose a multi-kernel graph
learning module to extract heterogeneous information from the multi-modal
graph. The information in the multi-modal graph at different levels is
aggregated by convolutional kernels with different receptive field sizes,
followed by generating a cross-kernel discovery tensor for disease prediction.
Our method is evaluated on the benchmark Autism Brain Imaging Data Exchange
(ABIDE) dataset and outperforms the state-of-the-art methods. In addition,
discriminative brain regions associated with autism are identified by our
model, providing guidance for the study of autism pathology.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DrivAerNet++: A Large-Scale Multimodal Car <span class="highlight-title">Dataset</span> with Computational
  Fluid Dynamics Simulations and Deep Learning Benchmarks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.09624v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.09624v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohamed Elrefaie, Florin Morar, Angela Dai, Faez Ahmed
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present DrivAerNet++, the largest and most comprehensive multimodal
dataset for aerodynamic car design. DrivAerNet++ comprises 8,000 diverse car
designs modeled with high-fidelity computational fluid dynamics (CFD)
simulations. The dataset includes diverse car configurations such as fastback,
notchback, and estateback, with different underbody and wheel designs to
represent both internal combustion engines and electric vehicles. Each entry in
the dataset features detailed 3D meshes, parametric models, aerodynamic
coefficients, and extensive flow and surface field data, along with segmented
parts for car classification and point cloud data. This dataset supports a wide
array of machine learning applications including data-driven design
optimization, generative modeling, surrogate model training, CFD simulation
acceleration, and geometric classification. With more than 39 TB of publicly
available engineering data, DrivAerNet++ fills a significant gap in available
resources, providing high-quality, diverse data to enhance model training,
promote generalization, and accelerate automotive design processes. Along with
rigorous dataset validation, we also provide ML benchmarking results on the
task of aerodynamic drag prediction, showcasing the breadth of applications
supported by our dataset. This dataset is set to significantly impact
automotive design and broader engineering disciplines by fostering innovation
and improving the fidelity of aerodynamic evaluations. Dataset and code
available at: https://github.com/Mohamedelrefaie/DrivAerNet.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explaining Explainability: Recommendations for Effective Use of Concept
  Activation Vectors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03713v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03713v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Angus Nicolson, Lisa Schut, J. Alison Noble, Yarin Gal
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Concept-based explanations translate the internal representations of deep
learning models into a language that humans are familiar with: concepts. One
popular method for finding concepts is Concept Activation Vectors (CAVs), which
are learnt using a probe dataset of concept exemplars. In this work, we
investigate three properties of CAVs: (1) inconsistency across layers, (2)
entanglement with other concepts, and (3) spatial dependency. Each property
provides both challenges and opportunities in interpreting models. We introduce
tools designed to detect the presence of these properties, provide insight into
how each property can lead to misleading explanations, and provide
recommendations to mitigate their impact. To demonstrate practical
applications, we apply our recommendations to a melanoma classification task,
showing how entanglement can lead to uninterpretable results and that the
choice of negative probe set can have a substantial impact on the meaning of a
CAV. Further, we show that understanding these properties can be used to our
advantage. For example, we introduce spatially dependent CAVs to test if a
model is translation invariant with respect to a specific concept and class.
Our experiments are performed on natural images (ImageNet), skin lesions (ISIC
2019), and a new synthetic dataset, Elements. Elements is designed to capture a
known ground truth relationship between concepts and classes. We release this
dataset to facilitate further research in understanding and evaluating
interpretability methods.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by Transactions on Machine Learning Research (02/2025)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and
  learning in neural networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08644v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08644v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hoony Kang, Wolfgang Losert
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The brain can rapidly adapt to new contexts and learn from limited data, a
coveted characteristic that artificial intelligence algorithms have struggled
to mimic. Inspired by oscillatory rhythms of the mechanical structures of
neural cells, we developed a learning paradigm that is based on oscillations in
link strengths and associates learning with the coordination of these
oscillations. We find that this paradigm yields rapid adaptation and learning
in artificial neural networks. Link oscillations can rapidly change
coordination, endowing the network with the ability to sense subtle context
changes in an unsupervised manner. In other words, the network generates the
missing contextual tokens required to perform as a generalist AI architecture
capable of predicting dynamics in multiple contexts. Oscillations also allow
the network to extrapolate dynamics to never-seen-before contexts. These
capabilities make our learning paradigm a powerful starting point for novel
models of learning and cognition. Furthermore, learning through link
coordination is agnostic to the specifics of the neural network architecture,
hence our study opens the door for introducing rapid adaptation and learning
capabilities into leading AI models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 3 figures v.2 comments: Updated email, updated typo on
  p.11: h -> h^2 for RMSE</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ The Value of Prediction in Identifying the Worst-Off 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.19334v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.19334v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Unai Fischer-Abaigar, Christoph Kern, Juan Carlos Perdomo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning is increasingly used in government programs to identify and
support the most vulnerable individuals, prioritizing assistance for those at
greatest risk over optimizing aggregate outcomes. This paper examines the
welfare impacts of prediction in equity-driven contexts, and how they compare
to other policy levers, such as expanding bureaucratic capacity. Through
mathematical models and a real-world case study on long-term unemployment
amongst German residents, we develop a comprehensive understanding of the
relative effectiveness of prediction in surfacing the worst-off. Our findings
provide clear analytical frameworks and practical, data-driven tools that
empower policymakers to make principled decisions when designing these systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Real-Time Operator Takeover for Visuomotor Diffusion Policy Training 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02308v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02308v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nils Ingelhag, Jesper Munkeby, Michael C. Welle, Marco Moletta, Danica Kragic
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present a Real-Time Operator Takeover (RTOT) paradigm enabling operators
to seamlessly take control of a live visuomotor diffusion policy, guiding the
system back into desirable states or reinforcing specific demonstrations. We
present new insights in using the Mahalonobis distance to automatically
identify undesirable states. Once the operator has intervened and redirected
the system, the control is seamlessly returned to the policy, which resumes
generating actions until further intervention is required. We demonstrate that
incorporating the targeted takeover demonstrations significantly improves
policy performance compared to training solely with an equivalent number of,
but longer, initial demonstrations. We provide an in-depth analysis of using
the Mahalanobis distance to detect out-of-distribution states, illustrating its
utility for identifying critical failure points during execution. Supporting
materials, including videos of initial and takeover demonstrations and all rice
scooping experiments, are available on the project website:
https://operator-takeover.github.io/
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Sequential Binary Classification for Intrusion Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.06099v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.06099v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shrihari Vasudevan, Ishan Chokshi, Raaghul Ranganathan, Nachiappan Sundaram
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Network Intrusion Detection Systems (IDS) have become increasingly important
as networks become more vulnerable to new and sophisticated attacks. Machine
Learning (ML)-based IDS are increasingly seen as the most effective approach to
handle this issue. However, IDS datasets suffer from high class imbalance,
which impacts the performance of standard ML models. Different from existing
data-driven techniques to handling class imbalance, this paper explores a
structural approach to handling class imbalance in multi-class classification
(MCC) problems. The proposed approach - Sequential Binary Classification (SBC),
is a hierarchical cascade of (regular) binary classifiers. Experiments on
benchmark IDS datasets demonstrate that the structural approach to handling
class-imbalance, as exemplified by SBC, is a viable approach to handling the
issue.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">2</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Visual-based spatial audio generation system for multi-speaker
  environments 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07538v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07538v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaojing Liu, Ogulcan Gurelli, Yan Wang, Joshua Reiss
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In multimedia applications such as films and video games, spatial audio
techniques are widely employed to enhance user experiences by simulating 3D
sound: transforming mono audio into binaural formats. However, this process is
often complex and labor-intensive for sound designers, requiring precise
synchronization of audio with the spatial positions of visual components. To
address these challenges, we propose a visual-based spatial audio generation
system - an automated system that integrates face detection YOLOv8 for object
detection, monocular depth estimation, and spatial audio techniques. Notably,
the system operates without requiring additional binaural dataset training. The
proposed system is evaluated against existing Spatial Audio generation system
using objective metrics. Experimental results demonstrate that our method
significantly improves spatial consistency between audio and video, enhances
speech quality, and performs robustly in multi-speaker scenarios. By
streamlining the audio-visual alignment process, the proposed system enables
sound engineers to achieve high-quality results efficiently, making it a
valuable tool for professionals in multimedia production.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SkinGEN: an Explainable Dermatology Diagnosis-to-Generation Framework
  with Interactive Vision-Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.14755v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.14755v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bo Lin, Yingjing Xu, Xuanwen Bao, Zhou Zhao, Zhouyang Wang, Jianwei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the continuous advancement of vision language models (VLMs) technology,
remarkable research achievements have emerged in the dermatology field, the
fourth most prevalent human disease category. However, despite these
advancements, VLM still faces explainable problems to user in diagnosis due to
the inherent complexity of dermatological conditions, existing tools offer
relatively limited support for user comprehension. We propose SkinGEN, a
diagnosis-to-generation framework that leverages the stable diffusion(SD) model
to generate reference demonstrations from diagnosis results provided by VLM,
thereby enhancing the visual explainability for users. Through extensive
experiments with Low-Rank Adaptation (LoRA), we identify optimal strategies for
skin condition image generation. We conduct a user study with 32 participants
evaluating both the system performance and explainability. Results demonstrate
that SkinGEN significantly improves users' comprehension of VLM predictions and
fosters increased trust in the diagnostic process. This work paves the way for
more transparent and user-centric VLM applications in dermatology and beyond.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-12T00:00:00Z">2025-02-12</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Computation and Language <span class="chip" style="font-size: 60%">35</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ask in Any Modality: A Comprehensive <span class="highlight-title">Survey</span> on Multimodal
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) struggle with hallucinations and outdated
knowledge due to their reliance on static training data. Retrieval-Augmented
Generation (RAG) mitigates these issues by integrating external dynamic
information enhancing factual and updated grounding. Recent advances in
multimodal learning have led to the development of Multimodal RAG,
incorporating multiple modalities such as text, images, audio, and video to
enhance the generated outputs. However, cross-modal alignment and reasoning
introduce unique challenges to Multimodal RAG, distinguishing it from
traditional unimodal RAG. This survey offers a structured and comprehensive
analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,
evaluation, methodologies, and innovations in retrieval, fusion, augmentation,
and generation. We precisely review training strategies, robustness
enhancements, and loss functions, while also exploring the diverse Multimodal
RAG scenarios. Furthermore, we discuss open challenges and future research
directions to support advancements in this evolving field. This survey lays the
foundation for developing more capable and reliable AI systems that effectively
leverage multimodal dynamic external knowledge bases. Resources are available
at https://github.com/llm-lab-org/Multimodal-RAG-Survey.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Examining and Adapting Time for Multilingual Classification via Mixture
  of Temporal Experts <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08825v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08825v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Weisi Liu, Guangzeng Han, Xiaolei Huang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Time is implicitly embedded in classification process: classifiers are
usually built on existing data while to be applied on future data whose
distributions (e.g., label and token) may change. However, existing
state-of-the-art classification models merely consider the temporal variations
and primarily focus on English corpora, which leaves temporal studies less
explored, let alone under multilingual settings. In this study, we fill the gap
by treating time as domains (e.g., 2024 vs. 2025), examining temporal effects,
and developing a domain adaptation framework to generalize classifiers over
time on multiple languages. Our framework proposes Mixture of Temporal Experts
(MoTE) to leverage both semantic and data distributional shifts to learn and
adapt temporal trends into classification models. Our analysis shows
classification performance varies over time across different languages, and we
experimentally demonstrate that MoTE can enhance classifier generalizability
over temporal data shifts. Our study provides analytic insights and addresses
the need for time-aware models that perform robustly in multilingual scenarios.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>accept to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Can a Single Model Master Both Multi-turn Conversations and Tool Use?
  CALM: A Unified Conversational Agentic Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08820v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08820v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Emre Can Acikgoz, Jeremiah Greer, Akul Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek Hakkani-Tür, Gokhan Tur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) with API-calling capabilities enabled building
effective Language Agents (LA), while also revolutionizing the conventional
task-oriented dialogue (TOD) paradigm. However, current approaches face a
critical dilemma: TOD systems are often trained on a limited set of target
APIs, requiring new data to maintain their quality when interfacing with new
services, while LAs are not trained to maintain user intent over multi-turn
conversations. Because both robust multi-turn management and advanced function
calling are crucial for effective conversational agents, we evaluate these
skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and
API-Bank (LA), and our analyses reveal that specialized approaches excel in one
domain but underperform in the other. To bridge this chasm, we introduce CALM
(Conversational Agentic Language Model), a unified approach that integrates
both conversational and agentic capabilities. We created CALM-IT, a carefully
constructed multi-task dataset that interleave multi-turn ReAct reasoning with
complex API usage. Using CALM-IT, we train three models CALM 8B, CALM 70B, and
CALM 405B, which outperform top domain-specific models, including GPT-4o,
across all three benchmarks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Lexical Manifold Reconfiguration in Large Language Models: A Novel
  Architectural Approach for Contextual Modulation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08818v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08818v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Koinis Vassilis, Godfrey Milbourne, Harriet Featherstone, Xanthe Peverell, Yorick Bletchley, Zachary Montford
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Contextual adaptation in token embeddings plays a central role in determining
how well language models maintain coherence and retain semantic relationships
over extended text sequences. Static embeddings often impose constraints on
lexical flexibility, leading to suboptimal performance when faced with complex
sentence structures or domain-specific terminology shifts. To address this
limitation, a structured approach was developed for dynamically reconfiguring
token embeddings through continuous geometric transformations, ensuring that
representations evolved in response to evolving discourse structures. A
manifold-based transformation mechanism was integrated to regulate lexical
positioning, allowing embeddings to undergo controlled shifts while preserving
linguistic relationships across varying textual contexts. Empirical evaluations
demonstrated that embedding reconfiguration contributed to reductions in
perplexity, improved lexical coherence, and enhanced sentence-level continuity,
particularly in structured and domain-adaptive text generation tasks.
Comparative analyses of embedding drift indicated that dynamically restructured
representations maintained stronger contextual consistency, reducing
misalignment in token dependencies while preserving fluency in language
modeling outputs. Computational overhead assessments confirmed that while
training complexity increased due to the iterative refinement of embeddings,
inference remained efficient, ensuring practical feasibility for real-time
generation. Evaluations across multiple datasets further demonstrated that
dynamically modulated embeddings exhibited broader lexical diversity, reducing
repetitive token patterns and enabling a more adaptable representation learning
process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Systematic <span class="highlight-title">Review</span> on the Evaluation of Large Language Models in Theory
  of Mind Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08796v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08796v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Karahan Sarıtaş, Kıvanç Tezören, Yavuz Durmazkeser
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, evaluating the Theory of Mind (ToM) capabilities of large
language models (LLMs) has received significant attention within the research
community. As the field rapidly evolves, navigating the diverse approaches and
methodologies has become increasingly complex. This systematic review
synthesizes current efforts to assess LLMs' ability to perform ToM tasks, an
essential aspect of human cognition involving the attribution of mental states
to oneself and others. Despite notable advancements, the proficiency of LLMs in
ToM remains a contentious issue. By categorizing benchmarks and tasks through a
taxonomy rooted in cognitive science, this review critically examines
evaluation techniques, prompting strategies, and the inherent limitations of
LLMs in replicating human-like mental state reasoning. A recurring theme in the
literature reveals that while LLMs demonstrate emerging competence in ToM
tasks, significant gaps persist in their emulation of human cognitive
abilities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ If Multi-Agent Debate is the Answer, What is the Question? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08788v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08788v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hangfan Zhang, Zhiyao Cui, Xinrun Wang, Qiaosheng Zhang, Zhen Wang, Dinghao Wu, Shuyue Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-agent debate (MAD) has emerged as a promising approach to enhance the
factual accuracy and reasoning quality of large language models (LLMs) by
engaging multiple agents in iterative discussions during inference. Despite its
potential, we argue that current MAD research suffers from critical
shortcomings in evaluation practices, including limited dataset overlap and
inconsistent baselines, raising significant concerns about generalizability.
Correspondingly, this paper presents a systematic evaluation of five
representative MAD methods across nine benchmarks using four foundational
models. Surprisingly, our findings reveal that MAD methods fail to reliably
outperform simple single-agent baselines such as Chain-of-Thought and
Self-Consistency, even when consuming additional inference-time computation.
From our analysis, we found that model heterogeneity can significantly improve
MAD frameworks. We propose Heter-MAD enabling a single LLM agent to access the
output from heterogeneous foundation models, which boosts the performance of
current MAD frameworks. Finally, we outline potential directions for advancing
MAD, aiming to spark a broader conversation and inspire future work in this
area.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This position paper takes a critical view of the status quo of MAD
  research, and outline multiple potential directions to improve MAD</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Zero-Shot Belief: A Hard Problem for LLMs <span class="chip">ACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08777v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08777v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        John Murzaku, Owen Rambow
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We present two LLM-based approaches to zero-shot source-and-target belief
prediction on FactBank: a unified system that identifies events, sources, and
belief labels in a single pass, and a hybrid approach that uses a fine-tuned
DeBERTa tagger for event detection. We show that multiple open-sourced,
closed-source, and reasoning-based LLMs struggle with the task. Using the
hybrid approach, we achieve new state-of-the-art results on FactBank and offer
a detailed error analysis. Our approach is then tested on the Italian belief
corpus ModaFact.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Universal Model Routing for Efficient LLM Inference 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08773v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08773v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wittawat Jitkrittum, Harikrishna Narasimhan, Ankit Singh Rawat, Jeevesh Juneja, Zifeng Wang, Chen-Yu Lee, Pradeep Shenoy, Rina Panigrahy, Aditya Krishna Menon, Sanjiv Kumar
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models' significant advances in capabilities are accompanied
by significant increases in inference costs. Model routing is a simple
technique for reducing inference cost, wherein one maintains a pool of
candidate LLMs, and learns to route each prompt to the smallest feasible LLM.
Existing works focus on learning a router for a fixed pool of LLMs. In this
paper, we consider the problem of dynamic routing, where new, previously
unobserved LLMs are available at test time. We propose a new approach to this
problem that relies on representing each LLM as a feature vector, derived based
on predictions on a set of representative prompts. Based on this, we detail two
effective strategies, relying on cluster-based routing and a learned cluster
map respectively. We prove that these strategies are estimates of a
theoretically optimal routing rule, and provide an excess risk bound to
quantify their errors. Experiments on a range of public benchmarks show the
effectiveness of the proposed strategies in routing amongst more than 30 unseen
LLMs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SelfElicit: Your Language Model Secretly Knows Where is the Relevant
  Evidence 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08767v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08767v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Providing Language Models (LMs) with relevant evidence in the context (either
via retrieval or user-provided) can significantly improve their ability to
provide factually correct grounded responses. However, recent studies have
found that LMs often struggle to fully comprehend and utilize key evidence from
the context, especially when it contains noise and irrelevant information - an
issue common in real-world scenarios. To address this, we propose SelfElicit,
an inference-time approach that helps LMs focus on key contextual evidence
through self-guided explicit highlighting. By leveraging the inherent
evidence-finding capabilities of LMs using the attention scores of deeper
layers, our method automatically identifies and emphasizes key evidence within
the input context, facilitating more accurate and factually grounded responses
without additional training or iterative prompting. We demonstrate that
SelfElicit brings consistent and significant improvement on multiple
evidence-based QA tasks for various LM families while maintaining computational
efficiency. Our code and documentation are available at
https://github.com/ZhiningLiu1998/SelfElicit.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages, 5 figures, 8 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IHEval: Evaluating Language Models on Following the Instruction
  Hierarchy <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08745v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08745v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhihan Zhang, Shiyang Li, Zixuan Zhang, Xin Liu, Haoming Jiang, Xianfeng Tang, Yifan Gao, Zheng Li, Haodong Wang, Zhaoxuan Tan, Yichuan Li, Qingyu Yin, Bing Yin, Meng Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The instruction hierarchy, which establishes a priority order from system
messages to user messages, conversation history, and tool outputs, is essential
for ensuring consistent and safe behavior in language models (LMs). Despite its
importance, this topic receives limited attention, and there is a lack of
comprehensive benchmarks for evaluating models' ability to follow the
instruction hierarchy. We bridge this gap by introducing IHEval, a novel
benchmark comprising 3,538 examples across nine tasks, covering cases where
instructions in different priorities either align or conflict. Our evaluation
of popular LMs highlights their struggle to recognize instruction priorities.
All evaluated models experience a sharp performance decline when facing
conflicting instructions, compared to their original instruction-following
performance. Moreover, the most competitive open-source model only achieves 48%
accuracy in resolving such conflicts. Our results underscore the need for
targeted optimization in the future development of LMs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Are Expressions for Music Emotions the Same Across Cultures? 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08744v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08744v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Elif Celen, Pol van Rijn, Harin Lee, Nori Jacoby
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music evokes profound emotions, yet the universality of emotional descriptors
across languages remains debated. A key challenge in cross-cultural research on
music emotion is biased stimulus selection and manual curation of taxonomies,
predominantly relying on Western music and languages. To address this, we
propose a balanced experimental design with nine online experiments in Brazil,
the US, and South Korea, involving N=672 participants. First, we sample a
balanced set of popular music from these countries. Using an open-ended tagging
pipeline, we then gather emotion terms to create culture-specific taxonomies.
Finally, using these bottom-up taxonomies, participants rate emotions of each
song. This allows us to map emotional similarities within and across cultures.
Results show consistency in high arousal, high valence emotions but greater
variability in others. Notably, machine translations were often inadequate to
capture music-specific meanings. These findings together highlight the need for
a domain-sensitive, open-ended, bottom-up emotion elicitation approach to
reduce cultural biases in emotion research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to CogSci</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Utility Engineering: Analyzing and Controlling Emergent Value Systems in
  AIs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08640v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08640v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mantas Mazeika, Xuwang Yin, Rishub Tamirisa, Jaehyuk Lim, Bruce W. Lee, Richard Ren, Long Phan, Norman Mu, Adam Khoja, Oliver Zhang, Dan Hendrycks
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As AIs rapidly advance and become more agentic, the risk they pose is
governed not only by their capabilities but increasingly by their propensities,
including goals and values. Tracking the emergence of goals and values has
proven a longstanding problem, and despite much interest over the years it
remains unclear whether current AIs have meaningful values. We propose a
solution to this problem, leveraging the framework of utility functions to
study the internal coherence of AI preferences. Surprisingly, we find that
independently-sampled preferences in current LLMs exhibit high degrees of
structural coherence, and moreover that this emerges with scale. These findings
suggest that value systems emerge in LLMs in a meaningful sense, a finding with
broad implications. To study these emergent value systems, we propose utility
engineering as a research agenda, comprising both the analysis and control of
AI utilities. We uncover problematic and often shocking values in LLM
assistants despite existing control measures. These include cases where AIs
value themselves over humans and are anti-aligned with specific individuals. To
constrain these emergent value systems, we propose methods of utility control.
As a case study, we show how aligning utilities with a citizen assembly reduces
political biases and generalizes to new scenarios. Whether we like it or not,
value systems have already emerged in AIs, and much work remains to fully
understand and control these emergent representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Examining Multilingual Embedding Models Cross-Lingually Through
  LLM-Generated Adversarial Examples 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08638v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08638v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Andrianos Michail, Simon Clematide, Rico Sennrich
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The evaluation of cross-lingual semantic search capabilities of models is
often limited to existing datasets from tasks such as information retrieval and
semantic textual similarity. To allow for domain-specific evaluation, we
introduce Cross Lingual Semantic Discrimination (CLSD), a novel cross-lingual
semantic search task that requires only a set of parallel sentence pairs of the
language pair of interest within the target domain. This task focuses on the
ability of a model to cross-lingually rank the true parallel sentence higher
than hard negatives generated by a large language model. We create four
instances of our introduced CLSD task for the language pair German-French
within the domain of news. Within this case study, we find that models that are
also fine-tuned for retrieval tasks (e.g., multilingual E5) benefit from using
English as the pivot language, while bitext mining models such as LaBSE perform
best directly cross-lingually. We also show a fine-grained similarity analysis
enabled by our distractor generation strategy, indicating that different
embedding models are sensitive to different types of perturbations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Randomness of Low-Layer Parameters Determines Confusing Samples in Terms
  of Interaction Representations of a DNN 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08625v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08625v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Junpeng Zhang, Lei Cheng, Qing Li, Liang Lin, Quanshi Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we find that the complexity of interactions encoded by a deep
neural network (DNN) can explain its generalization power. We also discover
that the confusing samples of a DNN, which are represented by non-generalizable
interactions, are determined by its low-layer parameters. In comparison, other
factors, such as high-layer parameters and network architecture, have much less
impact on the composition of confusing samples. Two DNNs with different
low-layer parameters usually have fully different sets of confusing samples,
even though they have similar performance. This finding extends the
understanding of the lottery ticket hypothesis, and well explains distinctive
representation power of different DNNs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Distillation Scaling Laws 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08606v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08606v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dan Busbridge, Amitis Shidani, Floris Weers, Jason Ramapuram, Etai Littwin, Russ Webb
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We provide a distillation scaling law that estimates distilled model
performance based on a compute budget and its allocation between the student
and teacher. Our findings reduce the risks associated with using distillation
at scale; compute allocation for both the teacher and student models can now be
done to maximize student performance. We provide compute optimal distillation
recipes for when 1) a teacher exists, or 2) a teacher needs training. If many
students are to be distilled, or a teacher already exists, distillation
outperforms supervised pretraining until a compute level which grows
predictably with student size. If one student is to be distilled and a teacher
also needs training, supervised learning should be done instead. Additionally,
we provide insights across our large scale study of distillation, which
increase our understanding of distillation and inform experimental design.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>67 pages, 54 figures, 13 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SPeCtrum: A Grounded Framework for Multidimensional Identity
  Representation in LLM-Based Agent <span class="chip">NAACL2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08599v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08599v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keyeun Lee, Seo Hyeong Kim, Seolhee Lee, Jinsu Eun, Yena Ko, Hayeon Jeon, Esther Hehsun Kim, Seonghye Cho, Soeun Yang, Eun-mee Kim, Hajin Lim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing methods for simulating individual identities often oversimplify
human complexity, which may lead to incomplete or flattened representations. To
address this, we introduce SPeCtrum, a grounded framework for constructing
authentic LLM agent personas by incorporating an individual's multidimensional
self-concept. SPeCtrum integrates three core components: Social Identity (S),
Personal Identity (P), and Personal Life Context (C), each contributing
distinct yet interconnected aspects of identity. To evaluate SPeCtrum's
effectiveness in identity representation, we conducted automated and human
evaluations. Automated evaluations using popular drama characters showed that
Personal Life Context (C)-derived from short essays on preferences and daily
routines-modeled characters' identities more effectively than Social Identity
(S) and Personal Identity (P) alone and performed comparably to the full SPC
combination. In contrast, human evaluations involving real-world individuals
found that the full SPC combination provided a more comprehensive self-concept
representation than C alone. Our findings suggest that while C alone may
suffice for basic identity simulation, integrating S, P, and C enhances the
authenticity and accuracy of real-world identity representation. Overall,
SPeCtrum offers a structured approach for simulating individuals in LLM agents,
enabling more personalized human-AI interactions and improving the realism of
simulation-based behavioral studies.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>21 pages, 8 figures, 5 tables, Accepted in NAACL2025 Main</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Quality-Aware Decoding: Unifying Quality Estimation and Decoding 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08561v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08561v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  An emerging research direction in NMT involves the use of Quality Estimation
(QE) models, which have demonstrated high correlations with human judgment and
can enhance translations through Quality-Aware Decoding. Although several
approaches have been proposed based on sampling multiple candidate
translations, none have integrated these models directly into the decoding
process. In this paper, we address this by proposing a novel token-level QE
model capable of reliably scoring partial translations. We build a
uni-directional QE model for this, as decoder models are inherently trained and
efficient on partial sequences. We then present a decoding strategy that
integrates the QE model for Quality-Aware decoding and demonstrate that the
translation quality improves when compared to the N-best list re-ranking with
state-of-the-art QE models (upto $1.39$ XCOMET-XXL $\uparrow$). Finally, we
show that our approach provides significant benefits in document translation
tasks, where the quality of N-best lists is typically suboptimal.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion
  in Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonduk Seo, Seunghyun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query expansion is widely used in Information Retrieval (IR) to improve
search outcomes by enriching queries with additional contextual information.
Although recent Large Language Model (LLM) based methods generate
pseudo-relevant content and expanded terms via multiple prompts, they often
yield repetitive, narrow expansions that lack the diverse context needed to
retrieve all relevant information. In this paper, we introduce QA-Expand, a
novel and effective framework for query expansion. It first generates multiple
relevant questions from the initial query and subsequently produces
corresponding pseudo-answers as surrogate documents. A feedback model further
rewrites and filters these answers to ensure only the most informative
augmentations are incorporated. Extensive experiments on benchmarks such as
BEIR and TREC demonstrate that QA-Expand enhances retrieval performance by up
to 13% over state-of-the-art methods, offering a robust solution for modern
retrieval challenges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLMs can implicitly learn from mistakes in-context 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08550v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08550v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lisa Alazraki, Maximilian Mozes, Jon Ander Campos, Yi Chern Tan, Marek Rei, Max Bartolo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Learning from mistakes is a fundamental feature of human intelligence.
Previous work has shown that Large Language Models (LLMs) can also learn from
incorrect answers when provided with a comprehensive rationale detailing why an
answer is wrong or how to correct it. In this work, we examine whether LLMs can
learn from mistakes in mathematical reasoning tasks when these explanations are
not provided. We investigate if LLMs are able to implicitly infer such
rationales simply from observing both incorrect and correct answers.
Surprisingly, we find that LLMs perform better, on average, when rationales are
eliminated from the context and incorrect answers are simply shown alongside
correct ones. This approach also substantially outperforms chain-of-thought
prompting in our evaluations. We show that these results are consistent across
LLMs of different sizes and varying reasoning abilities. Further, we carry out
an in-depth analysis, and show that prompting with both wrong and correct
answers leads to greater performance and better generalisation than introducing
additional, more diverse question-answer pairs into the context. Finally, we
show that new rationales generated by models that have only observed incorrect
and correct answers are scored equally as highly by humans as those produced
with the aid of exemplar rationales. Our results demonstrate that LLMs are
indeed capable of in-context implicit learning.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM <span class="highlight-title">Pretrain</span>ing with Continuous Concepts 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08524v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08524v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jihoon Tack, Jack Lanchantin, Jane Yu, Andrew Cohen, Ilia Kulikov, Janice Lan, Shibo Hao, Yuandong Tian, Jason Weston, Xian Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Next token prediction has been the standard training objective used in large
language model pretraining. Representations are learned as a result of
optimizing for token-level perplexity. We propose Continuous Concept Mixing
(CoCoMix), a novel pretraining framework that combines discrete next token
prediction with continuous concepts. Specifically, CoCoMix predicts continuous
concepts learned from a pretrained sparse autoencoder and mixes them into the
model's hidden state by interleaving with token hidden representations. Through
experiments on multiple benchmarks, including language modeling and downstream
reasoning tasks, we show that CoCoMix is more sample efficient and consistently
outperforms standard next token prediction, knowledge distillation and
inserting pause tokens. We find that combining both concept learning and
interleaving in an end-to-end framework is critical to performance gains.
Furthermore, CoCoMix enhances interpretability and steerability by allowing
direct inspection and modification of the predicted concept, offering a
transparent way to guide the model's internal reasoning process.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard
  Perturbations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06453v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06453v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, Yue Wu, Ming Yin, Shange Tang, Yangsibo Huang, Chi Jin, Xinyun Chen, Chiyuan Zhang, Mengdi Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models have demonstrated impressive performance on challenging
mathematical reasoning tasks, which has triggered the discussion of whether the
performance is achieved by true reasoning capability or memorization. To
investigate this question, prior work has constructed mathematical benchmarks
when questions undergo simple perturbations -- modifications that still
preserve the underlying reasoning patterns of the solutions. However, no work
has explored hard perturbations, which fundamentally change the nature of the
problem so that the original solution steps do not apply. To bridge the gap, we
construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard
perturbation, respectively. Each consists of 279 perturbed math problems
derived from level-5 (hardest) problems in the MATH dataset (Hendrycksmath et.
al., 2021). We observe significant performance drops on MATH-P-Hard across
various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking
(-12.9%). We also raise concerns about a novel form of memorization where
models blindly apply learned problem-solving skills without assessing their
applicability to modified contexts. This issue is amplified when using original
problems for in-context learning. We call for research efforts to address this
challenge, which is critical for developing more robust and reliable reasoning
models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>v2: fix bugs in Fig. 1</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Do Not Design, Learn: A Trainable Scoring Function for Uncertainty
  Estimation in Generative LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11278v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11278v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Duygu Nur Yaldiz, Yavuz Faruk Bakman, Baturalp Buyukates, Chenyang Tao, Anil Ramakrishna, Dimitrios Dimitriadis, Jieyu Zhao, Salman Avestimehr
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Uncertainty estimation (UE) of generative large language models (LLMs) is
crucial for evaluating the reliability of generated sequences. A significant
subset of UE methods utilize token probabilities to assess uncertainty,
aggregating multiple token probabilities into a single UE score using a scoring
function. Existing scoring functions for probability-based UE, such as
length-normalized scoring and semantic contribution-based weighting, are
designed to solve certain aspects of the problem but exhibit limitations,
including the inability to handle biased probabilities and complex semantic
dependencies between tokens. To address these issues, in this work, we propose
Learnable Response Scoring (LARS) function, a novel scoring function that
leverages supervised data to capture complex dependencies between tokens and
probabilities, thereby producing more reliable and calibrated response scores
in computing the uncertainty of LLM generations. Our comprehensive experiments
across question-answering and arithmetical reasoning tasks with various
datasets demonstrate that LARS significantly outperforms existing scoring
functions, achieving improvements of up to 16\% AUROC score.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal Medical Code Tokenizer 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04397v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04397v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models trained on patient electronic health records (EHRs) require
tokenizing medical data into sequences of discrete vocabulary items. Existing
tokenizers treat medical codes from EHRs as isolated textual tokens. However,
each medical code is defined by its textual description, its position in
ontological hierarchies, and its relationships to other codes, such as disease
co-occurrences and drug-treatment associations. Medical vocabularies contain
more than 600,000 codes with critical information for clinical reasoning. We
introduce MedTok, a multimodal medical code tokenizer that uses the text
descriptions and relational context of codes. MedTok processes text using a
language model encoder and encodes the relational structure with a graph
encoder. It then quantizes both modalities into a unified token space,
preserving modality-specific and cross-modality information. We integrate
MedTok into five EHR models and evaluate it on operational and clinical tasks
across in-patient and out-patient datasets, including outcome prediction,
diagnosis classification, drug recommendation, and risk stratification.
Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR
models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with
the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate
using MedTok tokenizer with medical QA systems. Our results demonstrate the
potential of MedTok as a unified tokenizer for medical codes, improving
tokenization for medical foundation models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ <span class="highlight-title">Transformer</span> Layers as Painters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.09298v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.09298v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qi Sun, Marc Pickett, Aakash Kumar Nain, Llion Jones
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite their nearly universal adoption for large language models, the
internal workings of transformers are not well understood. We aim to better
understand the impact of removing or reorganizing information throughout the
layers of a pretrained transformer. Such an understanding could both yield
better usage of existing models as well as to make architectural improvements
to produce new variants. We present a series of empirical studies on frozen
models that show that the lower and final layers of pretrained transformers
differ from middle layers, but that middle layers have a surprising amount of
uniformity. We further show that some classes of problems have robustness to
skipping layers, running the layers in an order different from how they were
trained, or running the layers in parallel. Our observations suggest that even
frozen pretrained models may gracefully trade accuracy for latency by skipping
layers or running layers in parallel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages total, including references and appendices</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Better RAG using Relevant Information Gain <span class="chip">EMNLP</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.12101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.12101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Marc Pickett, Jeremy Hartman, Ayan Kumar Bhowmick, Raquib-ul Alam, Aditya Vempaty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  A common way to extend the memory of large language models (LLMs) is by
retrieval augmented generation (RAG), which inserts text retrieved from a
larger memory into an LLM's context window. However, the context window is
typically limited to several thousand tokens, which limits the number of
retrieved passages that can inform a model's response. For this reason, it's
important to avoid occupying context window space with redundant information by
ensuring a degree of diversity among retrieved passages. At the same time, the
information should also be relevant to the current task. Most prior methods
that encourage diversity among retrieved results, such as Maximal Marginal
Relevance (MMR), do so by incorporating an objective that explicitly trades off
diversity and relevance. We propose a novel simple optimization metric based on
relevant information gain, a probabilistic measure of the total information
relevant to a query for a set of retrieved results. By optimizing this metric,
diversity organically emerges from our system. When used as a drop-in
replacement for the retrieval component of a RAG system, this method yields
state-of-the-art performance on question answering tasks from the Retrieval
Augmented Generation Benchmark (RGB), outperforming existing metrics that
directly optimize for relevance and diversity.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 page paper submitted to EMNLP</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Premise-Augmented Reasoning Chains Improve Error Identification in Math
  reasoning with LLMs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02362v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02362v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-Tür
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large
language models (LLMs) by enabling detailed step-by-step solutions. However,
due to the verbosity of LLMs, the resulting reasoning chains can be long,
making it harder to verify the reasoning steps and trace issues resulting from
dependencies between the steps that may be farther away in the sequence of
steps. Importantly, mathematical reasoning allows each step to be derived from
a small set of premises, which are a subset of the preceding steps in the
reasoning chain. In this paper, we present a framework that identifies the
premises for each step, to improve the evaluation of reasoning. We restructure
conventional linear reasoning chains into Premise Augmented Reasoning Chains
(PARC) by introducing premise links, resulting in a directed acyclic graph
where the nodes are the steps and the edges are the premise links. Through
experiments with a PARC-based dataset that we built, namely PERL (Premises and
ERrors identification in LLMs), we demonstrate that LLMs can reliably identify
premises within complex reasoning chains. In particular, even open-source LLMs
achieve 90% recall in premise identification. We also show that PARC helps to
identify errors in reasoning chains more reliably. The accuracy of error
identification improves by 6% to 16% absolute when step-by-step verification is
carried out in PARC under the premises. Our findings highlight the utility of
premise-centric representations in addressing complex problem-solving tasks and
open new avenues for improving the reliability of LLM-based reasoning
evaluations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ What can Large Language Models Capture about Code Functional
  Equivalence? <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.11081v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.11081v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nickil Maveli, Antonio Vergari, Shay B. Cohen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Code-LLMs, LLMs pre-trained on large code corpora, have shown great progress
in learning rich representations of the structure and syntax of code,
successfully using it to generate or classify code fragments. At the same time,
understanding if they are able to do so because they capture code semantics,
and how well, is still an open question. In this paper, we tackle this problem
by introducing SeqCoBench, a benchmark for systematically assessing how
Code-LLMs can capture code functional equivalence. SeqCoBench contains over 20
code transformations that either preserve or alter the semantics of Python
programs. We conduct extensive evaluations in different settings, including
zero-shot and parameter-efficient finetuning methods on state-of-the-art
(Code)-LLMs to see if they can discern semantically equivalent or different
pairs of programs in SeqCoBench. We find that the performance gap between these
LLMs and classical match-based retrieval scores is minimal, with both
approaches showing a concerning lack of depth in understanding code semantics.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to Findings of NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Curating corpora with classifiers: A case study of clean energy
  sentiment online 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2305.03092v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2305.03092v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael V. Arnold, Peter Sheridan Dodds, Christopher M. Danforth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Well curated, large-scale corpora of social media posts containing broad
public opinion offer an alternative data source to complement traditional
surveys. While surveys are effective at collecting representative samples and
are capable of achieving high accuracy, they can be both expensive to run and
lag public opinion by days or weeks. Both of these drawbacks could be overcome
with a real-time, high volume data stream and fast analysis pipeline. A central
challenge in orchestrating such a data pipeline is devising an effective method
for rapidly selecting the best corpus of relevant documents for analysis.
Querying with keywords alone often includes irrelevant documents that are not
easily disambiguated with bag-of-words natural language processing methods.
Here, we explore methods of corpus curation to filter irrelevant tweets using
pre-trained transformer-based models, fine-tuned for our binary classification
task on hand-labeled tweets. We are able to achieve F1 scores of up to 0.95.
The low cost and high performance of fine-tuning such a model suggests that our
approach could be of broad benefit as a pre-processing step for social media
datasets with uncertain corpus boundaries.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive
  Modality Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04328v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04328v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models, particularly following GPT-4o, have
sparked increasing interest in developing omni-modal models capable of
understanding more modalities. While some open-source alternatives have
emerged, there is still a notable lag behind specialized single-modality models
in performance. In this paper, we present Ola, an Omni-modal language model
that achieves competitive performance across image, video, and audio
understanding compared to specialized counterparts. The core design of Ola lies
in its progressive modality alignment strategy that extends the supporting
modality of the language model progressively. Our training pipeline begins with
the most distinct modalities: image and text, then gradually expands the skill
sets of the model using speech data that connects language and audio knowledge,
and video data that connects all modalities. The progressive learning pipeline
also enables us to maintain a relatively small size of the cross-modal
alignment data, making developing omni-modal from existing vision-language
models easy and less costly. Moreover, to unlock an advanced interactive
experience like GPT-4o, we further design a sentence-wise decoding solution for
streaming speech generation. Extensive experiments demonstrate that Ola
surpasses existing open omni-modal LLMs across all modalities while achieving
highly competitive performance compared to state-of-the-art specialized models
of similar sizes. We aim to make Ola a fully open omni-modal understanding
solution to advance future research in this emerging field. Model weights,
code, and data are open-sourced at https://github.com/Ola-Omni/Ola.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ARR: Question Answering with Large Language Models via Analyzing,
  Retrieving, and Reasoning 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04689v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04689v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuwei Yin, Giuseppe Carenini
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) achieve remarkable performance on challenging
benchmarks that are often structured as multiple-choice question-answering (QA)
tasks. Zero-shot Chain-of-Thought (CoT) prompting enhances reasoning in LLMs
but provides only vague and generic guidance ("think step by step"). This paper
introduces ARR, an intuitive and effective zero-shot prompting method that
explicitly incorporates three key steps in QA solving: analyzing the intent of
the question, retrieving relevant information, and reasoning step by step.
Comprehensive experiments across diverse and challenging QA tasks demonstrate
that ARR consistently improves the Baseline (without ARR prompting) and
outperforms CoT. Ablation and case studies further validate the positive
contributions of each component: analyzing, retrieving, and reasoning. Notably,
intent analysis plays a vital role in ARR. Additionally, extensive evaluations
across various model sizes, LLM series, and generation settings solidify the
effectiveness, robustness, and generalizability of ARR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>20 pages. Code: https://github.com/YuweiYin/ARR</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncovering Intermediate Variables in <span class="highlight-title">Transformer</span>s using Circuit Probing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2311.04354v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2311.04354v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Michael A. Lepori, Thomas Serre, Ellie Pavlick
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural network models have achieved high performance on a wide variety of
complex tasks, but the algorithms that they implement are notoriously difficult
to interpret. It is often necessary to hypothesize intermediate variables
involved in a network's computation in order to understand these algorithms.
For example, does a language model depend on particular syntactic properties
when generating a sentence? Yet, existing analysis tools make it difficult to
test hypotheses of this type. We propose a new analysis technique - circuit
probing - that automatically uncovers low-level circuits that compute
hypothesized intermediate variables. This enables causal analysis through
targeted ablation at the level of model parameters. We apply this method to
models trained on simple arithmetic tasks, demonstrating its effectiveness at
(1) deciphering the algorithms that models have learned, (2) revealing modular
structure within a model, and (3) tracking the development of circuits over
training. Across these three experiments we demonstrate that circuit probing
combines and extends the capabilities of existing methods, providing one
unified approach for a variety of analyses. Finally, we demonstrate circuit
probing on a real-world use case: uncovering circuits that are responsible for
subject-verb agreement and reflexive anaphora in GPT2-Small and Medium.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Evaluating the Performance of Chat<span class="highlight-title">GPT</span> for Spam Email Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.15537v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.15537v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shijing Si, Yuwei Wu, Le Tang, Yugui Zhang, Jedrek Wosik, Qinliang Su
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Email continues to be a pivotal and extensively utilized communication medium
within professional and commercial domains. Nonetheless, the prevalence of spam
emails poses a significant challenge for users, disrupting their daily routines
and diminishing productivity. Consequently, accurately identifying and
filtering spam based on content has become crucial for cybersecurity. Recent
advancements in natural language processing, particularly with large language
models like ChatGPT, have shown remarkable performance in tasks such as
question answering and text generation. However, its potential in spam
identification remains underexplored. To fill in the gap, this study attempts
to evaluate ChatGPT's capabilities for spam identification in both English and
Chinese email datasets. We employ ChatGPT for spam email detection using
in-context learning, which requires a prompt instruction with (or without) a
few demonstrations. We also investigate how the number of demonstrations in the
prompt affects the performance of ChatGPT. For comparison, we also implement
five popular benchmark methods, including naive Bayes, support vector machines
(SVM), logistic regression (LR), feedforward dense neural networks (DNN), and
BERT classifiers. Through extensive experiments, the performance of ChatGPT is
significantly worse than deep supervised learning methods in the large English
dataset, while it presents superior performance on the low-resourced Chinese
dataset. This study provides insights into the potential and limitations of
ChatGPT for spam identification, highlighting its potential as a viable
solution for resource-constrained language domains.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 4 figures; Accepted by Pacific Journal of Optimization
  (PJO)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ETM: Modern Insights into Perspective on Text-to-SQL Evaluation in the
  Age of Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.07313v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.07313v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Benjamin G. Ascoli, Yasoda Sai Ram Kandikonda, Jinho D. Choi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The task of Text-to-SQL enables anyone to retrieve information from SQL
databases using natural language. While this task has made substantial
progress, the two primary evaluation metrics -- Execution Accuracy (EXE) and
Exact Set Matching Accuracy (ESM) -- suffer from inherent limitations that can
misrepresent performance. Specifically, ESM's rigid matching overlooks
semantically correct but stylistically different queries, whereas EXE can
overestimate correctness by ignoring structural errors that yield correct
outputs. These shortcomings become especially problematic when assessing
outputs from large language model (LLM)-based approaches without fine-tuning,
which vary more in style and structure compared to their fine-tuned
counterparts. Thus, we introduce a new metric, Enhanced Tree Matching (ETM),
which mitigates these issues by comparing queries using both syntactic and
semantic elements. Through evaluating nine LLM-based models, we show that EXE
and ESM can produce false positive and negative rates as high as 23.0% and
28.9%, while ETM reduces these rates to 0.3% and 2.7%, respectively. We release
our ETM script as open source, offering the community a more robust and
reliable approach to evaluating Text-to-SQL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ URSA: Understanding and Verifying Chain-of-thought Reasoning in
  Multimodal Mathematics 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.04686v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.04686v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Chain-of-Thought (CoT) reasoning is widely used to enhance the mathematical
reasoning capabilities of large language models (LLMs). The introduction of
process supervision for CoT trajectories has sparked discussions on improving
test-time scaling, thereby unlocking the System 2-style thinking capabilities
of these models. However, in multimodal mathematical reasoning, the scarcity of
high-quality CoT training data has hindered existing models from achieving both
deliberate reasoning and fine-grained verification. In this work, we propose a
novel framework that introduces System 2-style thinking to multimodal
mathematical reasoning. We introduce a three-module CoT data synthesis process
that integrates CoT distillation, trajectory-format rewriting, and format
unification. This process generates MMathCoT-1M, a high-quality CoT reasoning
instruction fine-tuning dataset. Furthermore, we implement a dual-view
trajectory labeling automation that targets both visual grounding fidelity and
deductive chain validity, resulting in the DualMath-1.1M dataset. The URSA-8B
model, trained on MMathCoT-1M, achieves new state-of-the-art (SOTA) performance
among similarly sized multimodal LLMs on six popular reasoning benchmarks.
Training URSA-8B further on the DualMath-1.1M dataset yields URSA-RM-8B, a
verifier that enhances URSA-8B's test-time performance and surpasses strong
closed-source multimodal MLLMs like GPT-4o. The model weights, training data,
and code have been open-sourced: https://github.com/URSA-MATH/URSA-MATH.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Fix typos and add results. 27 pages, 11 tables, 17 figures. Models,
  training data and code have been open-sourced. Project url:
  https://ursa-math.github.io</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Automated Capability Discovery via Model Self-Exploration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07577v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07577v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Cong Lu, Shengran Hu, Jeff Clune
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Foundation models have become general-purpose assistants, exhibiting diverse
capabilities across numerous domains through training on web-scale data. It
remains challenging to precisely characterize even a fraction of the full
spectrum of capabilities and potential risks in any new model. Existing
evaluation approaches often require significant human effort, and it is taking
increasing effort to design ever harder challenges for more capable models. We
introduce Automated Capability Discovery (ACD), a framework that designates one
foundation model as a scientist to systematically propose open-ended tasks
probing the abilities of a subject model (potentially itself). By combining
frontier models with ideas from the field of open-endedness, ACD automatically
and systematically uncovers both surprising capabilities and failures in the
subject model. We demonstrate ACD across a range of foundation models
(including the GPT, Claude, and Llama series), showing that it automatically
reveals thousands of capabilities that would be challenging for any single team
to uncover. We further validate our method's automated scoring with extensive
human surveys, observing high agreement between model-generated and human
evaluations. By leveraging foundation models' ability to both create tasks and
self-evaluate, ACD is a significant step toward scalable, automated evaluation
of novel AI systems. All code and evaluation logs are open-sourced at
https://github.com/conglu1997/ACD.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">24</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimal <span class="highlight-title">Dataset</span> Size for Recommender Systems: Evaluating Algorithms'
  Performance via Downsampling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08845v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08845v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ardalan Arabzadeh, Joeran Beel, Tobias Vente
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This thesis investigates dataset downsampling as a strategy to optimize
energy efficiency in recommender systems while maintaining competitive
performance. With increasing dataset sizes posing computational and
environmental challenges, this study explores the trade-offs between energy
efficiency and recommendation quality in Green Recommender Systems, which aim
to reduce environmental impact. By applying two downsampling approaches to
seven datasets, 12 algorithms, and two levels of core pruning, the research
demonstrates significant reductions in runtime and carbon emissions. For
example, a 30% downsampling portion can reduce runtime by 52% compared to the
full dataset, leading to a carbon emission reduction of up to 51.02 KgCO2e
during the training of a single algorithm on a single dataset. The analysis
reveals that algorithm performance under different downsampling portions
depends on factors like dataset characteristics, algorithm complexity, and the
specific downsampling configuration (scenario dependent). Some algorithms,
which showed lower nDCG@10 scores compared to higher-performing ones, exhibited
lower sensitivity to the amount of training data, offering greater potential
for efficiency in lower downsampling portions. On average, these algorithms
retained 81% of full-size performance using only 50% of the training set. In
certain downsampling configurations, where more users were progressively
included while keeping the test set size fixed, they even showed higher nDCG@10
scores than when using the full dataset. These findings highlight the
feasibility of balancing sustainability and effectiveness, providing insights
for designing energy-efficient recommender systems and promoting sustainable AI
practices.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Ask in Any Modality: A Comprehensive <span class="highlight-title">Survey</span> on Multimodal
  Retrieval-Augmented Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08826v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08826v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mohammad Mahdi Abootorabi, Amirhosein Zobeiri, Mahdi Dehghani, Mohammadali Mohammadkhani, Bardia Mohammadi, Omid Ghahroodi, Mahdieh Soleymani Baghshah, Ehsaneddin Asgari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) struggle with hallucinations and outdated
knowledge due to their reliance on static training data. Retrieval-Augmented
Generation (RAG) mitigates these issues by integrating external dynamic
information enhancing factual and updated grounding. Recent advances in
multimodal learning have led to the development of Multimodal RAG,
incorporating multiple modalities such as text, images, audio, and video to
enhance the generated outputs. However, cross-modal alignment and reasoning
introduce unique challenges to Multimodal RAG, distinguishing it from
traditional unimodal RAG. This survey offers a structured and comprehensive
analysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,
evaluation, methodologies, and innovations in retrieval, fusion, augmentation,
and generation. We precisely review training strategies, robustness
enhancements, and loss functions, while also exploring the diverse Multimodal
RAG scenarios. Furthermore, we discuss open challenges and future research
directions to support advancements in this evolving field. This survey lays the
foundation for developing more capable and reliable AI systems that effectively
leverage multimodal dynamic external knowledge bases. Resources are available
at https://github.com/llm-lab-org/Multimodal-RAG-Survey.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion
  in Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonduk Seo, Seunghyun Lee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Query expansion is widely used in Information Retrieval (IR) to improve
search outcomes by enriching queries with additional contextual information.
Although recent Large Language Model (LLM) based methods generate
pseudo-relevant content and expanded terms via multiple prompts, they often
yield repetitive, narrow expansions that lack the diverse context needed to
retrieve all relevant information. In this paper, we introduce QA-Expand, a
novel and effective framework for query expansion. It first generates multiple
relevant questions from the initial query and subsequently produces
corresponding pseudo-answers as surrogate documents. A feedback model further
rewrites and filters these answers to ensure only the most informative
augmentations are incorporated. Extensive experiments on benchmarks such as
BEIR and TREC demonstrate that QA-Expand enhances retrieval performance by up
to 13% over state-of-the-art methods, offering a robust solution for modern
retrieval challenges.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>8 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Fine-Tuning Topics through Weighting Aspect Keywords 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08496v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08496v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ali Nazari, Michael Weiss
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic modeling often requires examining topics from multiple perspectives to
uncover hidden patterns, especially in less explored areas. This paper presents
an approach to address this need, utilizing weighted keywords from various
aspects derived from a domain knowledge. The research method starts with
standard topic modeling. Then, it adds a process consisting of four key steps.
First, it defines keywords for each aspect. Second, it gives weights to these
keywords based on their relevance. Third, it calculates relevance scores for
aspect-weighted keywords and topic keywords to create aspect-topic models.
Fourth, it uses these scores to tune relevant new documents. Finally, the
generated topic models are interpreted and validated. The findings show that
top-scoring documents are more likely to be about the same aspect of a topic.
This highlights the model's effectiveness in finding the related documents to
the aspects.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 8 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composite Sketch+Text Queries for Retrieving Objects with Elusive Names
  and Complex Interactions <span class="chip">AAAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08438v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08438v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prajwal Gatti, Kshitij Parikh, Dhriti Prasanna Paul, Manish Gupta, Anand Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-native speakers with limited vocabulary often struggle to name specific
objects despite being able to visualize them, e.g., people outside Australia
searching for numbats. Further, users may want to search for such elusive
objects with difficult-to-sketch interactions, e.g., numbat digging in the
ground. In such common but complex situations, users desire a search interface
that accepts composite multimodal queries comprising hand-drawn sketches of
difficult-to-name but easy-to-draw objects and text describing
difficult-to-sketch but easy-to-verbalize object attributes or interaction with
the scene. This novel problem statement distinctly differs from the previously
well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image
retrieval) problems. To study this under-explored task, we curate a dataset,
CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M
queries and 108K natural scene images. Further, as a solution to this problem,
we propose a pretrained multimodal transformer-based baseline, STNET
(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant
objects in the natural scene image, and encodes the text and image to perform
image retrieval. In addition to contrastive learning, we propose multiple
training objectives that improve the performance of our model. Extensive
experiments show that our proposed method outperforms several state-of-the-art
retrieval methods for text-only, sketch-only, and composite query modalities.
We make the dataset and code available at our project website.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AAAI 2024, 9 pages. Project Website:
  https://vl2g.github.io/projects/cstbir</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph Foundation Models for Recommendation: A Comprehensive <span class="highlight-title">Survey</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08346v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08346v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bin Wu, Yihang Wang, Yuanhao Zeng, Jiawei Liu, Jiashu Zhao, Cheng Yang, Yawen Li, Long Xia, Dawei Yin, Chuan Shi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems (RS) serve as a fundamental tool for navigating the vast
expanse of online information, with deep learning advancements playing an
increasingly important role in improving ranking accuracy. Among these, graph
neural networks (GNNs) excel at extracting higher-order structural information,
while large language models (LLMs) are designed to process and comprehend
natural language, making both approaches highly effective and widely adopted.
Recent research has focused on graph foundation models (GFMs), which integrate
the strengths of GNNs and LLMs to model complex RS problems more efficiently by
leveraging the graph-based structure of user-item relationships alongside
textual understanding. In this survey, we provide a comprehensive overview of
GFM-based RS technologies by introducing a clear taxonomy of current
approaches, diving into methodological details, and highlighting key challenges
and future directions. By synthesizing recent advancements, we aim to offer
valuable insights into the evolving landscape of GFM-based recommender systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Model-Free Counterfactual Subset Selection at Scale 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08326v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08326v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minh Hieu Nguyen, Viet Hung Doan, Anh Tuan Nguyen, Jun Jo, Quoc Viet Hung Nguyen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring transparency in AI decision-making requires interpretable
explanations, particularly at the instance level. Counterfactual explanations
are a powerful tool for this purpose, but existing techniques frequently depend
on synthetic examples, introducing biases from unrealistic assumptions, flawed
models, or skewed data. Many methods also assume full dataset availability, an
impractical constraint in real-time environments where data flows continuously.
In contrast, streaming explanations offer adaptive, real-time insights without
requiring persistent storage of the entire dataset. This work introduces a
scalable, model-free approach to selecting diverse and relevant counterfactual
examples directly from observed data. Our algorithm operates efficiently in
streaming settings, maintaining $O(\log k)$ update complexity per item while
ensuring high-quality counterfactual selection. Empirical evaluations on both
real-world and synthetic datasets demonstrate superior performance over
baseline methods, with robust behavior even under adversarial conditions.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Unlocking Scaling Law in Industrial Recommendation Systems with a
  Three-step Paradigm based Large User Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08309v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08309v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bencheng Yan, Shilei Liu, Zhiyuan Zeng, Zihao Wang, Yizhen Zhang, Yujin Yuan, Langming Liu, Jiaqi Liu, Di Wang, Wenbo Su, Wang Pengjie, Jian Xu, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in autoregressive Large Language Models (LLMs) have
achieved significant milestones, largely attributed to their scalability, often
referred to as the "scaling law". Inspired by these achievements, there has
been a growing interest in adapting LLMs for Recommendation Systems (RecSys) by
reformulating RecSys tasks into generative problems. However, these End-to-End
Generative Recommendation (E2E-GR) methods tend to prioritize idealized goals,
often at the expense of the practical advantages offered by traditional Deep
Learning based Recommendation Models (DLRMs) in terms of in features,
architecture, and practices. This disparity between idealized goals and
practical needs introduces several challenges and limitations, locking the
scaling law in industrial RecSys. In this paper, we introduce a large user
model (LUM) that addresses these limitations through a three-step paradigm,
designed to meet the stringent requirements of industrial settings while
unlocking the potential for scalable recommendations. Our extensive
experimental evaluations demonstrate that LUM outperforms both state-of-the-art
DLRMs and E2E-GR approaches. Notably, LUM exhibits excellent scalability, with
performance improvements observed as the model scales up to 7 billion
parameters. Additionally, we have successfully deployed LUM in an industrial
application, where it achieved significant gains in an A/B test, further
validating its effectiveness and practicality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ChorusCVR: Chorus Supervision for Entire Space Post-Click Conversion
  Rate Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08277v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08277v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Cheng, Yucheng Lu, Boyang Xia, Jiangxia Cao, Kuan Xu, Mingxing Wen, Wei Jiang, Jiaming Zhang, Zhaojie Liu, Kun Gai, Guorui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Post-click conversion rate (CVR) estimation is a vital task in many
recommender systems of revenue businesses, e.g., e-commerce and advertising. In
a perspective of sample, a typical CVR positive sample usually goes through a
funnel of exposure to click to conversion. For lack of post-event labels for
un-clicked samples, CVR learning task commonly only utilizes clicked samples,
rather than all exposed samples as for click-through rate (CTR) learning task.
However, during online inference, CVR and CTR are estimated on the same assumed
exposure space, which leads to a inconsistency of sample space between training
and inference, i.e., sample selection bias (SSB). To alleviate SSB, previous
wisdom proposes to design novel auxiliary tasks to enable the CVR learning on
un-click training samples, such as CTCVR and counterfactual CVR, etc. Although
alleviating SSB to some extent, none of them pay attention to the
discrimination between ambiguous negative samples (un-clicked) and factual
negative samples (clicked but un-converted) during modelling, which makes CVR
model lacks robustness. To full this gap, we propose a novel ChorusCVR model to
realize debiased CVR learning in entire-space.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MoLoRec: A Generalizable and Efficient Framework for LLM-Based
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08271v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08271v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Min Hou, Chenxi Bai, Le Wu, Hao Liu, Kun Zhang, Kai Zhang, Richang Hong, Meng Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have achieved remarkable success in recent
years, owing to their impressive generalization capabilities and rich world
knowledge. To capitalize on the potential of using LLMs as recommender systems,
mainstream approaches typically focus on two paradigms. The first paradigm
designs multi-domain or multi-task instruction data for generalizable
recommendation, so as to align LLMs with general recommendation areas and deal
with cold-start recommendation. The second paradigm enhances domain-specific
recommendation tasks with parameter-efficient fine-tuning techniques, in order
to improve models under the warm recommendation scenarios. While most previous
works treat these two paradigms separately, we argue that they have
complementary advantages, and combining them together would be helpful.
  To that end, in this paper, we propose a generalizable and efficient
LLM-based recommendation framework MoLoRec. Our approach starts by
parameter-efficient fine-tuning a domain-general module with general
recommendation instruction data, to align LLM with recommendation knowledge.
Then, given users' behavior of a specific domain, we construct a
domain-specific instruction dataset and apply efficient fine-tuning to the
pre-trained LLM. After that, we provide approaches to integrate the above
domain-general part and domain-specific part with parameters mixture. Please
note that, MoLoRec is efficient with plug and play, as the domain-general
module is trained only once, and any domain-specific plug-in can be efficiently
merged with only domain-specific fine-tuning. Extensive experiments on multiple
datasets under both warm and cold-start recommendation scenarios validate the
effectiveness and generality of the proposed MoLoRec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Wisdom of the Crowds in Forecasting: Forecast Summarization for
  Supporting Future Event Prediction 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08205v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08205v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Anisha Saha, Adam Jatowt
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Future Event Prediction (FEP) is an essential activity whose demand and
application range across multiple domains. While traditional methods like
simulations, predictive and time-series forecasting have demonstrated promising
outcomes, their application in forecasting complex events is not entirely
reliable due to the inability of numerical data to accurately capture the
semantic information related to events. One forecasting way is to gather and
aggregate collective opinions on the future to make predictions as cumulative
perspectives carry the potential to help estimating the likelihood of upcoming
events. In this work, we organize the existing research and frameworks that aim
to support future event prediction based on crowd wisdom through aggregating
individual forecasts. We discuss the challenges involved, available datasets,
as well as the scope of improvement and future research directions for this
task. We also introduce a novel data model to represent individual forecast
statements.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural
  Network for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08161v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08161v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangjin Xie, Yuxin Chen, Ruipeng Wang, Kai Ouyang, Zihan Zhang, Hai-Tao Zheng, Buyue Qian, Hansen Zheng, Bo Hu, Chengxiang Zhuo, Zang Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph neural networks have been widely used in recent recommender systems,
where negative sampling plays an important role. Existing negative sampling
methods restrict the relationship between nodes as either hard positive pairs
or hard negative pairs. This leads to the loss of structural information, and
lacks the mechanism to generate positive pairs for nodes with few neighbors. To
overcome limitations, we propose a novel soft link-based sampling method,
namely MixDec Sampling, which consists of Mixup Sampling module and Decay
Sampling module. The Mixup Sampling augments node features by synthesizing new
nodes and soft links, which provides sufficient number of samples for nodes
with few neighbors. The Decay Sampling strengthens the digestion of graph
structure information by generating soft links for node embedding learning. To
the best of our knowledge, we are the first to model sampling relationships
between nodes by soft links in GNN-based recommender systems. Extensive
experiments demonstrate that the proposed MixDec Sampling can significantly and
consistently improve the recommendation performance of several representative
GNN-based models on various recommendation benchmarks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ SS4Rec: Continuous-Time Sequential Recommendation with State Space
  Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08132v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08132v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Xiao, Huiying Wang, Qifeng Zhou, Qing Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation is a key area in the field of recommendation
systems aiming to model user interest based on historical interaction sequences
with irregular intervals. While previous recurrent neural network-based and
attention-based approaches have achieved significant results, they have
limitations in capturing system continuity due to the discrete characteristics.
In the context of continuous-time modeling, state space model (SSM) offers a
potential solution, as it can effectively capture the dynamic evolution of user
interest over time. However, existing SSM-based approaches ignore the impact of
irregular time intervals within historical user interactions, making it
difficult to model complexed user-item transitions in sequences. To address
this issue, we propose a hybrid SSM-based model called SS4Rec for
continuous-time sequential recommendation. SS4Rec integrates a time-aware SSM
to handle irregular time intervals and a relation-aware SSM to model contextual
dependencies, enabling it to infer user interest from both temporal and
sequential perspectives. In the training process, the time-aware SSM and the
relation-aware SSM are discretized by variable stepsizes according to user
interaction time intervals and input data, respectively. This helps capture the
continuous dependency from irregular time intervals and provides time-specific
personalized recommendations. Experimental studies on five benchmark datasets
demonstrate the superiority and effectiveness of SS4Rec.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Collaborative Filtering Meets Spectrum Shift: Connecting User-Item
  Interaction with Graph-Structured Side Information 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08071v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08071v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunhang He, Cong Xu, Jun Wang, Wei Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Graph Neural Network (GNN) has demonstrated their superiority in
collaborative filtering, where the user-item (U-I) interaction bipartite graph
serves as the fundamental data format. However, when graph-structured side
information (e.g., multimodal similarity graphs or social networks) is
integrated into the U-I bipartite graph, existing graph collaborative filtering
methods fall short of achieving satisfactory performance. We quantitatively
analyze this problem from a spectral perspective. Recall that a bipartite graph
possesses a full spectrum within the range of [-1, 1], with the highest
frequency exactly achievable at -1 and the lowest frequency at 1; however, we
observe as more side information is incorporated, the highest frequency of the
augmented adjacency matrix progressively shifts rightward. This spectrum shift
phenomenon has caused previous approaches built for the full spectrum [-1, 1]
to assign mismatched importance to different frequencies. To this end, we
propose Spectrum Shift Correction (dubbed SSC), incorporating shifting and
scaling factors to enable spectral GNNs to adapt to the shifted spectrum.
Unlike previous paradigms of leveraging side information, which necessitate
tailored designs for diverse data types, SSC directly connects traditional
graph collaborative filtering with any graph-structured side information.
Experiments on social and multimodal recommendation demonstrate the
effectiveness of SSC, achieving relative improvements of up to 23% without
incurring any additional computational overhead.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ End-to-end Training for Recommendation with Language-based User Profiles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18870v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18870v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhaolin Gao, Joyce Zhou, Yijia Dai, Thorsten Joachims
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  There is a growing interest in natural language-based user profiles for
recommender systems, which aims to enhance transparency and scrutability
compared with embedding-based methods. Existing studies primarily generate
these profiles using zero-shot inference from large language models (LLMs), but
their quality remains insufficient, leading to suboptimal recommendation
performance. In this paper, we introduce LangPTune, the first end-to-end
training framework to optimize LLM-generated user profiles. Our method
significantly outperforms zero-shot approaches by explicitly training the LLM
for the recommendation objective. Through extensive evaluations across diverse
training configurations and benchmarks, we demonstrate that LangPTune not only
surpasses zero-shot baselines but can also matches the performance of
state-of-the-art embedding-based methods. Finally, we investigate whether the
training procedure preserves the interpretability of these profiles compared to
zero-shot inference through both GPT-4 simulations and crowdworker user
studies. Implementation of LangPTune can be found at
https://github.com/ZhaolinGao/LangPTune.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Topic-Aware Knowledge Graph with Large Language Models for
  Interoperability in Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.20163v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.20163v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Minhye Jeon, Seokho Ahn, Young-Duk Seo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The use of knowledge graphs in recommender systems has become one of the
common approaches to addressing data sparsity and cold start problems. Recent
advances in large language models (LLMs) offer new possibilities for processing
side and context information within knowledge graphs. However, consistent
integration across various systems remains challenging due to the need for
domain expert intervention and differences in system characteristics. To
address these issues, we propose a consistent approach that extracts both
general and specific topics from both side and context information using LLMs.
First, general topics are iteratively extracted and updated from side
information. Then, specific topics are extracted using context information.
Finally, to address synonymous topics generated during the specific topic
extraction process, a refining algorithm processes and resolves these issues
effectively. This approach allows general topics to capture broad knowledge
across diverse item characteristics, while specific topics emphasize detailed
attributes, providing a more comprehensive understanding of the semantic
features of items and the preferences of users. Experimental results
demonstrate significant improvements in recommendation performance across
diverse knowledge graphs.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by The 40th ACM/SIGAPP Symposium On Applied Computing(SAC)
  2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CODE-ACCORD: A Corpus of building regulatory data for rule generation
  towards automatic compliance checking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.02231v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.02231v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hansi Hettiarachchi, Amna Dridi, Mohamed Medhat Gaber, Pouyan Parsafard, Nicoleta Bocaneala, Katja Breitenfelder, Gonçal Costa, Maria Hedblom, Mihaela Juganaru-Mathieu, Thamer Mecharnia, Sumee Park, He Tan, Abdel-Rahman H. Tawil, Edlira Vakaj
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Automatic Compliance Checking (ACC) within the Architecture, Engineering, and
Construction (AEC) sector necessitates automating the interpretation of
building regulations to achieve its full potential. Converting textual rules
into machine-readable formats is challenging due to the complexities of natural
language and the scarcity of resources for advanced Machine Learning (ML).
Addressing these challenges, we introduce CODE-ACCORD, a dataset of 862
sentences from the building regulations of England and Finland. Only the
self-contained sentences, which express complete rules without needing
additional context, were considered as they are essential for ACC. Each
sentence was manually annotated with entities and relations by a team of 12
annotators to facilitate machine-readable rule generation, followed by careful
curation to ensure accuracy. The final dataset comprises 4,297 entities and
4,329 relations across various categories, serving as a robust ground truth.
CODE-ACCORD supports a range of ML and Natural Language Processing (NLP) tasks,
including text classification, entity recognition, and relation extraction. It
enables applying recent trends, such as deep neural networks and large language
models, to ACC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This is a preprint of an article submitted to the Scientific Data
  Journal</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Intent Alignment between Interaction and Language Spaces for
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03307v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03307v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Intent-based recommender systems have garnered significant attention for
uncovering latent fine-grained preferences. Intents, as underlying factors of
interactions, are crucial for improving recommendation interpretability. Most
methods define intents as learnable parameters updated alongside interactions.
However, existing frameworks often overlook textual information (e.g., user
reviews, item descriptions), which is crucial for alleviating the sparsity of
interaction intents. Exploring these multimodal intents, especially the
inherent differences in representation spaces, poses two key challenges: i) How
to align multimodal intents and effectively mitigate noise issues; ii) How to
extract and match latent key intents across modalities. To tackle these
challenges, we propose a model-agnostic framework, Intent Representation
Learning with Large Language Model (IRLLRec), which leverages large language
models (LLMs) to construct multimodal intents and enhance recommendations.
Specifically, IRLLRec employs a dual-tower architecture to learn multimodal
intent representations. Next, we propose pairwise and translation alignment to
eliminate inter-modal differences and enhance robustness against noisy input
features. Finally, to better match textual and interaction-based intents, we
employ momentum distillation to perform teacher-student learning on fused
intent representations. Empirical evaluations on three datasets show that our
IRLLRec framework outperforms baselines.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 8 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ A Parameter Update Balancing Algorithm for Multi-task Ranking Models in
  Recommendation Systems <span class="chip">ICDM'24</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.05806v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.05806v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jun Yuan, Guohao Cai, Zhenhua Dong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multi-task ranking models have become essential for modern real-world
recommendation systems. While most recommendation researches focus on designing
sophisticated models for specific scenarios, achieving performance improvement
for multi-task ranking models across various scenarios still remains a
significant challenge. Training all tasks naively can result in inconsistent
learning, highlighting the need for the development of multi-task optimization
(MTO) methods to tackle this challenge. Conventional methods assume that the
optimal joint gradient on shared parameters leads to optimal parameter updates.
However, the actual update on model parameters may deviates significantly from
gradients when using momentum based optimizers such as Adam, and we design and
execute statistical experiments to support the observation. In this paper, we
propose a novel Parameter Update Balancing algorithm for multi-task
optimization, denoted as PUB. In contrast to traditional MTO method which are
based on gradient level tasks fusion or loss level tasks fusion, PUB is the
first work to optimize multiple tasks through parameter update balancing.
Comprehensive experiments on benchmark multi-task ranking datasets demonstrate
that PUB consistently improves several multi-task backbones and achieves
state-of-the-art performance. Additionally, experiments on benchmark computer
vision datasets show the great potential of PUB in various multi-task learning
scenarios. Furthermore, we deployed our method for an industrial evaluation on
the real-world commercial platform, HUAWEI AppGallery, where PUB significantly
enhances the online multi-task ranking model, efficiently managing the primary
traffic of a crucial channel.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICDM'24</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ FIRE: Fact-checking with Iterative Retrieval and Verification <span class="chip">NAACL</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.00784v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.00784v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhuohan Xie, Rui Xing, Yuxia Wang, Jiahui Geng, Hasan Iqbal, Dhruv Sahnan, Iryna Gurevych, Preslav Nakov
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Fact-checking long-form text is challenging, and it is therefore common
practice to break it down into multiple atomic claims. The typical approach to
fact-checking these atomic claims involves retrieving a fixed number of pieces
of evidence, followed by a verification step. However, this method is usually
not cost-effective, as it underutilizes the verification model's internal
knowledge of the claim and fails to replicate the iterative reasoning process
in human search strategies. To address these limitations, we propose FIRE, a
novel agent-based framework that integrates evidence retrieval and claim
verification in an iterative manner. Specifically, FIRE employs a unified
mechanism to decide whether to provide a final answer or generate a subsequent
search query, based on its confidence in the current judgment. We compare FIRE
with other strong fact-checking frameworks and find that it achieves slightly
better performance while reducing large language model (LLM) costs by an
average of 7.6 times and search costs by 16.5 times. These results indicate
that FIRE holds promise for application in large-scale fact-checking
operations. Our code is available at https://github.com/mbzuai-nlp/fire.git.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 figures, 8 tables, accepted to Findings of NAACL</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DisCo: Graph-Based Disentangled Contrastive Learning for Cold-Start
  Cross-Domain Recommendation <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.15005v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.15005v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hourun Li, Yifan Wang, Zhiping Xiao, Jia Yang, Changling Zhou, Ming Zhang, Wei Ju
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems are widely used in various real-world applications, but
they often encounter the persistent challenge of the user cold-start problem.
Cross-domain recommendation (CDR), which leverages user interactions from one
domain to improve prediction performance in another, has emerged as a promising
solution. However, users with similar preferences in the source domain may
exhibit different interests in the target domain. Therefore, directly
transferring embeddings may introduce irrelevant source-domain collaborative
information. In this paper, we propose a novel graph-based disentangled
contrastive learning framework to capture fine-grained user intent and filter
out irrelevant collaborative information, thereby avoiding negative transfer.
Specifically, for each domain, we use a multi-channel graph encoder to capture
diverse user intents. We then construct the affinity graph in the embedding
space and perform multi-step random walks to capture high-order user similarity
relationships. Treating one domain as the target, we propose a disentangled
intent-wise contrastive learning approach, guided by user similarity, to refine
the bridging of user intents across domains. Extensive experiments on four
benchmark CDR datasets demonstrate that DisCo consistently outperforms existing
state-of-the-art baselines, thereby validating the effectiveness of both DisCo
and its components.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Uncertainty Quantification and Decomposition for LLM-based
  Recommendation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17630v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17630v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wonbin Kweon, Sanghwan Jang, SeongKu Kang, Hwanjo Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Despite the widespread adoption of large language models (LLMs) for
recommendation, we demonstrate that LLMs often exhibit uncertainty in their
recommendations. To ensure the trustworthy use of LLMs in generating
recommendations, we emphasize the importance of assessing the reliability of
recommendations generated by LLMs. We start by introducing a novel framework
for estimating the predictive uncertainty to quantitatively measure the
reliability of LLM-based recommendations. We further propose to decompose the
predictive uncertainty into recommendation uncertainty and prompt uncertainty,
enabling in-depth analyses of the primary source of uncertainty. Through
extensive experiments, we (1) demonstrate predictive uncertainty effectively
indicates the reliability of LLM-based recommendations, (2) investigate the
origins of uncertainty with decomposed uncertainty measures, and (3) propose
uncertainty-aware prompting for a lower predictive uncertainty and enhanced
recommendation. Our source code and model weights are available at
https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WWW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ELASTIC: Efficient Linear Attention for Sequential Interest Compression 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.09380v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.09380v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaxin Deng, Shiyao Wang, Song Lu, Yinfeng Li, Xinchen Luo, Yuanjun Liu, Peixing Xu, Guorui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  State-of-the-art sequential recommendation models heavily rely on
transformer's attention mechanism. However, the quadratic computational and
memory complexities of self attention have limited its scalability for modeling
users' long range behaviour sequences. To address this problem, we propose
ELASTIC, an Efficient Linear Attention for SequenTial Interest Compression,
requiring only linear time complexity and decoupling model capacity from
computational cost. Specifically, ELASTIC introduces a fixed length interest
experts with linear dispatcher attention mechanism which compresses the
long-term behaviour sequences to a significantly more compact representation
which reduces up to 90% GPU memory usage with x2.7 inference speed up. The
proposed linear dispatcher attention mechanism significantly reduces the
quadratic complexity and makes the model feasible for adequately modeling
extremely long sequences. Moreover, in order to retain the capacity for
modeling various user interests, ELASTIC initializes a vast learnable interest
memory bank and sparsely retrieves compressed user's interests from the memory
with a negligible computational overhead. The proposed interest memory
retrieval technique significantly expands the cardinality of available interest
space while keeping the same computational cost, thereby striking a trade-off
between recommendation accuracy and efficiency. To validate the effectiveness
of our proposed ELASTIC, we conduct extensive experiments on various public
datasets and compare it with several strong sequential recommenders.
Experimental results demonstrate that ELASTIC consistently outperforms
baselines by a significant margin and also highlight the computational
efficiency of ELASTIC when modeling long sequences. We will make our
implementation code publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>We hereby withdraw this paper from arXiv due to incomplete
  experiments. Upon further review, we have determined that additional
  experimental work is necessary to fully validate our findings and conclusions</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ DOGR: Leveraging Document-Oriented Contrastive Learning in Generative
  Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07219v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07219v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Penghao Lu, Xin Dong, Yuansheng Zhou, Lei Cheng, Chuan Yuan, Linjian Mo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative retrieval constitutes an innovative approach in information
retrieval, leveraging generative language models (LM) to generate a ranked list
of document identifiers (docid) for a given query. It simplifies the retrieval
pipeline by replacing the large external index with model parameters. However,
existing works merely learned the relationship between queries and document
identifiers, which is unable to directly represent the relevance between
queries and documents. To address the above problem, we propose a novel and
general generative retrieval framework, namely Leveraging Document-Oriented
Contrastive Learning in Generative Retrieval (DOGR), which leverages
contrastive learning to improve generative retrieval tasks. It adopts a
two-stage learning strategy that captures the relationship between queries and
documents comprehensively through direct interactions. Furthermore, negative
sampling methods and corresponding contrastive learning objectives are
implemented to enhance the learning of semantic representations, thereby
promoting a thorough comprehension of the relationship between queries and
documents. Experimental results demonstrate that DOGR achieves state-of-the-art
performance compared to existing generative retrieval methods on two public
benchmark datasets. Further experiments have shown that our framework is
generally effective for common identifier construction techniques.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">10</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Human-Centric Foundation Models: Perception, Generation and Agentic
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08556v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08556v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shixiang Tang, Yizhou Wang, Lu Chen, Yuan Wang, Sida Peng, Dan Xu, Wanli Ouyang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Human understanding and generation are critical for modeling digital humans
and humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)
inspired by the success of generalist models, such as large language and vision
models, have emerged to unify diverse human-centric tasks into a single
framework, surpassing traditional task-specific approaches. In this survey, we
present a comprehensive overview of HcFMs by proposing a taxonomy that
categorizes current approaches into four groups: (1) Human-centric Perception
Foundation Models that capture fine-grained features for multi-modal 2D and 3D
understanding. (2) Human-centric AIGC Foundation Models that generate
high-fidelity, diverse human-related content. (3) Unified Perception and
Generation Models that integrate these capabilities to enhance both human
understanding and synthesis. (4) Human-centric Agentic Foundation Models that
extend beyond perception and generation to learn human-like intelligence and
interactive behaviors for humanoid embodied tasks. We review state-of-the-art
techniques, discuss emerging challenges and future research directions. This
survey aims to serve as a roadmap for researchers and practitioners working
towards more robust, versatile, and intelligent digital human and embodiments
modeling.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>9 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ "You'll Be Alice Adventuring in Wonderland!" Processes, Challenges, and
  Opportunities of Creating Animated Virtual Reality Stories 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08513v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08513v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lin-Ping Yuan, Feilin Han, Liwenhan Xie, Junjie Zhang, Jian Zhao, Huamin Qu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Animated virtual reality (VR) stories, combining the presence of VR and the
artistry of computer animation, offer a compelling way to deliver messages and
evoke emotions. Motivated by the growing demand for immersive narrative
experiences, more creators are creating animated VR stories. However, a
holistic understanding of their creation processes and challenges involved in
crafting these stories is still limited. Based on semi-structured interviews
with 21 animated VR story creators, we identify ten common stages in their
end-to-end creation processes, ranging from idea generation to evaluation,
which form diverse workflows that are story-driven or visual-driven.
Additionally, we highlight nine unique issues that arise during the creation
process, such as a lack of reference material for multi-element plots, the
absence of specific functionalities for story integration, and inadequate
support for audience evaluation. We compare the creation of animated VR stories
to general XR applications and distill several future research opportunities.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Conditionally accepted to the ACM Conference on Human Factors in
  Computing Systems (CHI'25)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Composite Sketch+Text Queries for Retrieving Objects with Elusive Names
  and Complex Interactions <span class="chip">AAAI 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08438v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08438v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Prajwal Gatti, Kshitij Parikh, Dhriti Prasanna Paul, Manish Gupta, Anand Mishra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Non-native speakers with limited vocabulary often struggle to name specific
objects despite being able to visualize them, e.g., people outside Australia
searching for numbats. Further, users may want to search for such elusive
objects with difficult-to-sketch interactions, e.g., numbat digging in the
ground. In such common but complex situations, users desire a search interface
that accepts composite multimodal queries comprising hand-drawn sketches of
difficult-to-name but easy-to-draw objects and text describing
difficult-to-sketch but easy-to-verbalize object attributes or interaction with
the scene. This novel problem statement distinctly differs from the previously
well-researched TBIR (text-based image retrieval) and SBIR (sketch-based image
retrieval) problems. To study this under-explored task, we curate a dataset,
CSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M
queries and 108K natural scene images. Further, as a solution to this problem,
we propose a pretrained multimodal transformer-based baseline, STNET
(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant
objects in the natural scene image, and encodes the text and image to perform
image retrieval. In addition to contrastive learning, we propose multiple
training objectives that improve the performance of our model. Extensive
experiments show that our proposed method outperforms several state-of-the-art
retrieval methods for text-only, sketch-only, and composite query modalities.
We make the dataset and code available at our project website.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at AAAI 2024, 9 pages. Project Website:
  https://vl2g.github.io/projects/cstbir</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ COutfitGAN: Learning to Synthesize Compatible Outfits Supervised by
  Silhouette Masks and Fashion Styles 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.08674v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.08674v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dongliang Zhou, Haijun Zhang, Qun Li, Jianghong Ma, Xiaofei Xu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  How to recommend outfits has gained considerable attention in both academia
and industry in recent years. Many studies have been carried out regarding
fashion compatibility learning, to determine whether the fashion items in an
outfit are compatible or not. These methods mainly focus on evaluating the
compatibility of existing outfits and rarely consider applying such knowledge
to 'design' new fashion items. We propose the new task of generating
complementary and compatible fashion items based on an arbitrary number of
given fashion items. In particular, given some fashion items that can make up
an outfit, the aim of this paper is to synthesize photo-realistic images of
other, complementary, fashion items that are compatible with the given ones. To
achieve this, we propose an outfit generation framework, referred to as
COutfitGAN, which includes a pyramid style extractor, an outfit generator, a
UNet-based real/fake discriminator, and a collocation discriminator. To train
and evaluate this framework, we collected a large-scale fashion outfit dataset
with over 200K outfits and 800K fashion items from the Internet. Extensive
experiments show that COutfitGAN outperforms other baselines in terms of
similarity, authenticity, and compatibility measurements.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper was accepted by IEEE TMM</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Enhancing Learned Image Compression via Cross Window-based Attention 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.21144v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.21144v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Priyanka Mudgal, Feng Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, learned image compression methods have demonstrated superior
rate-distortion performance compared to traditional image compression methods.
Recent methods utilize convolutional neural networks (CNN), variational
autoencoders (VAE), invertible neural networks (INN), and transformers. Despite
their significant contributions, a main drawback of these models is their poor
performance in capturing local redundancy. Therefore, to leverage global
features along with local redundancy, we propose a CNN-based solution
integrated with a feature encoding module. The feature encoding module encodes
important features before feeding them to the CNN and then utilizes cross-scale
window-based attention, which further captures local redundancy. Cross-scale
window-based attention is inspired by the attention mechanism in transformers
and effectively enlarges the receptive field. Both the feature encoding module
and the cross-scale window-based attention module in our architecture are
flexible and can be incorporated into any other network architecture. We
evaluate our method on the Kodak and CLIC datasets and demonstrate that our
approach is effective and on par with state-of-the-art methods. Our code is
publicly available at https://github.com/prmudgal/CWAM_IC_ISVC. .
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Paper accepted and presented in ISVC'24. Copyrights stay with ISVC
  Our code is available at: https://github.com/prmudgal/CWAM_IC_ISVC</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive
  Modality Alignment 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04328v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04328v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in large language models, particularly following GPT-4o, have
sparked increasing interest in developing omni-modal models capable of
understanding more modalities. While some open-source alternatives have
emerged, there is still a notable lag behind specialized single-modality models
in performance. In this paper, we present Ola, an Omni-modal language model
that achieves competitive performance across image, video, and audio
understanding compared to specialized counterparts. The core design of Ola lies
in its progressive modality alignment strategy that extends the supporting
modality of the language model progressively. Our training pipeline begins with
the most distinct modalities: image and text, then gradually expands the skill
sets of the model using speech data that connects language and audio knowledge,
and video data that connects all modalities. The progressive learning pipeline
also enables us to maintain a relatively small size of the cross-modal
alignment data, making developing omni-modal from existing vision-language
models easy and less costly. Moreover, to unlock an advanced interactive
experience like GPT-4o, we further design a sentence-wise decoding solution for
streaming speech generation. Extensive experiments demonstrate that Ola
surpasses existing open omni-modal LLMs across all modalities while achieving
highly competitive performance compared to state-of-the-art specialized models
of similar sizes. We aim to make Ola a fully open omni-modal understanding
solution to advance future research in this emerging field. Model weights,
code, and data are open-sourced at https://github.com/Ola-Omni/Ola.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TimeSuite: Improving MLLMs for Long Video Understanding via Grounded
  Tuning <span class="chip">ICLR2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.19702v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.19702v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Large Language Models (MLLMs) have demonstrated impressive
performance in short video understanding. However, understanding long-form
videos still remains challenging for MLLMs. This paper proposes TimeSuite, a
collection of new designs to adapt the existing short-form video MLLMs for long
video understanding, including a simple yet efficient framework to process long
video sequence, a high-quality video dataset for grounded tuning of MLLMs, and
a carefully-designed instruction tuning task to explicitly incorporate the
grounding supervision in the traditional QA format. Specifically, based on
VideoChat, we propose our long-video MLLM, coined as VideoChat-T, by
implementing a token shuffling to compress long video tokens and introducing
Temporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of
visual representation. Meanwhile, we introduce the TimePro, a comprehensive
grounding-centric instruction tuning dataset composed of 9 tasks and 349k
high-quality grounded annotations. Notably, we design a new instruction tuning
task type, called Temporal Grounded Caption, to peform detailed video
descriptions with the corresponding time stamps prediction. This explicit
temporal location prediction will guide MLLM to correctly attend on the visual
content when generating description, and thus reduce the hallucination risk
caused by the LLMs. Experimental results demonstrate that our TimeSuite
provides a successful solution to enhance the long video understanding
capability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the
benchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T
exhibits robust zero-shot temporal grounding capabilities, significantly
outperforming the existing state-of-the-art MLLMs. After fine-tuning, it
performs on par with the traditional supervised expert models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by ICLR2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Routing Experts: Learning to Route Dynamic Experts in Multi-modal Large
  Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.14093v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.14093v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qiong Wu, Zhaoxi Ke, Yiyi Zhou, Xiaoshuai Sun, Rongrong Ji
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently, mixture of experts (MoE) has become a popular paradigm for
achieving the trade-off between modal capacity and efficiency of multi-modal
large language models (MLLMs). Different from previous efforts, we are
dedicated to exploring the dynamic expert path in an already exist MLLM and
show that a standard MLLM can be also a mixture of experts. To approach this
target, we propose a novel dynamic expert scheme for MLLMs, termed Routing
Experts (RoE), which can achieve example-dependent optimal path routing without
obvious structure tweaks. Meanwhile, a new regularization of structure sparsity
is also introduced to enforce MLLMs to learn more short-cut inference, ensuring
the efficiency. In addition, we also realize the first attempt of aligning the
training and inference schemes of MLLMs in terms of network routing. To
validate RoE, we apply it to a set of latest MLLMs, including LLaVA-1.5,
LLaVA-HR and VILA, and conduct extensive experiments on a bunch of VL
benchmarks. The experiment results not only show the great advantages of our
RoE in improving MLLMs' efficiency, but also yield obvious advantages than
MoE-LLaVA in both performance and speed, e.g., an average performance gain of
3.3% on 5 benchmarks while being faster.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video
  Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07531v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07531v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sixiao Zheng, Zimian Peng, Yanpeng Zhou, Yi Zhu, Hang Xu, Xiangru Huang, Yanwei Fu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent image-to-video generation methods have demonstrated success in
enabling control over one or two visual elements, such as camera trajectory or
object motion. However, these methods are unable to offer control over multiple
visual elements due to limitations in data and network efficacy. In this paper,
we introduce VidCRAFT3, a novel framework for precise image-to-video generation
that enables control over camera motion, object motion, and lighting direction
simultaneously. To better decouple control over each visual element, we propose
the Spatial Triple-Attention Transformer, which integrates lighting direction,
text, and image in a symmetric way. Since most real-world video datasets lack
lighting annotations, we construct a high-quality synthetic video dataset, the
VideoLightingDirection (VLD) dataset. This dataset includes lighting direction
annotations and objects of diverse appearance, enabling VidCRAFT3 to
effectively handle strong light transmission and reflection effects.
Additionally, we propose a three-stage training strategy that eliminates the
need for training data annotated with multiple visual elements (camera motion,
object motion, and lighting direction) simultaneously. Extensive experiments on
benchmark datasets demonstrate the efficacy of VidCRAFT3 in producing
high-quality video content, surpassing existing state-of-the-art methods in
terms of control granularity and visual coherence. All code and data will be
publicly available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Music for All: Exploring Multicultural Representations in Music
  Generation Models <span class="chip">NAACL'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07328v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07328v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advent of Music-Language Models has greatly enhanced the automatic music
generation capability of AI systems, but they are also limited in their
coverage of the musical genres and cultures of the world. We present a study of
the datasets and research papers for music generation and quantify the bias and
under-representation of genres. We find that only 5.7% of the total hours of
existing music datasets come from non-Western genres, which naturally leads to
disparate performance of the models across genres. We then investigate the
efficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating
this bias. Our experiments with two popular models -- MusicGen and Mustango,
for two underrepresented non-Western music traditions -- Hindustani Classical
and Turkish Makam music, highlight the promises as well as the non-triviality
of cross-genre adaptation of music through small datasets, implying the need
for more equitable baseline music-language models that are designed for
cross-cultural transfer learning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>17 pages, 5 figures, accepted to NAACL'25</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-11T00:00:00Z">2025-02-11</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">21</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ReTreever: Tree-based Coarse-to-Fine Representations for Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07971v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07971v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Gupta, Zichao Li, Tianyi Chen, Cem Subakan, Siva Reddy, Perouz Taslakian, Valentina Zantedeschi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Document retrieval is a core component of question-answering systems, as it
enables conditioning answer generation on new and large-scale corpora. While
effective, the standard practice of encoding documents into high-dimensional
embeddings for similarity search entails large memory and compute footprints,
and also makes it hard to inspect the inner workings of the system. In this
paper, we propose a tree-based method for organizing and representing reference
documents at various granular levels, which offers the flexibility to balance
cost and utility, and eases the inspection of the corpus content and retrieval
operations. Our method, called ReTreever, jointly learns a routing function per
internal node of a binary tree such that query and reference documents are
assigned to similar tree branches, hence directly optimizing for retrieval
performance. Our evaluations show that ReTreever generally preserves full
representation accuracy. Its hierarchical structure further provides strong
coarse representations and enhances transparency by indirectly learning
meaningful semantic groupings. Among hierarchical retrieval methods, ReTreever
achieves the best retrieval accuracy at the lowest latency, proving that this
family of techniques can be viable in practical applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ exHarmony: Authorship and Citations for Benchmarking the <span class="highlight-title">Review</span>er
  Assignment Problem 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07683v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07683v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sajad Ebrahimi, Sara Salamat, Negar Arabzadeh, Mahdi Bashari, Ebrahim Bagheri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The peer review process is crucial for ensuring the quality and reliability
of scholarly work, yet assigning suitable reviewers remains a significant
challenge. Traditional manual methods are labor-intensive and often
ineffective, leading to nonconstructive or biased reviews. This paper
introduces the exHarmony (eHarmony but for connecting experts to manuscripts)
benchmark, designed to address these challenges by re-imagining the Reviewer
Assignment Problem (RAP) as a retrieval task. Utilizing the extensive data from
OpenAlex, we propose a novel approach that considers a host of signals from the
authors, most similar experts, and the citation relations as potential
indicators for a suitable reviewer for a manuscript. This approach allows us to
develop a standard benchmark dataset for evaluating the reviewer assignment
problem without needing explicit labels. We benchmark various methods,
including traditional lexical matching, static neural embeddings, and
contextualized neural embeddings, and introduce evaluation metrics that assess
both relevance and diversity in the context of RAP. Our results indicate that
while traditional methods perform reasonably well, contextualized embeddings
trained on scholarly literature show the best performance. The findings
underscore the importance of further research to enhance the diversity and
effectiveness of reviewer assignments.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ IU4Rec: Interest Unit-Based Product Organization and Recommendation for
  E-Commerce Platform <span class="chip">KDD25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07658v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07658v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenhao Wu, Xiaojie Li, Lin Wang, Jialiang Zhou, Di Wu, Qinye Xie, Qingheng Zhang, Yin Zhang, Shuguang Han, Fei Huang, Junfeng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Most recommendation systems typically follow a product-based paradigm
utilizing user-product interactions to identify the most engaging items for
users. However, this product-based paradigm has notable drawbacks for
Xianyu~\footnote{Xianyu is China's largest online C2C e-commerce platform where
a large portion of the product are post by individual sellers}. Most of the
product on Xianyu posted from individual sellers often have limited stock
available for distribution, and once the product is sold, it's no longer
available for distribution. This result in most items distributed product on
Xianyu having relatively few interactions, affecting the effectiveness of
traditional recommendation depending on accumulating user-item interactions. To
address these issues, we introduce \textbf{IU4Rec}, an \textbf{I}nterest
\textbf{U}nit-based two-stage \textbf{Rec}ommendation system framework. We
first group products into clusters based on attributes such as category, image,
and semantics. These IUs are then integrated into the Recommendation system,
delivering both product and technological innovations. IU4Rec begins by
grouping products into clusters based on attributes such as category, image,
and semantics, forming Interest Units (IUs). Then we redesign the
recommendation process into two stages. In the first stage, the focus is on
recommend these Interest Units, capturing broad-level interests. In the second
stage, it guides users to find the best option among similar products within
the selected Interest Unit. User-IU interactions are incorporated into our
ranking models, offering the advantage of more persistent IU behaviors compared
to item-specific interactions. Experimental results on the production dataset
and online A/B testing demonstrate the effectiveness and superiority of our
proposed IU-centric recommendation approach.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review at KDD25 ADS. This work has already been deployed on the
  Xianyu platform in Alibaba. arXiv admin note: substantial text overlap with
  arXiv:2403.06747</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Exploring Patterns Behind Sports 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07491v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07491v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chang Liu, Chengcheng Ma, XuanQi Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a comprehensive framework for time series prediction
using a hybrid model that combines ARIMA and LSTM. The model incorporates
feature engineering techniques, including embedding and PCA, to transform raw
data into a lower-dimensional representation while retaining key information.
The embedding technique is used to convert categorical data into continuous
vectors, facilitating the capture of complex relationships. PCA is applied to
reduce dimensionality and extract principal components, enhancing model
performance and computational efficiency. To handle both linear and nonlinear
patterns in the data, the ARIMA model captures linear trends, while the LSTM
model models complex nonlinear dependencies. The hybrid model is trained on
historical data and achieves high accuracy, as demonstrated by low RMSE and MAE
scores. Additionally, the paper employs the run test to assess the randomness
of sequences, providing insights into the underlying patterns. Ablation studies
are conducted to validate the roles of different components in the model,
demonstrating the significance of each module. The paper also utilizes the SHAP
method to quantify the impact of traditional advantages on the predicted
results, offering a detailed understanding of feature importance. The KNN
method is used to determine the optimal prediction interval, further enhancing
the model's accuracy. The results highlight the effectiveness of combining
traditional statistical methods with modern deep learning techniques for robust
time series forecasting in Sports.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ ETimeline: An Extensive Timeline Generation <span class="highlight-title">Dataset</span> based on Large
  Language Model 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07474v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07474v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaochen Liu, Yanan Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Timeline generation is of great significance for a comprehensive
understanding of the development of events over time. Its goal is to organize
news chronologically, which helps to identify patterns and trends that may be
obscured when viewing news in isolation, making it easier to track the
development of stories and understand the interrelationships between key
events. Timelines are now common in various commercial products, but academic
research in this area is notably scarce. Additionally, the current datasets are
in need of refinement for enhanced utility and expanded coverage. In this
paper, we propose ETimeline, which encompasses over $13,000$ news articles,
spanning $600$ bilingual timelines across $28$ news domains. Specifically, we
gather a candidate pool of more than $120,000$ news articles and employ the
large language model (LLM) Pipeline to improve performance, ultimately yielding
the ETimeline. The data analysis underscores the appeal of ETimeline.
Additionally, we also provide the news pool data for further research and
analysis. This work contributes to the advancement of timeline generation
research and supports a wide range of tasks, including topic generation and
event relationships. We believe that this dataset will serve as a catalyst for
innovative research and bridge the gap between academia and industry in
understanding the practical application of technology services. The dataset is
available at https://zenodo.org/records/11392212
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated
  Videos 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07327v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07327v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the rapid development of AI-generated content (AIGC), the creation of
high-quality AI-generated videos has become faster and easier, resulting in the
Internet being flooded with all kinds of video content. However, the impact of
these videos on the content ecosystem remains largely unexplored. Video
information retrieval remains a fundamental approach for accessing video
content. Building on the observation that retrieval models often favor
AI-generated content in ad-hoc and image retrieval tasks, we investigate
whether similar biases emerge in the context of challenging video retrieval,
where temporal and visual factors may further influence model behavior. To
explore this, we first construct a comprehensive benchmark dataset containing
both real and AI-generated videos, along with a set of fair and rigorous
metrics to assess bias. This benchmark consists of 13,000 videos generated by
two state-of-the-art open-source video generation models. We meticulously
design a suite of rigorous metrics to accurately measure this preference,
accounting for potential biases arising from the limited frame rate and
suboptimal quality of AIGC videos. We then applied three off-the-shelf video
retrieval models to perform retrieval tasks on this hybrid dataset. Our
findings reveal a clear preference for AI-generated videos in retrieval.
Further investigation shows that incorporating AI-generated videos into the
training set of retrieval models exacerbates this bias. Unlike the preference
observed in image modalities, we find that video retrieval bias arises from
both unseen visual and temporal information, making the root causes of video
bias a complex interplay of these two factors. To mitigate this bias, we
fine-tune the retrieval models using a contrastive learning approach. The
results of this study highlight the potential implications of AI-generated
videos on retrieval systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ <span class="highlight-title">Prompt</span>-Based Document Modifications In Ranking Competitions 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07315v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07315v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Niv Bardas, Tommy Mordo, Oren Kurland, Moshe Tennenholtz, Gal Zur
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We study prompting-based approaches with Large Language Models (LLMs) for
modifying documents so as to promote their ranking in a competitive search
setting. Our methods are inspired by prior work on leveraging LLMs as rankers.
We evaluate our approach by deploying it as a bot in previous ranking
competitions and in competitions we organized. Our findings demonstrate that
our approach effectively improves document ranking while preserving high levels
of faithfulness to the original content and maintaining overall document
quality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CreAgent: Towards Long-Term Evaluation of Recommender System under
  Platform-Creator Information Asymmetry 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07307v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07307v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiaopeng Ye, Chen Xu, Zhongxiang Sun, Jun Xu, Gang Wang, Zhenhua Dong, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ensuring the long-term sustainability of recommender systems (RS) emerges as
a crucial issue. Traditional offline evaluation methods for RS typically focus
on immediate user feedback, such as clicks, but they often neglect the
long-term impact of content creators. On real-world content platforms, creators
can strategically produce and upload new items based on user feedback and
preference trends. While previous studies have attempted to model creator
behavior, they often overlook the role of information asymmetry. This asymmetry
arises because creators primarily have access to feedback on the items they
produce, while platforms possess data on the entire spectrum of user feedback.
Current RS simulators, however, fail to account for this asymmetry, leading to
inaccurate long-term evaluations. To address this gap, we propose CreAgent, a
Large Language Model (LLM)-empowered creator simulation agent. By incorporating
game theory's belief mechanism and the fast-and-slow thinking framework,
CreAgent effectively simulates creator behavior under conditions of information
asymmetry. Additionally, we enhance CreAgent's simulation ability by
fine-tuning it using Proximal Policy Optimization (PPO). Our credibility
validation experiments show that CreAgent aligns well with the behaviors
between real-world platform and creator, thus improving the reliability of
long-term RS evaluations. Moreover, through the simulation of RS involving
CreAgents, we can explore how fairness- and diversity-aware RS algorithms
contribute to better long-term performance for various stakeholders. CreAgent
and the simulation platform are publicly available at
https://github.com/shawnye2000/CreAgent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Flow Matching for Collaborative Filtering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07303v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07303v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chengkai Liu, Yangtian Zhang, Jianling Wang, Rex Ying, James Caverlee
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Generative models have shown great promise in collaborative filtering by
capturing the underlying distribution of user interests and preferences.
However, existing approaches struggle with inaccurate posterior approximations
and misalignment with the discrete nature of recommendation data, limiting
their expressiveness and real-world performance. To address these limitations,
we propose FlowCF, a novel flow-based recommendation system leveraging flow
matching for collaborative filtering. We tailor flow matching to the unique
challenges in recommendation through two key innovations: (1) a behavior-guided
prior that aligns with user behavior patterns to handle the sparse and
heterogeneous user-item interactions, and (2) a discrete flow framework to
preserve the binary nature of implicit feedback while maintaining the benefits
of flow matching, such as stable training and efficient inference. Extensive
experiments demonstrate that FlowCF achieves state-of-the-art recommendation
accuracy across various datasets with the fastest inference speed, making it a
compelling approach for real-world recommender systems.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Personalized Negative Reservoir for Incremental Learning in Recommender
  Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.03993v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.03993v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Antonios Valkanas, Yuening Wang, Yingxue Zhang, Mark Coates
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems have become an integral part of online platforms. Every
day the volume of training data is expanding and the number of user
interactions is constantly increasing. The exploration of larger and more
expressive models has become a necessary pursuit to improve user experience.
However, this progression carries with it an increased computational burden. In
commercial settings, once a recommendation system model has been trained and
deployed it typically needs to be updated frequently as new client data arrive.
Cumulatively, the mounting volume of data is guaranteed to eventually make full
batch retraining of the model from scratch computationally infeasible. Naively
fine-tuning solely on the new data runs into the well-documented problem of
catastrophic forgetting. Despite the fact that negative sampling is a crucial
part of training with implicit feedback, no specialized technique exists that
is tailored to the incremental learning framework. In this work, we propose a
personalized negative reservoir strategy, which is used to obtain negative
samples for the standard triplet loss of graph-based recommendation systems.
Our technique balances alleviation of forgetting with plasticity by encouraging
the model to remember stable user preferences and selectively forget when user
interests change. We derive the mathematical formulation of a negative sampler
to populate and update the reservoir. We integrate our design in three SOTA and
commonly used incremental recommendation models. We show that these concrete
realizations of our negative reservoir framework achieve state-of-the-art
results for standard benchmarks using multiple top-k evaluation metrics.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Faux Polyglot: A Study on Information Disparity in Multilingual Large
  Language Models <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.05502v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.05502v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nikhil Sharma, Kenton Murray, Ziang Xiao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Although the multilingual capability of LLMs offers new opportunities to
overcome the language barrier, do these capabilities translate into real-life
scenarios where linguistic divide and knowledge conflicts between multilingual
sources are known occurrences? In this paper, we studied LLM's linguistic
preference in a cross-language RAG-based information search setting. We found
that LLMs displayed systemic bias towards information in the same language as
the query language in both document retrieval and answer generation.
Furthermore, in scenarios where no information is in the language of the query,
LLMs prefer documents in high-resource languages during generation, potentially
reinforcing the dominant views. Such bias exists for both factual and
opinion-based queries. Our results highlight the linguistic divide within
multilingual LLMs in information search systems. The seemingly beneficial
multilingual capability of LLMs may backfire on information parity by
reinforcing language-specific information cocoons or filter bubbles further
marginalizing low-resource views.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized
  Recommendation Systems <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06097v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06097v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shuli Wang, Xue Wei, Senjie Kou, Chi Wang, Wenshuai Chen, Qi Tang, Yinhua Zhu, Xiong Xiao, Xingxing Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Reranking plays a crucial role in modern multi-stage recommender systems by
rearranging the initial ranking list. Due to the inherent challenges of
combinatorial search spaces, some current research adopts an
evaluator-generator paradigm, with a generator generating feasible sequences
and an evaluator selecting the best sequence based on the estimated list
utility. However, these methods still face two issues. Firstly, due to the goal
inconsistency problem between the evaluator and generator, the generator tends
to fit the local optimal solution of exposure distribution rather than
combinatorial space optimization. Secondly, the strategy of generating target
items one by one is difficult to achieve optimality because it ignores the
information of subsequent items.
  To address these issues, we propose a utilizing Neighbor Lists model for
Generative Reranking (NLGR), which aims to improve the performance of the
generator in the combinatorial space. NLGR follows the evaluator-generator
paradigm and improves the generator's training and generating methods.
Specifically, we use neighbor lists in combination space to enhance the
training process, making the generator perceive the relative scores and find
the optimization direction. Furthermore, we propose a novel sampling-based
non-autoregressive generation method, which allows the generator to jump
flexibly from the current list to any neighbor list. Extensive experiments on
public and industrial datasets validate NLGR's effectiveness and we have
successfully deployed NLGR on the Meituan food delivery platform.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2025 Industry Track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SampleLLM: Optimizing Tabular Data Synthesis in Recommendations 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16125v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16125v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jingtong Gao, Zhaocheng Du, Xiaopeng Li, Yichao Wang, Xiangyang Li, Huifeng Guo, Ruiming Tang, Xiangyu Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Tabular data synthesis is crucial in machine learning, yet existing general
methods-primarily based on statistical or deep learning models-are highly
data-dependent and often fall short in recommender systems. This limitation
arises from their difficulty in capturing complex distributions and
understanding feature relationships from sparse and limited data, along with
their inability to grasp semantic feature relations. Recently, Large Language
Models (LLMs) have shown potential in generating synthetic data samples through
few-shot learning and semantic understanding. However, they often suffer from
inconsistent distribution and lack of diversity due to their inherent
distribution disparity with the target dataset. To address these challenges and
enhance tabular data synthesis for recommendation tasks, we propose a novel
two-stage framework named SampleLLM to improve the quality of LLM-based tabular
data synthesis for recommendations by ensuring better distribution alignment.
In the first stage, SampleLLM employs LLMs with Chain-of-Thought prompts and
diverse exemplars to generate data that closely aligns with the target dataset
distribution, even when input samples are limited. The second stage uses an
advanced feature attribution-based importance sampling method to refine feature
relationships within the synthesized data, reducing any distribution biases
introduced by the LLM. Experimental results on three recommendation datasets,
two general datasets, and online deployment illustrate that SampleLLM
significantly surpasses existing methods for recommendation tasks and holds
promise for a broader range of tabular data scenarios.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MIM: Multi-modal Content Interest Modeling Paradigm for User Behavior
  Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00321v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00321v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bencheng Yan, Si Chen, Shichang Jia, Jianyu Liu, Yueran Liu, Chenghan Fu, Wanxian Guan, Hui Zhao, Xiang Zhang, Kai Zhang, Wenbo Su, Pengjie Wang, Jian Xu, Bo Zheng, Baolin Liu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Click-Through Rate (CTR) prediction is a crucial task in recommendation
systems, online searches, and advertising platforms, where accurately capturing
users' real interests in content is essential for performance. However,
existing methods heavily rely on ID embeddings, which fail to reflect users'
true preferences for content such as images and titles. This limitation becomes
particularly evident in cold-start and long-tail scenarios, where traditional
approaches struggle to deliver effective results. To address these challenges,
we propose a novel Multi-modal Content Interest Modeling paradigm (MIM), which
consists of three key stages: Pre-training, Content-Interest-Aware Supervised
Fine-Tuning (C-SFT), and Content-Interest-Aware UBM (CiUBM). The pre-training
stage adapts foundational models to domain-specific data, enabling the
extraction of high-quality multi-modal embeddings. The C-SFT stage bridges the
semantic gap between content and user interests by leveraging user behavior
signals to guide the alignment of embeddings with user preferences. Finally,
the CiUBM stage integrates multi-modal embeddings and ID-based collaborative
filtering signals into a unified framework. Comprehensive offline experiments
and online A/B tests conducted on the Taobao, one of the world's largest
e-commerce platforms, demonstrated the effectiveness and efficiency of MIM
method. The method has been successfully deployed online, achieving a
significant increase of +14.14% in CTR and +4.12% in RPM, showcasing its
industrial applicability and substantial impact on platform performance. To
promote further research, we have publicly released the code and dataset at
https://pan.quark.cn/s/8fc8ec3e74f3.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Distinguished Quantized Guidance for Diffusion-based Sequence
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.17670v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.17670v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wenyu Mao, Shuchang Liu, Haoyang Liu, Haozhe Liu, Xiang Li, Lantao Hu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Diffusion models (DMs) have emerged as promising approaches for sequential
recommendation due to their strong ability to model data distributions and
generate high-quality items. Existing work typically adds noise to the next
item and progressively denoises it guided by the user's interaction sequence,
generating items that closely align with user interests. However, we identify
two key issues in this paradigm. First, the sequences are often heterogeneous
in length and content, exhibiting noise due to stochastic user behaviors. Using
such sequences as guidance may hinder DMs from accurately understanding user
interests. Second, DMs are prone to data bias and tend to generate only the
popular items that dominate the training dataset, thus failing to meet the
personalized needs of different users. To address these issues, we propose
Distinguished Quantized Guidance for Diffusion-based Sequence Recommendation
(DiQDiff), which aims to extract robust guidance to understand user interests
and generate distinguished items for personalized user interests within DMs. To
extract robust guidance, DiQDiff introduces Semantic Vector Quantization (SVQ)
to quantize sequences into semantic vectors (e.g., collaborative signals and
category interests) using a codebook, which can enrich the guidance to better
understand user interests. To generate distinguished items, DiQDiff
personalizes the generation through Contrastive Discrepancy Maximization (CDM),
which maximizes the distance between denoising trajectories using contrastive
loss to prevent biased generation for different users. Extensive experiments
are conducted to compare DiQDiff with multiple baseline models across four
widely-used datasets. The superior recommendation performance of DiQDiff
against leading approaches demonstrates its effectiveness in sequential
recommendation tasks.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AURO: Reinforcement Learning for Adaptive User Retention Optimization in
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.03984v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.03984v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhenghai Xue, Qingpeng Cai, Bin Yang, Lantao Hu, Peng Jiang, Kun Gai, Bo An
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of Reinforcement Learning (RL) has garnered increasing attention
for its ability of optimizing user retention in recommender systems. A primary
obstacle in this optimization process is the environment non-stationarity
stemming from the continual and complex evolution of user behavior patterns
over time, such as variations in interaction rates and retention propensities.
These changes pose significant challenges to existing RL algorithms for
recommendations, leading to issues with dynamics and reward distribution
shifts. This paper introduces a novel approach called \textbf{A}daptive
\textbf{U}ser \textbf{R}etention \textbf{O}ptimization (AURO) to address this
challenge. To navigate the recommendation policy in non-stationary
environments, AURO introduces an state abstraction module in the policy
network. The module is trained with a new value-based loss function, aligning
its output with the estimated performance of the current policy. As the policy
performance of RL is sensitive to environment drifts, the loss function enables
the state abstraction to be reflective of environment changes and notify the
recommendation policy to adapt accordingly. Additionally, the non-stationarity
of the environment introduces the problem of implicit cold start, where the
recommendation policy continuously interacts with users displaying novel
behavior patterns. AURO encourages exploration guarded by performance-based
rejection sampling to maintain a stable recommendation quality in the
cost-sensitive online environment. Extensive empirical analysis are conducted
in a user retention simulator, the MovieLens dataset, and a live short-video
recommendation platform, demonstrating AURO's superior performance against all
evaluated baseline algorithms.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>The Web Conference 2025 (Oral)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Large Memory Network for Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05558v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05558v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hui Lu, Zheng Chai, Yuchao Zheng, Zhe Chen, Deping Xie, Peng Xu, Xun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modeling user behavior sequences in recommender systems is essential for
understanding user preferences over time, enabling personalized and accurate
recommendations for improving user retention and enhancing business values.
Despite its significance, there are two challenges for current sequential
modeling approaches. From the spatial dimension, it is difficult to mutually
perceive similar users' interests for a generalized intention understanding;
from the temporal dimension, current methods are generally prone to forgetting
long-term interests due to the fixed-length input sequence. In this paper, we
present Large Memory Network (LMN), providing a novel idea by compressing and
storing user history behavior information in a large-scale memory block. With
the elaborated online deployment strategy, the memory block can be easily
scaled up to million-scale in the industry. Extensive offline comparison
experiments, memory scaling up experiments, and online A/B test on Douyin
E-Commerce Search (ECS) are performed, validating the superior performance of
LMN. Currently, LMN has been fully deployed in Douyin ECS, serving millions of
users each day.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniHGKR: Unified Instruction-aware Heterogeneous Knowledge Retrievers <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20163v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20163v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dehai Min, Zhiyang Xu, Guilin Qi, Lifu Huang, Chenyu You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing information retrieval (IR) models often assume a homogeneous
structure for knowledge sources and user queries, limiting their applicability
in real-world settings where retrieval is inherently heterogeneous and diverse.
In this paper, we introduce UniHGKR, a unified instruction-aware heterogeneous
knowledge retriever that (1) builds a unified retrieval space for heterogeneous
knowledge and (2) follows diverse user instructions to retrieve knowledge of
specified types. UniHGKR consists of three principal stages: heterogeneous
self-supervised pretraining, text-anchored embedding alignment, and
instruction-aware retriever fine-tuning, enabling it to generalize across
varied retrieval contexts. This framework is highly scalable, with a BERT-based
version and a UniHGKR-7B version trained on large language models. Also, we
introduce CompMix-IR, the first native heterogeneous knowledge retrieval
benchmark. It includes two retrieval scenarios with various instructions, over
9,400 question-answer (QA) pairs, and a corpus of 10 million entries, covering
four different types of data. Extensive experiments show that UniHGKR
consistently outperforms state-of-the-art methods on CompMix-IR, achieving up
to 6.36% and 54.23% relative improvements in two scenarios, respectively.
Finally, by equipping our retriever for open-domain heterogeneous QA systems,
we achieve a new state-of-the-art result on the popular ConvMix task, with an
absolute improvement of up to 5.90 points.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>NAACL 2025, Main, Long Paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Adaptive Domain Scaling for Personalized Sequential Modeling in
  Recommenders 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05523v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05523v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheng Chai, Hui Lu, Di Chen, Qin Ren, Yuchao Zheng, Xun Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Users generally exhibit complex behavioral patterns and diverse intentions in
multiple business scenarios of super applications like Douyin, presenting great
challenges to current industrial multi-domain recommenders. To mitigate the
discrepancies across diverse domains, researches and industrial practices
generally emphasize sophisticated network structures to accomodate diverse data
distributions, while neglecting the inherent understanding of user behavioral
sequence from the multi-domain perspective. In this paper, we present Adaptive
Domain Scaling (ADS) model, which comprehensively enhances the personalization
capability in target-aware sequence modeling across multiple domains.
Specifically, ADS comprises of two major modules, including personalized
sequence representation generation (PSRG) and personalized candidate
representation generation (PCRG). The modules contribute to the tailored
multi-domain learning by dynamically learning both the user behavioral sequence
item representation and the candidate target item representation under
different domains, facilitating adaptive user intention understanding.
Experiments are performed on both a public dataset and two billion-scaled
industrial datasets, and the extensive results verify the high effectiveness
and compatibility of ADS. Besides, we conduct online experiments on two
influential business scenarios including Douyin Advertisement Platform and
Douyin E-commerce Service Platform, both of which show substantial business
improvements. Currently, ADS has been fully deployed in many recommendation
services at ByteDance, serving billions of users.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CROWN: A Novel Approach to Comprehending Users' Preferences for Accurate
  Personalized News Recommendation <span class="chip">WWW</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09401v6">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09401v6.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yunyong Ko, Seongeun Ryu, Sang-Wook Kim
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Personalized news recommendation aims to assist users in finding news
articles that align with their interests, which plays a pivotal role in
mitigating users' information overload problem. Although many recent works have
been studied for better personalized news recommendation, the following
challenges should be explored more: (C1) Comprehending manifold intents coupled
within a news article, (C2) Differentiating varying post-read preferences of
news articles, and (C3) Addressing the cold-start user problem. To tackle the
aforementioned challenges together, in this paper, we propose a novel
personalized news recommendation framework (CROWN) that employs (1)
category-guided intent disentanglement for (C1), (2) consistency-based news
representation for (C2), and (3) GNN-enhanced hybrid user representation for
(C3). Furthermore, we incorporate a category prediction into the training
process of CROWN as an auxiliary task, which provides supplementary supervisory
signals to enhance intent disentanglement. Extensive experiments on two
real-world datasets reveal that (1) CROWN provides consistent performance
improvements over ten state-of-the-art news recommendation methods and (2) the
proposed strategies significantly improve the accuracy of CROWN.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages, 7 figures, 9 tables, the ACM Web Conference (WWW) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ RALLRec: Improving Retrieval Augmented Large Language Model
  Recommendation with Representation Learning <span class="chip">WWW'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06101v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06101v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jian Xu, Sichun Luo, Xiangyu Chen, Haoming Huang, Hanxu Hou, Linqi Song
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have been integrated into recommendation systems
to enhance user behavior comprehension. The Retrieval Augmented Generation
(RAG) technique is further incorporated into these systems to retrieve more
relevant items and improve system performance. However, existing RAG methods
rely primarily on textual semantics and often fail to incorporate the most
relevant items, limiting the effectiveness of the systems.
  In this paper, we propose Representation learning for retrieval-Augmented
Large Language model Recommendation (RALLRec). Specifically, we enhance textual
semantics by prompting LLMs to generate more detailed item descriptions,
followed by joint representation learning of textual and collaborative
semantics, which are extracted by the LLM and recommendation models,
respectively. Considering the potential time-varying characteristics of user
interest, a simple yet effective reranking method is further introduced to
capture the dynamics of user preference. We conducted extensive experiments on
three real-world datasets, and the evaluation results validated the
effectiveness of our method. Code is made public at
https://github.com/JianXu95/RALLRec.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by TheWebConf'25 (WWW'25) as a Short Paper</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RenderBox: Expressive Performance Rendering with Text Control 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07711v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07711v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Huan Zhang, Akira Maezawa, Simon Dixon
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Expressive music performance rendering involves interpreting symbolic scores
with variations in timing, dynamics, articulation, and instrument-specific
techniques, resulting in performances that capture musical can emotional
intent. We introduce RenderBox, a unified framework for text-and-score
controlled audio performance generation across multiple instruments, applying
coarse-level controls through natural language descriptions and granular-level
controls using music scores. Based on a diffusion transformer architecture and
cross-attention joint conditioning, we propose a curriculum-based paradigm that
trains from plain synthesis to expressive performance, gradually incorporating
controllable factors such as speed, mistakes, and style diversity.
  RenderBox achieves high performance compared to baseline models across key
metrics such as FAD and CLAP, and also tempo and pitch accuracy under different
prompting tasks. Subjective evaluation further demonstrates that RenderBox is
able to generate controllable expressive performances that sound natural and
musically engaging, aligning well with prompts and intent.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07411v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07411v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sheng Zhou, Junbin Xiao, Qingyun Li, Yicong Li, Xun Yang, Dan Guo, Meng Wang, Tat-Seng Chua, Angela Yao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce EgoTextVQA, a novel and rigorously constructed benchmark for
egocentric QA assistance involving scene text. EgoTextVQA contains 1.5K
ego-view videos and 7K scene-text aware questions that reflect real-user needs
in outdoor driving and indoor house-keeping activities. The questions are
designed to elicit identification and reasoning on scene text in an egocentric
and dynamic environment. With EgoTextVQA, we comprehensively evaluate 10
prominent multimodal large language models. Currently, all models struggle, and
the best results (Gemini 1.5 Pro) are around 33% accuracy, highlighting the
severe deficiency of these techniques in egocentric QA assistance. Our further
investigations suggest that precise temporal grounding and multi-frame
reasoning, along with high resolution and auxiliary scene-text inputs, are key
for better performance. With thorough analyses and heuristic suggestions, we
hope EgoTextVQA can serve as a solid testbed for research in egocentric
scene-text QA assistance.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HDCompression: Hybrid-Diffusion Image Compression for Ultra-Low Bitrates 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07160v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07160v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Lu, Yize Li, Yanzhi Wang, Wei Wang, Wei Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Image compression under ultra-low bitrates remains challenging for both
conventional learned image compression (LIC) and generative vector-quantized
(VQ) modeling. Conventional LIC suffers from severe artifacts due to heavy
quantization, while generative VQ modeling gives poor fidelity due to the
mismatch between learned generative priors and specific inputs. In this work,
we propose Hybrid-Diffusion Image Compression (HDCompression), a dual-stream
framework that utilizes both generative VQ-modeling and diffusion models, as
well as conventional LIC, to achieve both high fidelity and high perceptual
quality. Different from previous hybrid methods that directly use pre-trained
LIC models to generate low-quality fidelity-preserving information from heavily
quantized latent, we use diffusion models to extract high-quality complimentary
fidelity information from the ground-truth input, which can enhance the system
performance in several aspects: improving indices map prediction, enhancing the
fidelity-preserving output of the LIC stream, and refining conditioned image
reconstruction with VQ-latent correction. In addition, our diffusion model is
based on a dense representative vector (DRV), which is lightweight with very
simple sampling schedulers. Extensive experiments demonstrate that our
HDCompression outperforms the previous conventional LIC, generative
VQ-modeling, and hybrid frameworks in both quantitative metrics and qualitative
visualization, providing balanced robust compression performance at ultra-low
bitrates.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under Review</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Fast Audio Codec Identification Using Overlapping LCS 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.00950v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.00950v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Farzane Jafari
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio data are widely exchanged over telecommunications networks. Due to the
limitations of network resources, these data are typically compressed before
transmission. Various methods are available for compressing audio data. To
access such audio information, it is first necessary to identify the codec used
for compression. One of the most effective approaches for audio codec
identification involves analyzing the content of received packets. In these
methods, statistical features extracted from the packets are utilized to
determine the codec employed. This paper proposes a novel method for audio
codec classification based on features derived from the overlapped longest
common sub-string and sub-sequence (LCS). The simulation results, which
achieved an accuracy of 97% for 8 KB packets, demonstrate the superiority of
the proposed method over conventional approaches. This method divides each 8 KB
packet into fifteen 1 KB packets with a 50% overlap. The results indicate that
this division has no significant impact on the simulation outcomes, while
significantly speeding up the feature extraction, being eight times faster than
the traditional method for extracting LCS features.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ BioVL-QR: Egocentric Biochemical Vision-and-Language <span class="highlight-title">Dataset</span> Using Micro
  QR Codes 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2404.03161v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2404.03161v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tomohiro Nishimoto, Taichi Nishimura, Koki Yamamoto, Keisuke Shirai, Hirotaka Kameko, Yuto Haneji, Tomoya Yoshida, Keiya Kajimura, Taiyu Cui, Chihiro Nishiwaki, Eriko Daikoku, Natsuko Okuda, Fumihito Ono, Shinsuke Mori
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces BioVL-QR, a biochemical vision-and-language dataset
comprising 23 egocentric experiment videos, corresponding protocols, and
vision-and-language alignments. A major challenge in understanding biochemical
videos is detecting equipment, reagents, and containers because of the
cluttered environment and indistinguishable objects. Previous studies assumed
manual object annotation, which is costly and time-consuming. To address the
issue, we focus on Micro QR Codes. However, detecting objects using only Micro
QR Codes is still difficult due to blur and occlusion caused by object
manipulation. To overcome this, we propose an object labeling method combining
a Micro QR Code detector with an off-the-shelf hand object detector. As an
application of the method and BioVL-QR, we tackled the task of localizing the
procedural steps in an instructional video. The experimental results show that
using Micro QR Codes and our method improves biochemical video understanding.
Data and code are available through https://nishi10mo.github.io/BioVL-QR/
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-10T00:00:00Z">2025-02-10</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Repository-level Code Search with Neural Retrieval Methods 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07067v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07067v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Siddharth Gandhi, Luyu Gao, Jamie Callan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper presents a multi-stage reranking system for repository-level code
search, which leverages the vastly available commit histories of large
open-source repositories to aid in bug fixing. We define the task of
repository-level code search as retrieving the set of files from the current
state of a code repository that are most relevant to addressing a user's
question or bug. The proposed approach combines BM25-based retrieval over
commit messages with neural reranking using CodeBERT to identify the most
pertinent files. By learning patterns from diverse repositories and their
commit histories, the system can surface relevant files for the task at hand.
The system leverages both commit messages and source code for relevance
matching, and is evaluated in both normal and oracle settings. Experiments on a
new dataset created from 7 popular open-source repositories demonstrate
substantial improvements of up to 80% in MAP, MRR and P@1 over the BM25
baseline, across a diverse set of queries, demonstrating the effectiveness this
approach. We hope this work aids LLM agents as a tool for better code search
and understanding. Our code and results obtained are publicly available.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>16 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ RSAttAE: An Information-Aware Attention-based Autoencoder Recommender
  System 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06705v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06705v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Dadashzadeh Taromi, Sina Heydari, Mohsen Hooshmand, Majid Ramezani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recommender systems play a crucial role in modern life, including information
retrieval, the pharmaceutical industry, retail, and entertainment. The
entertainment sector, in particular, attracts significant attention and
generates substantial profits. This work proposes a new method for predicting
unknown user-movie ratings to enhance customer satisfaction. To achieve this,
we utilize the MovieLens 100K dataset. Our approach introduces an
attention-based autoencoder to create meaningful representations and the
XGBoost method for rating predictions. The results demonstrate that our
proposal outperforms most of the existing state-of-the-art methods.
Availability: github.com/ComputationIASBS/RecommSys
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>6 pages, 4 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ The 2021 Tokyo Olympics Multilingual News Article <span class="highlight-title">Dataset</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06648v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06648v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Erik Novak, Erik Calcina, Dunja Mladenić, Marko Grobelnik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we introduce a dataset of multilingual news articles covering
the 2021 Tokyo Olympics. A total of 10,940 news articles were gathered from
1,918 different publishers, covering 1,350 sub-events of the 2021 Olympics, and
published between July 1, 2021, and August 14, 2021. These articles are written
in nine languages from different language families and in different scripts. To
create the dataset, the raw news articles were first retrieved via a service
that collects and analyzes news articles. Then, the articles were grouped using
an online clustering algorithm, with each group containing articles reporting
on the same sub-event. Finally, the groups were manually annotated and
evaluated. The development of this dataset aims to provide a resource for
evaluating the performance of multilingual news clustering algorithms, for
which limited datasets are available. It can also be used to analyze the
dynamics and events of the 2021 Tokyo Olympics from different perspectives. The
dataset is available in CSV format and can be accessed from the CLARIN.SI
repository.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LiveForesighter: Generating Future Information for Live-Streaming
  Recommendations at Kuaishou 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06557v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06557v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yucheng Lu, Jiangxia Cao, Xu Kuan, Wei Cheng, Wei Jiang, Jiaming Zhang, Yang Shuang, Liu Zhaojie, Liyin Hong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Live-streaming, as a new-generation media to connect users and authors, has
attracted a lot of attention and experienced rapid growth in recent years.
Compared with the content-static short-video recommendation, the live-streaming
recommendation faces more challenges in giving our users a satisfactory
experience: (1) Live-streaming content is dynamically ever-changing along time.
(2) valuable behaviors (e.g., send digital-gift, buy products) always require
users to watch for a long-time (>10 min). Combining the two attributes, here
raising a challenging question for live-streaming recommendation: How to
discover the live-streamings that the content user is interested in at the
current moment, and further a period in the future?
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Progressive Collaborative and Semantic Knowledge Fusion for Generative
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06269v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06269v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Longtao Xiao, Haozhao Wang, Cheng Wang, Linfei Ji, Yifan Wang, Jieming Zhu, Zhenhua Dong, Rui Zhang, Ruixuan Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  With the recent surge in interest surrounding generative paradigms,
generative recommendation has increasingly attracted the attention of
researchers in the recommendation community. This paradigm generally consists
of two stages. In the first stage, pretrained semantic embeddings or
collaborative ID embeddings are quantized to create item codes, aiming to
capture and preserve rich semantic or collaborative knowledge within these
codes. The second stage involves utilizing these discrete codes to perform an
autoregressive sequence generation task. Existing methods often either overlook
collaborative or semantic knowledge, or combine the two roughly. In this paper,
we observe that naively concatenating representations from semantic and
collaborative modality leads to a semantic domination issue, where the
resulting representation is overly influenced by semantic information,
effectively overshadowing the collaborative representation. Consequently,
downstream recommendation tasks fail to fully exploit the knowledge from both
modalities, resulting in suboptimal performance. To address this, we propose a
progressive collaborative and semantic knowledge fusion model for generative
recommendation, named PRORec, which integrates semantic and collaborative
knowledge with a unified code through a two-stage framework. Specifically, in
the first stage, we propose a cross-modality knowledge alignment task, which
integrates semantic knowledge into collaborative embeddings, enhancing their
representational capability. In the second stage, we propose an in-modality
knowledge distillation task, designed to effectively capture and integrate
knowledge from both semantic and collaborative modalities. Extensive
experiments on three widely used benchmarks validate the effectiveness of our
approach, demonstrating its superiority compared to existing methods.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Evaluating Entity Retrieval in Electronic Health Records: a Semantic Gap
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06252v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06252v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyun Zhao, Hongyi Yuan, Jingjing Liu, Haichao Chen, Huaiyuan Ying, Songchi Zhou, Sheng Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Entity retrieval plays a crucial role in the utilization of Electronic Health
Records (EHRs) and is applied across a wide range of clinical practices.
However, a comprehensive evaluation of this task is lacking due to the absence
of a public benchmark. In this paper, we propose the development and release of
a novel benchmark for evaluating entity retrieval in EHRs, with a particular
focus on the semantic gap issue. Using discharge summaries from the MIMIC-III
dataset, we incorporate ICD codes and prescription labels associated with the
notes as queries, and annotate relevance judgments using GPT-4. In total, we
use 1,000 patient notes, generate 1,246 queries, and provide over 77,000
relevance annotations. To offer the first assessment of the semantic gap, we
introduce a novel classification system for relevance matches. Leveraging
GPT-4, we categorize each relevant pair into one of five categories: string,
synonym, abbreviation, hyponym, and implication. Using the proposed benchmark,
we evaluate several retrieval methods, including BM25, query expansion, and
state-of-the-art dense retrievers. Our findings show that BM25 provides a
strong baseline but struggles with semantic matches. Query expansion
significantly improves performance, though it slightly reduces string match
capabilities. Dense retrievers outperform traditional methods, particularly for
semantic matches, and general-domain dense retrievers often surpass those
trained specifically in the biomedical domain.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Under review, and the dataset will be made public upon reception of
  our paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and
  Cup Segmentation in Fundus Images 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06220v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06220v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jinchen Yu, Yongwei Nie, Fei Qi, Wenxiong Liao, Hongmin Cai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The Segment Anything Model (SAM) has gained popularity as a versatile image
segmentation method, thanks to its strong generalization capabilities across
various domains. However, when applied to optic disc (OD) and optic cup (OC)
segmentation tasks, SAM encounters challenges due to the complex structures,
low contrast, and blurred boundaries typical of fundus images, leading to
suboptimal performance. To overcome these challenges, we introduce a novel
model, FunduSAM, which incorporates several Adapters into SAM to create a deep
network specifically designed for OD and OC segmentation. The FunduSAM utilizes
Adapter into each transformer block after encoder for parameter fine-tuning
(PEFT). It enhances SAM's feature extraction capabilities by designing a
Convolutional Block Attention Module (CBAM), addressing issues related to
blurred boundaries and low contrast. Given the unique requirements of OD and OC
segmentation, polar transformation is used to convert the original fundus OD
images into a format better suited for training and evaluating FunduSAM. A
joint loss is used to achieve structure preservation between the OD and OC,
while accurate segmentation. Extensive experiments on the REFUGE dataset,
comprising 1,200 fundus images, demonstrate the superior performance of
FunduSAM compared to five mainstream approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Optimizing Knowledge Integration in Retrieval-Augmented Generation with
  Self-Selection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06148v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06148v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yan Weng, Fengbin Zhu, Tong Ye, Haoyan Liu, Fuli Feng, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG), which integrates external knowledge
into Large Language Models (LLMs), has proven effective in enabling LLMs to
produce more accurate and reliable responses. However, it remains a significant
challenge how to effectively integrate external retrieved knowledge with
internal parametric knowledge in LLMs. In this work, we propose a novel
Self-Selection RAG framework, where the LLM is made to select from pairwise
responses generated with internal parametric knowledge solely and with external
retrieved knowledge together to achieve enhanced accuracy. To this end, we
devise a Self-Selection-RGP method to enhance the capabilities of the LLM in
both generating and selecting the correct answer, by training the LLM with
Direct Preference Optimization (DPO) over a curated Retrieval Generation
Preference (RGP) dataset. Experimental results with two open-source LLMs (i.e.,
Llama2-13B-Chat and Mistral-7B) well demonstrate the superiority of our
approach over other baseline methods on Natural Questions (NQ) and TrivialQA
datasets.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>12 pages, 6 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Bridging Conversational and Collaborative Signals for Conversational
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.06949v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.06949v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ahmad Bin Rabiah, Nafis Sadeq, Julian McAuley
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Conversational recommendation systems (CRS) leverage contextual information
from conversations to generate recommendations but often struggle due to a lack
of collaborative filtering (CF) signals, which capture user-item interaction
patterns essential for accurate recommendations. We introduce Reddit-ML32M, a
dataset that links Reddit conversations with interactions on MovieLens 32M, to
enrich item representations by leveraging collaborative knowledge and
addressing interaction sparsity in conversational datasets. We propose an
LLM-based framework that uses Reddit-ML32M to align LLM-generated
recommendations with CF embeddings, refining rankings for better performance.
We evaluate our framework against three sets of baselines: CF-based
recommenders using only interactions from CRS tasks, traditional CRS models,
and LLM-based methods relying on conversational context without item
representations. Our approach achieves consistent improvements, including a
12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the
best-performing baseline that relies on conversational context but lacks
collaborative item representations.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MARM: Unlocking the Future of Recommendation Systems through Memory
  Augmentation and Scalable Complexity 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.09425v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.09425v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xiao Lv, Jiangxia Cao, Shijie Guan, Xiaoyou Zhou, Zhiguang Qi, Yaqiang Zang, Ming Li, Ben Wang, Kun Gai, Guorui Zhou
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Scaling-law has guided the language model designing for past years, however,
it is worth noting that the scaling laws of NLP cannot be directly applied to
RecSys due to the following reasons: (1) The amount of training samples and
model parameters is typically not the bottleneck for the model. Our
recommendation system can generate over 50 billion user samples daily, and such
a massive amount of training data can easily allow our model parameters to
exceed 200 billion, surpassing many LLMs (about 100B). (2) To ensure the
stability and robustness of the recommendation system, it is essential to
control computational complexity FLOPs carefully. Considering the above
differences with LLM, we can draw a conclusion that: for a RecSys model,
compared to model parameters, the computational complexity FLOPs is a more
expensive factor that requires careful control. In this paper, we propose our
milestone work, MARM (Memory Augmented Recommendation Model), which explores a
new cache scaling-laws successfully.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LLM-based SPARQL Query Generation from Natural Language over Federated
  Knowledge Graphs 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.06062v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.06062v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce a Retrieval-Augmented Generation (RAG) system for translating
user questions into accurate federated SPARQL queries over bioinformatics
knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance
accuracy and reduce hallucinations in query generation, our system utilises
metadata from the KGs, including query examples and schema information, and
incorporates a validation step to correct generated queries. The system is
available online at chat.expasy.org.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential
  Recommendation <span class="chip">WSDM'25</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.01457v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.01457v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingrui Liu, Sixiao Zhang, Cheng Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sequential recommendation (SR) systems excel at capturing users' dynamic
preferences by leveraging their interaction histories. Most existing SR systems
assign a single embedding vector to each item to represent its features, and
various types of models are adopted to combine these item embeddings into a
sequence representation vector to capture the user intent. However, we argue
that this representation alone is insufficient to capture an item's
multi-faceted nature (e.g., movie genres, starring actors). Besides, users
often exhibit complex and varied preferences within these facets (e.g., liking
both action and musical films in the facet of genre), which are challenging to
fully represent. To address the issues above, we propose a novel structure
called Facet-Aware Multi-Head Mixture-of-Experts Model for Sequential
Recommendation (FAME). We leverage sub-embeddings from each head in the last
multi-head attention layer to predict the next item separately. This approach
captures the potential multi-faceted nature of items without increasing model
complexity. A gating mechanism integrates recommendations from each head and
dynamically determines their importance. Furthermore, we introduce a
Mixture-of-Experts (MoE) network in each attention head to disentangle various
user preferences within each facet. Each expert within the MoE focuses on a
specific preference. A learnable router network is adopted to compute the
importance weight for each expert and aggregate them. We conduct extensive
experiments on four public sequential recommendation datasets and the results
demonstrate the effectiveness of our method over existing baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper has been accepted by WSDM'25</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Identity-Aware Cross-Modal Retrieval: a <span class="highlight-title">Dataset</span> and a Baseline <span class="chip">ECIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.21009v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.21009v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Messina, Lucia Vadicamo, Leo Maltese, Claudio Gennaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in deep learning have significantly enhanced
content-based retrieval methods, notably through models like CLIP that map
images and texts into a shared embedding space. However, these methods often
struggle with domain-specific entities and long-tail concepts absent from their
training data, particularly in identifying specific individuals. In this paper,
we explore the task of identity-aware cross-modal retrieval, which aims to
retrieve images of persons in specific contexts based on natural language
queries. This task is critical in various scenarios, such as for searching and
browsing personalized video collections or large audio-visual archives
maintained by national broadcasters. We introduce a novel dataset, COCO Person
FaceSwap (COCO-PFS), derived from the widely used COCO dataset and enriched
with deepfake-generated faces from VGGFace2. This dataset addresses the lack of
large-scale datasets needed for training and evaluating models for this task.
Our experiments assess the performance of different CLIP variations repurposed
for this task, including our architecture, Identity-aware CLIP (Id-CLIP), which
achieves competitive retrieval performance through targeted fine-tuning. Our
contributions lay the groundwork for more robust cross-modal retrieval systems
capable of recognizing long-tail identities and contextual nuances. Data and
code are available at https://github.com/mesnico/IdCLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as full paper at ECIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LemmaHead: RAG Assisted Proof Generation Using Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.15797v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.15797v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Tianbo Yang, Mingqi Yan, Hongyi Zhao, Tianshuo Yang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Developing the logic necessary to solve mathematical problems or write
mathematical proofs is one of the more difficult objectives for large language
models (LLMS). Currently, the most popular methods in literature consists of
fine-tuning the model on written mathematical content such as academic
publications and textbooks, so that the model can learn to emulate the style of
mathematical writing. In this project, we explore the effectiveness of using
retrieval augmented generation (RAG) to address gaps in the mathematical
reasoning of LLMs. We develop LemmaHead, a RAG knowledge base that supplements
queries to the model with relevant mathematical context, with particular focus
on context from published textbooks. To measure our model's performance in
mathematical reasoning, our testing paradigm focuses on the task of automated
theorem proving via generating proofs to a given mathematical claim in the Lean
formal language.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Epidemiology-informed Network for Robust Rumor Detection 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.12949v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.12949v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Wei Jiang, Tong Chen, Xinyi Gao, Wentao Zhang, Lizhen Cui, Hongzhi Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid spread of rumors on social media has posed significant challenges
to maintaining public trust and information integrity. Since an information
cascade process is essentially a propagation tree, recent rumor detection
models leverage graph neural networks to additionally capture information
propagation patterns, thus outperforming text-only solutions. Given the
variations in topics and social impact of the root node, different source
information naturally has distinct outreach capabilities, resulting in
different heights of propagation trees. This variation, however, impedes the
data-driven design of existing graph-based rumor detectors. Given a shallow
propagation tree with limited interactions, it is unlikely for graph-based
approaches to capture sufficient cascading patterns, questioning their ability
to handle less popular news or early detection needs. In contrast, a deep
propagation tree is prone to noisy user responses, and this can in turn
obfuscate the predictions. In this paper, we propose a novel
Epidemiology-informed Network (EIN) that integrates epidemiological knowledge
to enhance performance by overcoming data-driven methods sensitivity to data
quality. Meanwhile, to adapt epidemiology theory to rumor detection, it is
expected that each users stance toward the source information will be
annotated. To bypass the costly and time-consuming human labeling process, we
take advantage of large language models to generate stance labels, facilitating
optimization objectives for learning epidemiology-informed representations. Our
experimental results demonstrate that the proposed EIN not only outperforms
state-of-the-art methods on real-world datasets but also exhibits enhanced
robustness across varying tree depths.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">7</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cardiverse: Harnessing LLMs for Novel Card Game Prototyping 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.07128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.07128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Danrui Li, Sen Zhang, Sam S. Sohn, Kaidong Hu, Muhammad Usman, Mubbasir Kapadia
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The prototyping of computer games, particularly card games, requires
extensive human effort in creative ideation and gameplay evaluation. Recent
advances in Large Language Models (LLMs) offer opportunities to automate and
streamline these processes. However, it remains challenging for LLMs to design
novel game mechanics beyond existing databases, generate consistent gameplay
environments, and develop scalable gameplay AI for large-scale evaluations.
This paper addresses these challenges by introducing a comprehensive automated
card game prototyping framework. The approach highlights a graph-based indexing
method for generating novel game designs, an LLM-driven system for consistent
game code generation validated by gameplay records, and a gameplay AI
constructing method that uses an ensemble of LLM-generated action-value
functions optimized through self-play. These contributions aim to accelerate
card game prototyping, reduce human labor, and lower barriers to entry for game
developers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>13 pages, 7 figures, 3 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Learning Musical Representations for Music Performance Question
  Answering <span class="chip">EMNLP 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06710v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06710v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Diao, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Music performances are representative scenarios for audio-visual modeling.
Unlike common scenarios with sparse audio, music performances continuously
involve dense audio signals throughout. While existing multimodal learning
methods on the audio-video QA demonstrate impressive capabilities in general
scenarios, they are incapable of dealing with fundamental problems within the
music performances: they underexplore the interaction between the multimodal
signals in performance and fail to consider the distinctive characteristics of
instruments and music. Therefore, existing methods tend to answer questions
regarding musical performances inaccurately. To bridge the above research gaps,
(i) given the intricate multimodal interconnectivity inherent to music data,
our primary backbone is designed to incorporate multimodal interactions within
the context of music; (ii) to enable the model to learn music characteristics,
we annotate and release rhythmic and music sources in the current music
datasets; (iii) for time-aware audio-visual modeling, we align the model's
music predictions with the temporal dimension. Our experiments show
state-of-the-art effects on the Music AVQA datasets. Our code is available at
https://github.com/xid32/Amuse.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EMNLP 2024</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ From Code to Canvas 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06616v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06616v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bernhard O. Werner
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The web-based dynamic geometry software CindyJS is a versatile tool to create
interactive applications for mathematics and other topics. In this workshop, we
will look at a code package that makes the creation of animations in CindyJS
easier and more streamlined. Animations, which can then be embedded into
presentations or be used in (lecture) videos. The focus lies on the creation of
the animations themselves and some of the technical and artistic fundamentals
to do so.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>A workshop paper for the Bridges 2025 conference</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Recent Advances in Discrete Speech Tokens: A <span class="highlight-title">Review</span> 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06490v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06490v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiwei Guo, Zhihan Li, Hankun Wang, Bohan Li, Chongtian Shao, Hanglei Zhang, Chenpeng Du, Xie Chen, Shujie Liu, Kai Yu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rapid advancement of speech generation technologies in the era of large
language models (LLMs) has established discrete speech tokens as a foundational
paradigm for speech representation. These tokens, characterized by their
discrete, compact, and concise nature, are not only advantageous for efficient
transmission and storage, but also inherently compatible with the language
modeling framework, enabling seamless integration of speech into text-dominated
LLM architectures. Current research categorizes discrete speech tokens into two
principal classes: acoustic tokens and semantic tokens, each of which has
evolved into a rich research domain characterized by unique design philosophies
and methodological approaches. This survey systematically synthesizes the
existing taxonomy and recent innovations in discrete speech tokenization,
conducts a critical examination of the strengths and limitations of each
paradigm, and presents systematic experimental comparisons across token types.
Furthermore, we identify persistent challenges in the field and propose
potential research directions, aiming to offer actionable insights to inspire
future advancements in the development and application of discrete speech
tokens.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages, 8 figures, 3 tables. Work in progress</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LapisGS: Layered Progressive 3D Gaussian Splatting for Adaptive
  Streaming <span class="chip">3DV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.14823v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.14823v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuang Shi, Géraldine Morin, Simone Gasparini, Wei Tsang Ooi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The rise of Extended Reality (XR) requires efficient streaming of 3D online
worlds, challenging current 3DGS representations to adapt to
bandwidth-constrained environments. This paper proposes LapisGS, a layered 3DGS
that supports adaptive streaming and progressive rendering. Our method
constructs a layered structure for cumulative representation, incorporates
dynamic opacity optimization to maintain visual fidelity, and utilizes
occupancy maps to efficiently manage Gaussian splats. This proposed model
offers a progressive representation supporting a continuous rendering quality
adapted for bandwidth-aware streaming. Extensive experiments validate the
effectiveness of our approach in balancing visual fidelity with the compactness
of the model, with up to 50.71% improvement in SSIM, 286.53% improvement in
LPIPS with 23% of the original model size, and shows its potential for
bandwidth-adapted 3D streaming and rendering applications.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>3DV 2025; Project Page: https://yuang-ian.github.io/lapisgs/ ; Code:
  https://github.com/nus-vv-streams/lapis-gs</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Towards Identity-Aware Cross-Modal Retrieval: a <span class="highlight-title">Dataset</span> and a Baseline <span class="chip">ECIR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.21009v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.21009v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Nicola Messina, Lucia Vadicamo, Leo Maltese, Claudio Gennaro
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in deep learning have significantly enhanced
content-based retrieval methods, notably through models like CLIP that map
images and texts into a shared embedding space. However, these methods often
struggle with domain-specific entities and long-tail concepts absent from their
training data, particularly in identifying specific individuals. In this paper,
we explore the task of identity-aware cross-modal retrieval, which aims to
retrieve images of persons in specific contexts based on natural language
queries. This task is critical in various scenarios, such as for searching and
browsing personalized video collections or large audio-visual archives
maintained by national broadcasters. We introduce a novel dataset, COCO Person
FaceSwap (COCO-PFS), derived from the widely used COCO dataset and enriched
with deepfake-generated faces from VGGFace2. This dataset addresses the lack of
large-scale datasets needed for training and evaluating models for this task.
Our experiments assess the performance of different CLIP variations repurposed
for this task, including our architecture, Identity-aware CLIP (Id-CLIP), which
achieves competitive retrieval performance through targeted fine-tuning. Our
contributions lay the groundwork for more robust cross-modal retrieval systems
capable of recognizing long-tail identities and contextual nuances. Data and
code are available at https://github.com/mesnico/IdCLIP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted as full paper at ECIR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Progressive Confident Masking Attention Network for Audio-Visual
  Segmentation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.02345v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.02345v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yuxuan Wang, Jinchao Zhu, Feng Dong, Shuyue Zhu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audio and visual signals typically occur simultaneously, and humans possess
an innate ability to correlate and synchronize information from these two
modalities. Recently, a challenging problem known as Audio-Visual Segmentation
(AVS) has emerged, intending to produce segmentation maps for sounding objects
within a scene. However, the methods proposed so far have not sufficiently
integrated audio and visual information, and the computational costs have been
extremely high. Additionally, the outputs of different stages have not been
fully utilized. To facilitate this research, we introduce a novel Progressive
Confident Masking Attention Network (PMCANet). It leverages attention
mechanisms to uncover the intrinsic correlations between audio signals and
visual frames. Furthermore, we design an efficient and effective
cross-attention module to enhance semantic perception by selecting query
tokens. This selection is determined through confidence-driven units based on
the network's multi-stage predictive outputs. Experiments demonstrate that our
network outperforms other AVS methods while requiring less computational
resources. The code is available at: https://github.com/PrettyPlate/PCMANet.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>23 pages, 11 figures, submitted to Elsevier Knowledge-Based System</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-09T00:00:00Z">2025-02-09</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">13</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Benchmarking <span class="highlight-title">Prompt</span> Sensitivity in Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06065v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06065v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Amirhossein Razavi, Mina Soltangheis, Negar Arabzadeh, Sara Salamat, Morteza Zihayat, Ebrahim Bagheri
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language Models (LLMs) are highly sensitive to variations in prompt
formulation, which can significantly impact their ability to generate accurate
responses. In this paper, we introduce a new task, Prompt Sensitivity
Prediction, and a dataset PromptSET designed to investigate the effects of
slight prompt variations on LLM performance. Using TriviaQA and HotpotQA
datasets as the foundation of our work, we generate prompt variations and
evaluate their effectiveness across multiple LLMs. We benchmark the prompt
sensitivity prediction task employing state-of-the-art methods from related
tasks, including LLM-based self-evaluation, text classification, and query
performance prediction techniques. Our findings reveal that existing methods
struggle to effectively address prompt sensitivity prediction, underscoring the
need to understand how information needs should be phrased for accurate LLM
responses.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FactIR: A Real-World Zero-shot Open-Domain Retrieval Benchmark for
  Fact-Checking <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06006v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06006v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Venktesh V, Vinay Setty
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The field of automated fact-checking increasingly depends on retrieving
web-based evidence to determine the veracity of claims in real-world scenarios.
A significant challenge in this process is not only retrieving relevant
information, but also identifying evidence that can both support and refute
complex claims. Traditional retrieval methods may return documents that
directly address claims or lean toward supporting them, but often struggle with
more complex claims requiring indirect reasoning. While some existing
benchmarks and methods target retrieval for fact-checking, a comprehensive
real-world open-domain benchmark has been lacking. In this paper, we present a
real-world retrieval benchmark FactIR, derived from Factiverse production logs,
enhanced with human annotations. We rigorously evaluate state-of-the-art
retrieval models in a zero-shot setup on FactIR and offer insights for
developing practical retrieval systems for fact-checking. Code and data are
available at https://github.com/factiverse/factIR.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to WWW 2025 resource track</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Multi-Branch Collaborative Learning Network for Video Quality Assessment
  in Industrial Video Search <span class="chip">KDD 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05924v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05924v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hengzhu Tang, Zefeng Zhang, Zhiping Li, Zhenyu Zhang, Xing Wu, Li Gao, Suqi Cheng, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Video Quality Assessment (VQA) is vital for large-scale video retrieval
systems, aimed at identifying quality issues to prioritize high-quality videos.
In industrial systems, low-quality video characteristics fall into four
categories: visual-related issues like mosaics and black boxes, textual issues
from video titles and OCR content, and semantic issues like frame incoherence
and frame-text mismatch from AI-generated videos. Despite their prevalence in
industrial settings, these low-quality videos have been largely overlooked in
academic research, posing a challenge for accurate identification. To address
this, we introduce the Multi-Branch Collaborative Network (MBCN) tailored for
industrial video retrieval systems. MBCN features four branches, each designed
to tackle one of the aforementioned quality issues. After each branch
independently scores videos, we aggregate these scores using a weighted
approach and a squeeze-and-excitation mechanism to dynamically address quality
issues across different scenarios. We implement point-wise and pair-wise
optimization objectives to ensure score stability and reasonableness. Extensive
offline and online experiments on a world-level video search engine demonstrate
MBCN's effectiveness in identifying video quality issues, significantly
enhancing the retrieval system's ranking performance. Detailed experimental
analyses confirm the positive contribution of all four evaluation branches.
Furthermore, MBCN significantly improves recognition accuracy for low-quality
AI-generated videos compared to the baseline.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>KDD 2025 ADS</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05863v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05863v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhao Jia, Xinyi Wu, Hao Li, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In AI-facilitated teaching, leveraging various query styles to interpret
abstract text descriptions is crucial for ensuring high-quality teaching.
However, current retrieval models primarily focus on natural text-image
retrieval, making them insufficiently tailored to educational scenarios due to
the ambiguities in the retrieval process. In this paper, we propose a diverse
expression retrieval task tailored to educational scenarios, supporting
retrieval based on multiple query styles and expressions. We introduce the STEM
Education Retrieval Dataset (SER), which contains over 24,000 query pairs of
different styles, and the Uni-Retrieval, an efficient and style-diversified
retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts
query style features as prototypes and builds a continuously updated Prompt
Bank containing prompt tokens for diverse queries. This bank can updated during
test time to represent domain-specific knowledge for different subject
retrieval scenarios. Our framework demonstrates scalability and robustness by
dynamically retrieving prompt tokens based on prototype similarity, effectively
facilitating learning for unknown queries. Experimental results indicate that
Uni-Retrieval outperforms existing retrieval models in most retrieval tasks.
This advancement provides a scalable and precise solution for diverse
educational needs.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LegalSeg: Unlocking the Structure of Indian Legal Judgments Through
  Rhetorical Role Classification <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05836v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05836v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shubham Kumar Nigam, Tanmay Dubey, Govind Sharma, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In this paper, we address the task of semantic segmentation of legal
documents through rhetorical role classification, with a focus on Indian legal
judgments. We introduce LegalSeg, the largest annotated dataset for this task,
comprising over 7,000 documents and 1.4 million sentences, labeled with 7
rhetorical roles. To benchmark performance, we evaluate multiple
state-of-the-art models, including Hierarchical BiLSTM-CRF,
TransformerOverInLegalBERT (ToInLegalBERT), Graph Neural Networks (GNNs), and
Role-Aware Transformers, alongside an exploratory RhetoricLLaMA, an
instruction-tuned large language model. Our results demonstrate that models
incorporating broader context, structural relationships, and sequential
sentence information outperform those relying solely on sentence-level
features. Additionally, we conducted experiments using surrounding context and
predicted or actual labels of neighboring sentences to assess their impact on
classification accuracy. Despite these advancements, challenges persist in
distinguishing between closely related roles and addressing class imbalance.
Our work underscores the potential of advanced techniques for improving legal
document understanding and sets a strong foundation for future research in
legal NLP.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted on NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ HCMRM: A High-Consistency Multimodal Relevance Model for Search Ads <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05822v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05822v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Guobing Gan, Kaiming Gao, Li Wang, Shen Jiang, Peng Jiang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search advertising is essential for merchants to reach the target users on
short video platforms. Short video ads aligned with user search intents are
displayed through relevance matching and bid ranking mechanisms. This paper
focuses on improving query-to-video relevance matching to enhance the
effectiveness of ranking in ad systems. Recent vision-language pre-training
models have demonstrated promise in various multimodal tasks. However, their
contribution to downstream query-video relevance tasks is limited, as the
alignment between the pair of visual signals and text differs from the modeling
of the triplet of the query, visual signals, and video text. In addition, our
previous relevance model provides limited ranking capabilities, largely due to
the discrepancy between the binary cross-entropy fine-tuning objective and the
ranking objective. To address these limitations, we design a high-consistency
multimodal relevance model (HCMRM). It utilizes a simple yet effective method
to enhance the consistency between pre-training and relevance tasks.
Specifically, during the pre-training phase, along with aligning visual signals
and video text, several keywords are extracted from the video text as
pseudo-queries to perform the triplet relevance modeling. For the fine-tuning
phase, we introduce a hierarchical softmax loss, which enables the model to
learn the order within labels while maximizing the distinction between positive
and negative samples. This promotes the fusion ranking of relevance and bidding
in the subsequent ranking stage. The proposed method has been deployed in the
Kuaishou search advertising system for over a year, contributing to a 6.1%
reduction in the proportion of irrelevant ads and a 1.4% increase in ad
revenue.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2025 (Industry Track)</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ FlashCheck: Exploration of Efficient Evidence Retrieval for Fast
  Fact-Checking <span class="chip">ECIR 2024</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05803v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05803v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kevin Nanekhan, Venktesh V, Erik Martin, Henrik Vatndal, Vinay Setty, Avishek Anand
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The advances in digital tools have led to the rampant spread of
misinformation. While fact-checking aims to combat this, manual fact-checking
is cumbersome and not scalable. It is essential for automated fact-checking to
be efficient for aiding in combating misinformation in real-time and at the
source. Fact-checking pipelines primarily comprise a knowledge retrieval
component which extracts relevant knowledge to fact-check a claim from large
knowledge sources like Wikipedia and a verification component. The existing
works primarily focus on the fact-verification part rather than evidence
retrieval from large data collections, which often face scalability issues for
practical applications such as live fact-checking. In this study, we address
this gap by exploring various methods for indexing a succinct set of factual
statements from large collections like Wikipedia to enhance the retrieval phase
of the fact-checking pipeline. We also explore the impact of vector
quantization to further improve the efficiency of pipelines that employ dense
retrieval approaches for first-stage retrieval. We study the efficiency and
effectiveness of the approaches on fact-checking datasets such as HoVer and
WiCE, leveraging Wikipedia as the knowledge source. We also evaluate the
real-world utility of the efficient retrieval approaches by fact-checking 2024
presidential debate and also open source the collection of claims with
corresponding labels identified in the debate. Through a combination of indexed
facts together with Dense retrieval and Index compression, we achieve up to a
10.0x speedup on CPUs and more than a 20.0x speedup on GPUs compared to the
classical fact-checking pipelines over large collections.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ECIR 2024, 15 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ LOCALINTEL: Generating Organizational Threat Intelligence from Global
  and Local Cyber Knowledge 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2401.10036v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2401.10036v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Shaswata Mitra, Subash Neupane, Trisha Chakraborty, Sudip Mittal, Aritran Piplai, Manas Gaur, Shahram Rahimi
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Security Operations Center (SoC) analysts gather threat reports from openly
accessible global threat repositories and tailor the information to their
organization's needs, such as developing threat intelligence and security
policies. They also depend on organizational internal repositories, which act
as private local knowledge database. These local knowledge databases store
credible cyber intelligence, critical operational and infrastructure details.
SoCs undertake a manual labor-intensive task of utilizing these global threat
repositories and local knowledge databases to create both organization-specific
threat intelligence and mitigation policies. Recently, Large Language Models
(LLMs) have shown the capability to process diverse knowledge sources
efficiently. We leverage this ability to automate this organization-specific
threat intelligence generation. We present LocalIntel, a novel automated threat
intelligence contextualization framework that retrieves zero-day vulnerability
reports from the global threat repositories and uses its local knowledge
database to determine implications and mitigation strategies to alert and
assist the SoC analyst. LocalIntel comprises two key phases: knowledge
retrieval and contextualization. Quantitative and qualitative assessment has
shown effectiveness in generating up to 93% accurate organizational threat
intelligence with 64% inter-rater agreement.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Orbit: A Framework for Designing and Evaluating Multi-objective Rankers 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.04798v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.04798v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chenyang Yang, Tesi Xiao, Michael Shavlovsky, Christian Kästner, Tongshuang Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Machine learning in production needs to balance multiple objectives: This is
particularly evident in ranking or recommendation models, where conflicting
objectives such as user engagement, satisfaction, diversity, and novelty must
be considered at the same time. However, designing multi-objective rankers is
inherently a dynamic wicked problem -- there is no single optimal solution, and
the needs evolve over time. Effective design requires collaboration between
cross-functional teams and careful analysis of a wide range of information. In
this work, we introduce Orbit, a conceptual framework for Objective-centric
Ranker Building and Iteration. The framework places objectives at the center of
the design process, to serve as boundary objects for communication and guide
practitioners for design and evaluation. We implement Orbit as an interactive
system, which enables stakeholders to interact with objective spaces directly
and supports real-time exploration and evaluation of design trade-offs. We
evaluate Orbit through a user study involving twelve industry practitioners,
showing that it supports efficient design space exploration, leads to more
informed decision-making, and enhances awareness of the inherent trade-offs of
multiple objectives. Orbit (1) opens up new opportunities of an
objective-centric design process for any multi-objective ML models, as well as
(2) sheds light on future designs that push practitioners to go beyond a narrow
metric-centric or example-centric mindset.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TF-DCon: Leveraging Large Language Models (LLMs) to Empower
  Training-Free <span class="highlight-title">Dataset</span> Condensation for Content-Based Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2310.09874v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2310.09874v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiahao Wu, Qijiong Liu, Hengchang Hu, Wenqi Fan, Shengcai Liu, Qing Li, Xiao-Ming Wu, Ke Tang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Modern techniques in Content-based Recommendation (CBR) leverage item content
information to provide personalized services to users, but suffer from
resource-intensive training on large datasets. To address this issue, we
explore the dataset condensation for textual CBR in this paper. The goal of
dataset condensation is to synthesize a small yet informative dataset, upon
which models can achieve performance comparable to those trained on large
datasets. While existing condensation approaches are tailored to classification
tasks for continuous data like images or embeddings, direct application of them
to CBR has limitations. To bridge this gap, we investigate efficient dataset
condensation for content-based recommendation. Inspired by the remarkable
abilities of large language models (LLMs) in text comprehension and generation,
we leverage LLMs to empower the generation of textual content during
condensation. To handle the interaction data involving both users and items, we
devise a dual-level condensation method: content-level and user-level. At
content-level, we utilize LLMs to condense all contents of an item into a new
informative title. At user-level, we design a clustering-based synthesis
module, where we first utilize LLMs to extract user interests. Then, the user
interests and user embeddings are incorporated to condense users and generate
interactions for condensed users. Notably, the condensation paradigm of this
method is forward and free from iterative optimization on the synthesized
dataset. Extensive empirical findings from our study, conducted on three
authentic datasets, substantiate the efficacy of the proposed method.
Particularly, we are able to approximate up to 97% of the original performance
while reducing the dataset size by 95% (i.e., on dataset MIND).
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Full version of TheWebConf'25 accepted paper</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Multimodal semantic retrieval for product search <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.07365v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.07365v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Dong Liu, Esther Lopez Ramos
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Semantic retrieval (also known as dense retrieval) based on textual data has
been extensively studied for both web search and product search application
fields, where the relevance of a query and a potential target document is
computed by their dense vector representation comparison. Product image is
crucial for e-commerce search interactions and is a key factor for customers at
product explorations. However, its impact on semantic retrieval has not been
well studied yet. In this research, we build a multimodal representation for
product items in e-commerce search in contrast to pure-text representation of
products, and investigate the impact of such representations. The models are
developed and evaluated on e-commerce datasets. We demonstrate that a
multimodal representation scheme for a product can show improvement either on
purchase recall or relevance accuracy in semantic retrieval. Additionally, we
provide numerical analysis for exclusive matches retrieved by a multimodal
semantic retrieval model versus a text-only semantic retrieval model, to
demonstrate the validation of multimodal solutions.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at EReL@MIR WWW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Mask-based Membership Inference Attacks for Retrieval-Augmented
  Generation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.20142v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.20142v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mingrui Liu, Sixiao Zhang, Cheng Long
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has been an effective approach to
mitigate hallucinations in large language models (LLMs) by incorporating
up-to-date and domain-specific knowledge. Recently, there has been a trend of
storing up-to-date or copyrighted data in RAG knowledge databases instead of
using it for LLM training. This practice has raised concerns about Membership
Inference Attacks (MIAs), which aim to detect if a specific target document is
stored in the RAG system's knowledge database so as to protect the rights of
data producers. While research has focused on enhancing the trustworthiness of
RAG systems, existing MIAs for RAG systems remain largely insufficient.
Previous work either relies solely on the RAG system's judgment or is easily
influenced by other documents or the LLM's internal knowledge, which is
unreliable and lacks explainability. To address these limitations, we propose a
Mask-Based Membership Inference Attacks (MBA) framework. Our framework first
employs a masking algorithm that effectively masks a certain number of words in
the target document. The masked text is then used to prompt the RAG system, and
the RAG system is required to predict the mask values. If the target document
appears in the knowledge database, the masked text will retrieve the complete
target document as context, allowing for accurate mask prediction. Finally, we
adopt a simple yet effective threshold-based method to infer the membership of
target document by analyzing the accuracy of mask prediction. Our mask-based
approach is more document-specific, making the RAG system's generation less
susceptible to distractions from other documents or the LLM's internal
knowledge. Extensive experiments demonstrate the effectiveness of our approach
compared to existing baseline models.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This paper is accepted by conference WWW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ AgentMove: A Large Language Model based Agentic Framework for Zero-shot
  Next Location Prediction <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.13986v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.13986v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jie Feng, Yuwei Du, Jie Zhao, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Next location prediction plays a crucial role in various real-world
applications. Recently, due to the limitation of existing deep learning
methods, attempts have been made to apply large language models (LLMs) to
zero-shot next location prediction task. However, they directly generate the
final output using LLMs without systematic design, which limits the potential
of LLMs to uncover complex mobility patterns and underestimates their extensive
reserve of global geospatial knowledge. In this paper, we introduce AgentMove,
a systematic agentic prediction framework to achieve generalized next location
prediction. In AgentMove, we first decompose the mobility prediction task and
design specific modules to complete them, including spatial-temporal memory for
individual mobility pattern mining, world knowledge generator for modeling the
effects of urban structure and collective knowledge extractor for capturing the
shared patterns among population. Finally, we combine the results of three
modules and conduct a reasoning step to generate the final predictions.
Extensive experiments utilizing mobility data from two distinct sources reveal
that AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of
12 metrics and it shows robust predictions with various LLMs as base and also
less geographical bias across cities. Our codes are available via
https://github.com/tsinghua-fib-lab/AgentMove.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by NAACL 2025 as main conference paper,
  https://github.com/tsinghua-fib-lab/AgentMove</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Temporal Working Memory: Query-Guided Segment Refinement for Enhanced
  Multimodal Understanding <span class="chip">NAACL 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06020v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06020v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xingjian Diao, Chunhui Zhang, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal foundation models (MFMs) have demonstrated significant success in
tasks such as visual captioning, question answering, and image-text retrieval.
However, these models face inherent limitations due to their finite internal
capacity, which restricts their ability to process extended temporal sequences,
a crucial requirement for comprehensive video and audio analysis. To overcome
these challenges, we introduce a specialized cognitive module, temporal working
memory (TWM), which aims to enhance the temporal modeling capabilities of MFMs.
It selectively retains task-relevant information across temporal dimensions,
ensuring that critical details are preserved throughout the processing of video
and audio content. The TWM uses a query-guided attention approach to focus on
the most informative multimodal segments within temporal sequences. By
retaining only the most relevant content, TWM optimizes the use of the model's
limited capacity, enhancing its temporal modeling ability. This plug-and-play
module can be easily integrated into existing MFMs. With our TWM, nine
state-of-the-art models exhibit significant performance improvements across
tasks such as video captioning, question answering, and video-text retrieval.
By enhancing temporal modeling, TWM extends the capability of MFMs to handle
complex, time-sensitive data effectively. Our code is available at
https://github.com/xid32/NAACL_2025_TWM.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at NAACL 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Speaker Embedding Informed Audiovisual Active Speaker Detection for
  Egocentric Recordings <span class="chip">ICASSP 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06012v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06012v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jason Clarke, Yoshihiko Gotoh, Stefan Goetze
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Audiovisual active speaker detection (ASD) addresses the task of determining
the speech activity of a candidate speaker given acoustic and visual data.
Typically, systems model the temporal correspondence of audiovisual cues, such
as the synchronisation between speech and lip movement. Recent work has
explored extending this paradigm by additionally leveraging speaker embeddings
extracted from candidate speaker reference speech. This paper proposes the
speaker comparison auxiliary network (SCAN) which uses speaker-specific
information from both reference speech and the candidate audio signal to
disambiguate challenging scenes when the visual signal is unresolvable.
Furthermore, an improved method for enrolling face-speaker libraries is
developed, which implements a self-supervised approach to video-based face
recognition. Fitting with the recent proliferation of wearable devices, this
work focuses on improving speaker-embedding-informed ASD in the context of
egocentric recordings, which can be characterised by acoustic noise and highly
dynamic scenes. SCAN is implemented with two well-established baselines, namely
TalkNet and Light-ASD; yielding a relative improvement in mAP of 14.5% and
10.3% on the Ego4D benchmark, respectively.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted to ICASSP 2025. 5 pages, 4 figures. To appear in Proceedings
  of IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP), April 6-11, 2025, Hyderabad, India</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Large-scale <span class="highlight-title">Dataset</span> with Behavior, Attributes, and Content of Mobile
  Short-video Platform 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05922v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05922v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yu Shang, Chen Gao, Nian Li, Yong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Short-video platforms show an increasing impact on people's daily lives
nowadays, with billions of active users spending plenty of time each day. The
interactions between users and online platforms give rise to many scientific
problems across computational social science and artificial intelligence.
However, despite the rapid development of short-video platforms, currently
there are serious shortcomings in existing relevant datasets on three aspects:
inadequate user-video feedback, limited user attributes and lack of video
content. To address these problems, we provide a large-scale dataset with rich
user behavior, attributes and video content from a real mobile short-video
platform. This dataset covers 10,000 voluntary users and 153,561 videos, and we
conduct four-fold technical validations of the dataset. First, we verify the
richness of the behavior and attribute data. Second, we confirm the
representing ability of the content features. Third, we provide benchmarking
results on recommendation algorithms with our dataset. Finally, we explore the
filter bubble phenomenon on the platform using the dataset. We believe the
dataset could support the broad research community, including but not limited
to user modeling, social science, human behavior understanding, etc. The
dataset and code is available at
https://github.com/tsinghua-fib-lab/ShortVideo_dataset.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>4 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A New Hybrid Intelligent Approach for Multimodal Detection of Suspected
  Disinformation on TikTok 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.06893v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.06893v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jared D. T. Guerrero-Sosa, Andres Montoro-Montarroso, Francisco P. Romero, Jesus Serrano-Guerrero, Jose A. Olivas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the context of the rapid dissemination of multimedia content, identifying
disinformation on social media platforms such as TikTok represents a
significant challenge. This study introduces a hybrid framework that combines
the computational power of deep learning with the interpretability of fuzzy
logic to detect suspected disinformation in TikTok videos. The methodology is
comprised of two core components: a multimodal feature analyser that extracts
and evaluates data from text, audio, and video; and a multimodal disinformation
detector based on fuzzy logic. These systems operate in conjunction to evaluate
the suspicion of spreading disinformation, drawing on human behavioural cues
such as body language, speech patterns, and text coherence. Two experiments
were conducted: one focusing on context-specific disinformation and the other
on the scalability of the model across broader topics. For each video
evaluated, high-quality, comprehensive, well-structured reports are generated,
providing a detailed view of the disinformation behaviours.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Uni-Retrieval: A Multi-Style Retrieval Framework for STEM's Education 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05863v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05863v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yanhao Jia, Xinyi Wu, Hao Li, Qinglin Zhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In AI-facilitated teaching, leveraging various query styles to interpret
abstract text descriptions is crucial for ensuring high-quality teaching.
However, current retrieval models primarily focus on natural text-image
retrieval, making them insufficiently tailored to educational scenarios due to
the ambiguities in the retrieval process. In this paper, we propose a diverse
expression retrieval task tailored to educational scenarios, supporting
retrieval based on multiple query styles and expressions. We introduce the STEM
Education Retrieval Dataset (SER), which contains over 24,000 query pairs of
different styles, and the Uni-Retrieval, an efficient and style-diversified
retrieval vision-language model based on prompt tuning. Uni-Retrieval extracts
query style features as prototypes and builds a continuously updated Prompt
Bank containing prompt tokens for diverse queries. This bank can updated during
test time to represent domain-specific knowledge for different subject
retrieval scenarios. Our framework demonstrates scalability and robustness by
dynamically retrieving prompt tokens based on prototype similarity, effectively
facilitating learning for unknown queries. Experimental results indicate that
Uni-Retrieval outperforms existing retrieval models in most retrieval tasks.
This advancement provides a scalable and precise solution for diverse
educational needs.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-08T00:00:00Z">2025-02-08</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">4</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Graph-Based Vector Search: An Experimental Evaluation of the
  State-of-the-Art 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05575v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05575v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ilias Azizi, Karima Echihabi, Themis Palpanas
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Vector data is prevalent across business and scientific applications, and its
popularity is growing with the proliferation of learned embeddings. Vector data
collections often reach billions of vectors with thousands of dimensions, thus,
increasing the complexity of their analysis. Vector search is the backbone of
many critical analytical tasks, and graph-based methods have become the best
choice for analytical tasks that do not require guarantees on the quality of
the answers. We briefly survey in-memory graph-based vector search, outline the
chronology of the different methods and classify them according to five main
design paradigms: seed selection, incremental insertion, neighborhood
propagation, neighborhood diversification, and divide-and-conquer. We conduct
an exhaustive experimental evaluation of twelve state-of-the-art methods on
seven real data collections, with sizes up to 1 billion vectors. We share key
insights about the strengths and limitations of these methods; e.g., the best
approaches are typically based on incremental insertion and neighborhood
diversification, and the choice of the base graph can hurt scalability.
Finally, we discuss open research directions, such as the importance of
devising more sophisticated data-adaptive seed selection and diversification
strategies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TACLR: A Scalable and Efficient Retrieval-based Method for Industrial
  Product Attribute Value Identification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.03835v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.03835v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yindu Su, Huike Zou, Lin Sun, Ting Zhang, Haiyang Yang, Liyu Chen, David Lo, Qingheng Zhang, Shuguang Han, Jufeng Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Product Attribute Value Identification (PAVI) involves identifying attribute
values from product profiles, a key task for improving product search,
recommendations, and business analytics on e-commerce platforms. However,
existing PAVI methods face critical challenges, such as inferring implicit
values, handling out-of-distribution (OOD) values, and producing normalized
outputs. To address these limitations, we introduce Taxonomy-Aware Contrastive
Learning Retrieval (TACLR), the first retrieval-based method for PAVI. TACLR
formulates PAVI as an information retrieval task by encoding product profiles
and candidate values into embeddings and retrieving values based on their
similarity to the item embedding. It leverages contrastive training with
taxonomy-aware hard negative sampling and employs adaptive inference with
dynamic thresholds. TACLR offers three key advantages: (1) it effectively
handles implicit and OOD values while producing normalized outputs; (2) it
scales to thousands of categories, tens of thousands of attributes, and
millions of values; and (3) it supports efficient inference for high-load
industrial scenarios. Extensive experiments on proprietary and public datasets
validate the effectiveness and efficiency of TACLR. Moreover, it has been
successfully deployed in a real-world e-commerce platform, processing millions
of product listings daily while supporting dynamic, large-scale attribute
taxonomies.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ GraphHash: Graph Clustering Enables Parameter Efficiency in Recommender
  Systems <span class="chip">WWW</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.17245v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.17245v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinyi Wu, Donald Loveland, Runjin Chen, Yozen Liu, Xin Chen, Leonardo Neves, Ali Jadbabaie, Clark Mingxuan Ju, Neil Shah, Tong Zhao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Deep recommender systems rely heavily on large embedding tables to handle
high-cardinality categorical features such as user/item identifiers, and face
significant memory constraints at scale. To tackle this challenge, hashing
techniques are often employed to map multiple entities to the same embedding
and thus reduce the size of the embedding tables. Concurrently, graph-based
collaborative signals have emerged as powerful tools in recommender systems,
yet their potential for optimizing embedding table reduction remains
unexplored. This paper introduces GraphHash, the first graph-based approach
that leverages modularity-based bipartite graph clustering on user-item
interaction graphs to reduce embedding table sizes. We demonstrate that the
modularity objective has a theoretical connection to message-passing, which
provides a foundation for our method. By employing fast clustering algorithms,
GraphHash serves as a computationally efficient proxy for message-passing
during preprocessing and a plug-and-play graph-based alternative to traditional
ID hashing. Extensive experiments show that GraphHash substantially outperforms
diverse hashing baselines on both retrieval and click-through-rate prediction
tasks. In particular, GraphHash achieves on average a 101.52% improvement in
recall when reducing the embedding table size by more than 75%, highlighting
the value of graph-based collaborative information for model reduction. Our
code is available at https://github.com/snap-research/GraphHash.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>ACM Web Conference (WWW) 2025, Oral</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Explainable LLM-driven Multi-dimensional Distillation for E-Commerce
  Relevance Learning <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.13045v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.13045v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gang Zhao, Ximing Zhang, Chenji Lu, Hui Zhao, Tianshu Wu, Pengjie Wang, Jian Xu, Bo Zheng
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Effective query-item relevance modeling is pivotal for enhancing user
experience and safeguarding user satisfaction in e-commerce search systems.
Recently, benefiting from the vast inherent knowledge, Large Language Model
(LLM) approach demonstrates strong performance and long-tail generalization
ability compared with previous neural-based specialized relevance learning
methods. Though promising, current LLM-based methods encounter the following
inadequacies in practice: First, the massive parameters and computational
demands make it difficult to be deployed online. Second, distilling LLM models
to online models is a feasible direction, but the LLM relevance modeling is a
black box, and its rich intrinsic knowledge is difficult to extract and apply
online. To improve the interpretability of LLM and boost the performance of
online relevance models via LLM, we propose an Explainable LLM-driven
Multi-dimensional Distillation framework for e-commerce relevance learning,
which comprises two core components: (1) An Explainable LLM for relevance
modeling (ELLM-rele), which decomposes the relevance learning into intermediate
steps and models relevance learning as a Chain-of-Thought (CoT) reasoning,
thereby enhancing both interpretability and performance of LLM. (2) A
Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the
knowledge of ELLM-rele to current deployable interaction-based and
representation-based student models from both the relevance score distribution
and CoT reasoning aspects. Through distilling the probabilistic and CoT
reasoning knowledge, MKD improves both the semantic interaction and long-tail
generalization abilities of student models. Extensive offline evaluations and
online experiments on Taobao search ad scene demonstrate that our proposed
framework significantly enhances e-commerce relevance learning performance and
user experience.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2025 oral</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">3</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models
  for Wireless Networks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05695v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05695v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper proposes a novel framework for real-time adaptive-bitrate video
streaming by integrating latent diffusion models (LDMs) within the FFmpeg
techniques. This solution addresses the challenges of high bandwidth usage,
storage inefficiencies, and quality of experience (QoE) degradation associated
with traditional constant bitrate streaming (CBS) and adaptive bitrate
streaming (ABS). The proposed approach leverages LDMs to compress I-frames into
a latent space, offering significant storage and semantic transmission savings
without sacrificing high visual quality. While it keeps B-frames and P-frames
as adjustment metadata to ensure efficient video reconstruction at the user
side, the proposed framework is complemented with the most state-of-the-art
denoising and video frame interpolation (VFI) techniques. These techniques
mitigate semantic ambiguity and restore temporal coherence between frames, even
in noisy wireless communication environments. Experimental results demonstrate
the proposed method achieves high-quality video streaming with optimized
bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and
resource efficiency. This work opens new possibilities for scalable real-time
video streaming in 5G and future post-5G networks.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submission for possible publication</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ UniForm: A Unified Diffusion <span class="highlight-title">Transformer</span> for Audio-Video Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03897v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03897v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Lei Zhao, Linfeng Feng, Dongxu Ge, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  As a natural multimodal content, audible video delivers an immersive sensory
experience. Consequently, audio-video generation systems have substantial
potential. However, existing diffusion-based studies mainly employ relatively
independent modules for generating each modality, which lack exploration of
shared-weight generative modules. This approach may under-use the intrinsic
correlations between audio and visual modalities, potentially resulting in
sub-optimal generation quality. To address this, we propose UniForm, a unified
diffusion transformer designed to enhance cross-modal consistency. By
concatenating auditory and visual information, UniForm learns to generate audio
and video simultaneously within a unified latent space, facilitating the
creation of high-quality and well-aligned audio-visual pairs. Extensive
experiments demonstrate the superior performance of our method in joint
audio-video generation, audio-guided video generation, and video-guided audio
generation tasks. Our demos are available at https://uniform-t2av.github.io/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Our demos are available at https://uniform-t2av.github.io/</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CAMSIC: Content-aware Masked Image Modeling <span class="highlight-title">Transformer</span> for Stereo Image
  Compression <span class="chip">AAAI 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.08505v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.08505v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xinjie Zhang, Shenyuan Gao, Zhening Liu, Jiawei Shao, Xingtong Ge, Dailan He, Tongda Xu, Yan Wang, Jun Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Existing learning-based stereo image codec adopt sophisticated transformation
with simple entropy models derived from single image codecs to encode latent
representations. However, those entropy models struggle to effectively capture
the spatial-disparity characteristics inherent in stereo images, which leads to
suboptimal rate-distortion results. In this paper, we propose a stereo image
compression framework, named CAMSIC. CAMSIC independently transforms each image
to latent representation and employs a powerful decoder-free Transformer
entropy model to capture both spatial and disparity dependencies, by
introducing a novel content-aware masked image modeling (MIM) technique. Our
content-aware MIM facilitates efficient bidirectional interaction between prior
information and estimated tokens, which naturally obviates the need for an
extra Transformer decoder. Experiments show that our stereo image codec
achieves state-of-the-art rate-distortion performance on two stereo image
datasets Cityscapes and InStereo2K with fast encoding and decoding speed. Code
is available at https://github.com/Xinjie-Q/CAMSIC.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by AAAI 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-07T00:00:00Z">2025-02-07</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">16</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Hypencoder: Hypernetworks for Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05364v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05364v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Julian Killingback, Hansi Zeng, Hamed Zamani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The vast majority of retrieval models depend on vector inner products to
produce a relevance score between a query and a document. This naturally limits
the expressiveness of the relevance score that can be employed. We propose a
new paradigm, instead of producing a vector to represent the query we produce a
small neural network which acts as a learned relevance function. This small
neural network takes in a representation of the document, in this paper we use
a single vector, and produces a scalar relevance score. To produce the little
neural network we use a hypernetwork, a network that produce the weights of
other networks, as our query encoder or as we call it a Hypencoder. Experiments
on in-domain search tasks show that Hypencoder is able to significantly
outperform strong dense retrieval models and has higher metrics then reranking
models and models an order of magnitude larger. Hypencoder is also shown to
generalize well to out-of-domain search tasks. To assess the extent of
Hypencoder's capabilities, we evaluate on a set of hard retrieval tasks
including tip-of-the-tongue retrieval and instruction-following retrieval tasks
and find that the performance gap widens substantially compared to standard
retrieval tasks. Furthermore, to demonstrate the practicality of our method we
implement an approximate search algorithm and show that our model is able to
search 8.8M documents in under 60ms.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ A Tutorial On Intersectionality in Fair Rankings 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05333v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05333v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chiara Criscuolo, Davide Martinenghi, Giuseppe Piccirillo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We address the critical issue of biased algorithms and unfair rankings, which
have permeated various sectors, including search engines, recommendation
systems, and workforce management. These biases can lead to discriminatory
outcomes in a data-driven world, especially against marginalized and
underrepresented groups. Efforts towards responsible data science and
responsible artificial intelligence aim to mitigate these biases and promote
fairness, diversity, and transparency. However, most fairness-aware ranking
methods singularly focus on protected attributes such as race, gender, or
socio-economic status, neglecting the intersectionality of these attributes,
i.e., the interplay between multiple social identities. Understanding
intersectionality is crucial to ensure that existing inequalities are not
preserved by fair rankings. We offer a description of the main ways to
incorporate intersectionality in fair ranking systems through practical
examples and provide a comparative overview of existing literature and a
synoptic table summarizing the various methodologies. Our analysis highlights
the need for intersectionality to attain fairness, while also emphasizing that
fairness, alone, does not necessarily imply intersectionality.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Holistically Guided Monte Carlo Tree Search for Intricate Information
  Seeking 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04751v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04751v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ruiyang Ren, Yuhao Wang, Junyi Li, Jinhao Jiang, Wayne Xin Zhao, Wenjie Wang, Tat-Seng Chua
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of vast digital information, the sheer volume and heterogeneity of
available information present significant challenges for intricate information
seeking. Users frequently face multistep web search tasks that involve
navigating vast and varied data sources. This complexity demands every step
remains comprehensive, accurate, and relevant. However, traditional search
methods often struggle to balance the need for localized precision with the
broader context required for holistic understanding, leaving critical facets of
intricate queries underexplored. In this paper, we introduce an LLM-based
search assistant that adopts a new information seeking paradigm with
holistically guided Monte Carlo tree search (HG-MCTS). We reformulate the task
as a progressive information collection process with a knowledge memory and
unite an adaptive checklist with multi-perspective reward modeling in MCTS. The
adaptive checklist provides explicit sub-goals to guide the MCTS process toward
comprehensive coverage of complex user queries. Simultaneously, our
multi-perspective reward modeling offers both exploration and retrieval
rewards, along with progress feedback that tracks completed and remaining
sub-goals, refining the checklist as the tree search progresses. By striking a
balance between localized tree expansion and global guidance, HG-MCTS reduces
redundancy in search paths and ensures that all crucial aspects of an intricate
query are properly addressed. Extensive experiments on real-world intricate
information seeking tasks demonstrate that HG-MCTS acquires thorough knowledge
collections and delivers more accurate final responses compared with existing
baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Enhancing Health Information Retrieval with RAG by Prioritizing Topical
  Relevance and Factual Accuracy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04666v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04666v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rishabh Uapadhyay, Marco Viviani
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  The exponential surge in online health information, coupled with its
increasing use by non-experts, highlights the pressing need for advanced Health
Information Retrieval models that consider not only topical relevance but also
the factual accuracy of the retrieved information, given the potential risks
associated with health misinformation. To this aim, this paper introduces a
solution driven by Retrieval-Augmented Generation (RAG), which leverages the
capabilities of generative Large Language Models (LLMs) to enhance the
retrieval of health-related documents grounded in scientific evidence. In
particular, we propose a three-stage model: in the first stage, the user's
query is employed to retrieve topically relevant passages with associated
references from a knowledge base constituted by scientific literature. In the
second stage, these passages, alongside the initial query, are processed by
LLMs to generate a contextually relevant rich text (GenText). In the last
stage, the documents to be retrieved are evaluated and ranked both from the
point of view of topical relevance and factual accuracy by means of their
comparison with GenText, either through stance detection or semantic
similarity. In addition to calculating factual accuracy, GenText can offer a
layer of explainability for it, aiding users in understanding the reasoning
behind the retrieval. Experimental evaluation of our model on benchmark
datasets and against baseline models demonstrates its effectiveness in
enhancing the retrieval of both topically relevant and factually accurate
health information, thus presenting a significant step forward in the health
misinformation mitigation problem.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Efficient Knowledge Feeding to Language Models: A Novel Integrated
  Encoder-Decoder Architecture 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05233v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05233v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        S Santosh Kumar, Rishi Gottimukkala, Supriya Devidutta, Karthikeyan S
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  This paper introduces a novel approach to efficiently feeding knowledge to
language models (LLMs) during prediction by integrating retrieval and
generation processes within a unified framework. While the Retrieval-Augmented
Generation (RAG) model addresses gaps in LLMs' training data and knowledge
limits, it is hindered by token limit restrictions and dependency on the
retrieval system's accuracy. Our proposed architecture incorporates in-context
vectors (ICV) to overcome these challenges. ICV recasts in-context learning by
using latent embeddings of LLMs to create a vector that captures essential task
information. This vector is then used to shift the latent states of the LLM,
enhancing the generation process without adding demonstration examples to the
prompt. ICV directly integrates information into the model, enabling it to
process this information more effectively. Our extensive experimental
evaluation demonstrates that ICV outperforms standard in-context learning and
fine-tuning across question-answering, information retrieval, and other tasks.
This approach mitigates the limitations of current RAG models and offers a more
robust solution for handling extensive and diverse datasets. Despite leveraging
a fraction of the parameters, our ICV-enhanced model achieves competitive
performance against models like LLaMA-3, Gemma, and Phi-3, significantly
reducing computational costs and memory requirements. ICV reduces prompt
length, is easy to control, surpasses token limitations, and is computationally
efficient compared to fine-tuning.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Submitted to ACM TIST journal: under revision stage, 8 pages, 2
  figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Cross-Encoder Rediscovers a Semantic Variant of BM25 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04645v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04645v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Meng Lu, Catherine Chen, Carsten Eickhoff
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Neural Ranking Models (NRMs) have rapidly advanced state-of-the-art
performance on information retrieval tasks. In this work, we investigate a
Cross-Encoder variant of MiniLM to determine which relevance features it
computes and where they are stored. We find that it employs a semantic variant
of the traditional BM25 in an interpretable manner, featuring localized
components: (1) Transformer attention heads that compute soft term frequency
while controlling for term saturation and document length effects, and (2) a
low-rank component of its embedding matrix that encodes inverse document
frequency information for the vocabulary. This suggests that the Cross-Encoder
uses the same fundamental mechanisms as BM25, but further leverages their
capacity to capture semantics for improved retrieval performance. The granular
understanding lays the groundwork for model editing to enhance model
transparency, addressing safety concerns, and improving scalability in training
and real-world applications.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ 360Brew: A Decoder-only Foundation Model for Personalized Ranking and
  Recommendation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.16450v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.16450v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Hamed Firooz, Maziar Sanjabi, Adrian Englhardt, Aman Gupta, Ben Levine, Dre Olgiati, Gungor Polatkan, Iuliia Melnychuk, Karthik Ramgopal, Kirill Talanine, Kutta Srinivasan, Luke Simon, Natesh Sivasubramoniapillai, Necip Fazil Ayan, Qingquan Song, Samira Sriram, Souvik Ghosh, Tao Song, Tejas Dharamsi, Vignesh Kothapalli, Xiaoling Zhai, Ya Xu, Yu Wang, Yun Dai
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Ranking and recommendation systems are the foundation for numerous online
experiences, ranging from search results to personalized content delivery.
These systems have evolved into complex, multilayered architectures that
leverage vast datasets and often incorporate thousands of predictive models.
The maintenance and enhancement of these models is a labor intensive process
that requires extensive feature engineering. This approach not only exacerbates
technical debt but also hampers innovation in extending these systems to
emerging problem domains. In this report, we present our research to address
these challenges by utilizing a large foundation model with a textual interface
for ranking and recommendation tasks. We illustrate several key advantages of
our approach: (1) a single model can manage multiple predictive tasks involved
in ranking and recommendation, (2) decoder models with textual interface due to
their comprehension of reasoning capabilities, can generalize to new
recommendation surfaces and out-of-domain problems, and (3) by employing
natural language interfaces for task definitions and verbalizing member
behaviors and their social connections, we eliminate the need for feature
engineering and the maintenance of complex directed acyclic graphs of model
dependencies. We introduce our research pre-production model, 360Brew V1.0, a
150B parameter, decoder-only model that has been trained and fine-tuned on
LinkedIn's data and tasks. This model is capable of solving over 30 predictive
tasks across various segments of the LinkedIn platform, achieving performance
levels comparable to or exceeding those of current production systems based on
offline metrics, without task-specific fine-tuning. Notably, each of these
tasks is conventionally addressed by dedicated models that have been developed
and maintained over multiple years by teams of a similar or larger size than
our own.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ From Data Creator to Data Reuser: Distance Matters 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07926v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07926v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Christine L. Borgman, Paul T. Groth
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Sharing research data is necessary, but not sufficient, for data reuse. Open
science policies focus more heavily on data sharing than on reuse, yet both are
complex, labor-intensive, expensive, and require infrastructure investments by
multiple stakeholders. The value of data reuse lies in relationships between
creators and reusers. By addressing knowledge exchange, rather than mere
transactions between stakeholders, investments in data management and knowledge
infrastructures can be made more wisely. Drawing upon empirical studies of data
sharing and reuse, we develop the metaphor of distance between data creator and
data reuser, identifying six dimensions of distance that influence the ability
to transfer knowledge effectively: domain, methods, collaboration, curation,
purposes, and time and temporality. We explore how social and socio-technical
aspects of these dimensions may decrease -- or increase -- distances to be
traversed between creators and reusers. Our theoretical framing of the distance
between data creators and prospective reusers leads to recommendations to four
categories of stakeholders on how to make data sharing and reuse more
effective: data creators, data reusers, data archivists, and funding agencies.
'It takes a village' to share research data -- and a village to reuse data. Our
aim is to provoke new research questions, new research, and new investments in
effective and efficient circulation of research data; and to identify criteria
for investments at each stage of data and research life cycles.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>41 pages, single-spaced, consisting of Title information, Abstract,
  26 page narrative, 1 box, 1 figure, 1 table, 16 pages references. Original
  work</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ NV-Retriever: Improving text embedding models with effective
  hard-negative mining 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.15831v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.15831v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Gabriel de Souza P. Moreira, Radek Osmulski, Mengyao Xu, Ronay Ak, Benedikt Schifferer, Even Oldridge
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Text embedding models have been popular for information retrieval
applications such as semantic search and Question-Answering systems based on
Retrieval-Augmented Generation (RAG). Those models are typically Transformer
models that are fine-tuned with contrastive learning objectives. One of the
challenging aspects of fine-tuning embedding models is the selection of high
quality hard-negative passages for contrastive learning. In this paper we
introduce a family of positive-aware mining methods that use the positive
relevance score as an anchor for effective false negative removal, leading to
faster training and more accurate retrieval models. We provide an ablation
study on hard-negative mining methods over their configurations, exploring
different teacher and base models. We further demonstrate the efficacy of our
proposed mining methods at scale with the NV-Retriever-v1 model, which scores
60.9 on MTEB Retrieval (BEIR) benchmark and placed 1st when it was published to
the MTEB Retrieval on July, 2024.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Digital Gatekeeping: An Audit of Search Engine Results shows tailoring
  of queries on the Israel-Palestine Conflict 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04266v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04266v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Íris Damião, José M. Reis, Paulo Almeida, Nuno Santos, Joana Gonçalves-Sá
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search engines, often viewed as reliable gateways to information, tailor
search results using customization algorithms based on user preferences,
location, and more. While this can be useful for routine queries, it raises
concerns when the topics are sensitive or contentious, possibly limiting
exposure to diverse viewpoints and increasing polarization.
  To examine the extent of this tailoring, we focused on the Israel-Palestine
conflict and developed a privacy-protecting tool to audit the behavior of three
search engines: DuckDuckGo, Google and Yahoo. Our study focused on two main
questions: (1) How do search results for the same query about the conflict vary
among different users? and (2) Are these results influenced by the user's
location and browsing history?
  Our findings revealed significant customization based on location and
browsing preferences, unlike previous studies that found only mild
personalization for general topics. Moreover, queries related to the conflict
were more customized than unrelated queries, and the results were not neutral
concerning the conflict's portrayal.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 4 figures, 2 tables</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Extending and Applying Automated HERMES Software Publication Workflows 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.17614v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.17614v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sophie Kernchen, Michael Meinel, Stephan Druskat, Michael Fritzsche, David Pape, Oliver Bertuch
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Research software is an important output of research and must be published
according to the FAIR Principles for Research Software. This can be achieved by
publishing software with metadata under a persistent identifier. HERMES is a
tool that leverages continuous integration to automate the publication of
software with rich metadata. In this work, we describe the HERMES workflow
itself, and how to extend it to meet the needs of specific research software
metadata or infrastructure. We introduce the HERMES plugin architecture and
provide the example of creating a new HERMES plugin that harvests metadata from
a metadata source in source code repositories. We show how to use HERMES as an
end user, both via the command line interface, and as a step in a continuous
integration pipeline. Finally, we report three informal case studies whose
results provide a preliminary evaluation of the feasibility and applicability
of HERMES workflows, and the extensibility of the hermes software package.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>18 pages, 3 figures, 2 tables, 1 code listing, revision as accepted
  to a special issue of Electronic Communications of the EASST collecting
  submissions of deRSE24, Conference for Research Software Engineers</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Tethering Broken Themes: Aligning Neural Topic Models with Labels and
  Authors 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.18140v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.18140v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Mayank Nagda, Phil Ostheimer, Sophie Fellenz
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Topic models are a popular approach for extracting semantic information from
large document collections. However, recent studies suggest that the topics
generated by these models often do not align well with human intentions.
Although metadata such as labels and authorship information are available, it
has not yet been effectively incorporated into neural topic models. To address
this gap, we introduce FANToM, a novel method to align neural topic models with
both labels and authorship information. FANToM allows for the inclusion of this
metadata when available, producing interpretable topics and author
distributions for each topic. Our approach demonstrates greater expressiveness
than conventional topic models by learning the alignment between labels,
topics, and authors. Experimental results show that FANToM improves existing
models in terms of both topic quality and alignment. Additionally, it
identifies author interests and similarities.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Comprehending Knowledge Graphs with Large Language Models for
  Recommender Systems 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2410.12229v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2410.12229v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ziqiang Cui, Yunpeng Weng, Xing Tang, Fuyuan Lyu, Dugang Liu, Xiuqiang He, Chen Ma
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In recent years, the introduction of knowledge graphs (KGs) has significantly
advanced recommender systems by facilitating the discovery of potential
associations between items. However, existing methods still face several
limitations. First, most KGs suffer from missing facts or limited scopes.
Second, existing methods convert textual information in KGs into IDs, resulting
in the loss of natural semantic connections between different items. Third,
existing methods struggle to capture high-order connections in the global KG.
To address these limitations, we propose a novel method called CoLaKG, which
leverages large language models (LLMs) to improve KG-based recommendations. The
extensive world knowledge and remarkable reasoning capabilities of LLMs enable
our method to supplement missing facts in KGs. Additionally, their powerful
text understanding abilities allow for better utilization of semantic
information. Specifically, CoLaKG extracts useful information from the KG at
both local and global levels. By employing item-centered subgraph extraction
and prompt engineering, it accurately captures the local KG. Subsequently,
through retrieval-based neighbor enhancement, it supplements the current item
by capturing related items from the entire KG, thereby effectively utilizing
global information. The local and global information extracted by the LLM are
effectively integrated into the recommendation model through a representation
fusion module and a retrieval-augmented representation learning module,
respectively, thereby improving recommendation performance. Extensive
experiments on four real-world datasets demonstrate the superiority of our
method.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge
  in RAG Systems <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.02959v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.02959v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiejun Tan, Zhicheng Dou, Wen Wang, Mang Wang, Weipeng Chen, Ji-Rong Wen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-Augmented Generation (RAG) has been shown to improve knowledge
capabilities and alleviate the hallucination problem of LLMs. The Web is a
major source of external knowledge used in RAG systems, and many commercial RAG
systems have used Web search engines as their major retrieval systems.
Typically, such RAG systems retrieve search results, download HTML sources of
the results, and then extract plain texts from the HTML sources. Plain text
documents or chunks are fed into the LLMs to augment the generation. However,
much of the structural and semantic information inherent in HTML, such as
headings and table structures, is lost during this plain-text-based RAG
process. To alleviate this problem, we propose HtmlRAG, which uses HTML instead
of plain text as the format of retrieved knowledge in RAG. We believe HTML is
better than plain text in modeling knowledge in external documents, and most
LLMs possess robust capacities to understand HTML. However, utilizing HTML
presents new challenges. HTML contains additional content such as tags,
JavaScript, and CSS specifications, which bring extra input tokens and noise to
the RAG system. To address this issue, we propose HTML cleaning, compression,
and a two-step block-tree-based pruning strategy, to shorten the HTML while
minimizing the loss of information. Experiments on six QA datasets confirm the
superiority of using HTML in RAG systems.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2025 main conference. Repo:
  https://github.com/plageon/HtmlRAG</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Behavior Modeling Space Reconstruction for E-Commerce Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.18216v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.18216v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yejing Wang, Chi Zhang, Xiangyu Zhao, Qidong Liu, Maolin Wang, Xuewei Tao, Zitao Liu, Xing Shi, Xudong Yang, Ling Zhong, Wei Lin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Delivering superior search services is crucial for enhancing customer
experience and driving revenue growth. Conventionally, search systems model
user behaviors by combining user preference and query item relevance
statically, often through a fixed logical 'and' relationship. This paper
reexamines existing approaches through a unified lens using both causal graphs
and Venn diagrams, uncovering two prevalent yet significant issues: entangled
preference and relevance effects, and a collapsed modeling space. To surmount
these challenges, our research introduces a novel framework, DRP, which
enhances search accuracy through two components to reconstruct the behavior
modeling space. Specifically, we implement preference editing to proactively
remove the relevance effect from preference predictions, yielding untainted
user preferences. Additionally, we employ adaptive fusion, which dynamically
adjusts fusion criteria to align with the varying patterns of relevance and
preference, facilitating more nuanced and tailored behavior predictions within
the reconstructed modeling space. Empirical validation on two public datasets
and a proprietary search dataset underscores the superiority of our proposed
methodology, demonstrating marked improvements in performance over existing
approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement
  Framework for Multimodal Question Answering <span class="chip">COLING 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2408.08521v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2408.08521v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhengyuan Zhu, Daniel Lee, Hong Zhang, Sai Sree Harsha, Loic Feujio, Akash Maharaj, Yunyao Li
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in retrieval-augmented generation (RAG) have demonstrated
impressive performance in the question-answering (QA) task. However, most
previous works predominantly focus on text-based answers. While some studies
address multimodal data, they still fall short in generating comprehensive
multimodal answers, particularly for explaining concepts or providing
step-by-step tutorials on how to accomplish specific goals. This capability is
especially valuable for applications such as enterprise chatbots and settings
such as customer service and educational systems, where the answers are sourced
from multimodal data. In this paper, we introduce a simple and effective
framework named MuRAR (Multimodal Retrieval and Answer Refinement). MuRAR
enhances text-based answers by retrieving relevant multimodal data and refining
the responses to create coherent multimodal answers. This framework can be
easily extended to support multimodal answers in enterprise chatbots with
minimal modifications. Human evaluation results indicate that multimodal
answers generated by MuRAR are more useful and readable compared to plain text
answers.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted at COLING 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Latent Swap Joint Diffusion for Long-Form Audio Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.05130v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.05130v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Previous work on long-form audio generation using global-view diffusion or
iterative generation demands significant training or inference costs. While
recent advancements in multi-view joint diffusion for panoramic generation
provide an efficient option, they struggle with spectrum generation with severe
overlap distortions and high cross-view consistency costs. We initially explore
this phenomenon through the connectivity inheritance of latent maps and uncover
that averaging operations excessively smooth the high-frequency components of
the latent map. To address these issues, we propose Swap Forward (SaFa), a
frame-level latent swap framework that synchronizes multiple diffusions to
produce a globally coherent long audio with more spectrum details in a
forward-only manner. At its core, the bidirectional Self-Loop Latent Swap is
applied between adjacent views, leveraging stepwise diffusion trajectory to
adaptively enhance high-frequency components without disrupting low-frequency
components. Furthermore, to ensure cross-view consistency, the unidirectional
Reference-Guided Latent Swap is applied between the reference and the
non-overlap regions of each subview during the early stages, providing
centralized trajectory guidance. Quantitative and qualitative experiments
demonstrate that SaFa significantly outperforms existing joint diffusion
methods and even training-based long audio generation models. Moreover, we find
that it also adapts well to panoramic generation, achieving comparable
state-of-the-art performance with greater efficiency and model
generalizability. Project page is available at https://swapforward.github.io/.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Towards Multimodal Empathetic Response Generation: A Rich
  Text-Speech-Vision Avatar-based Benchmark <span class="chip">WWW</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04976v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04976v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Han Zhang, Zixiang Meng, Meng Luo, Hong Han, Lizi Liao, Erik Cambria, Hao Fei
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Empathetic Response Generation (ERG) is one of the key tasks of the affective
computing area, which aims to produce emotionally nuanced and compassionate
responses to user's queries. However, existing ERG research is predominantly
confined to the singleton text modality, limiting its effectiveness since human
emotions are inherently conveyed through multiple modalities. To combat this,
we introduce an avatar-based Multimodal ERG (MERG) task, entailing rich text,
speech, and facial vision information. We first present a large-scale
high-quality benchmark dataset, \textbf{AvaMERG}, which extends traditional
text ERG by incorporating authentic human speech audio and dynamic talking-face
avatar videos, encompassing a diverse range of avatar profiles and broadly
covering various topics of real-world scenarios. Further, we deliberately
tailor a system, named \textbf{Empatheia}, for MERG. Built upon a Multimodal
Large Language Model (MLLM) with multimodal encoder, speech and avatar
generators, Empatheia performs end-to-end MERG, with Chain-of-Empathetic
reasoning mechanism integrated for enhanced empathy understanding and
reasoning. Finally, we devise a list of empathetic-enhanced tuning strategies,
strengthening the capabilities of emotional accuracy and content,
avatar-profile consistency across modalities. Experimental results on AvaMERG
data demonstrate that Empatheia consistently shows superior performance than
baseline methods on both textual ERG and MERG. Overall, this work is expected
to pioneer the MERG research by introducing a novel benchmark and an end-to-end
model, laying a solid foundation for future advancements in multimodal
empathetic response generation.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by TheWebConf (WWW) 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ PDStream: Slashing Long-Tail Delay in Interactive Video Streaming via
  Pseudo-Dual Streaming 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04691v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04691v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuedou Xiao, Yingying Zuo, Mingxuan Yan, Kezhong Liu, Wei Wang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  End-to-end (E2E) delay is critical for interactive video streaming (IVS)
experiences, but remains unsatisfactory for its long-tail distribution caused
by periodic large keyframes. Conventional optimization strategies, such as
jitter buffer, bitrate adaptation, and customized encoding, either sacrifice
clarity, average delay, or compatibility. To address this issue, we propose
PDStream, a novel pseudo-dual streaming algorithm, aimed at minimizing E2E
delay while maintaining video clarity. The core idea is to split the two
functions, delay-sensitive playback and delay-tolerant reference, on keyframes
through dual streaming. Specifically, the playback function is held by a second
parallel stream, which comprises much smaller non-keyframes and is allocated
more immediate bandwidth for real-time performance. The reference function is
ensured by the first stream with keyframe preservation, allocated more
subsequent bandwidth to smooth out bursty traffic. Additionally, ``pseudo''
minimizes computational and transmission overheads by restricting dual streams
to brief activation only when keyframes appear, supported by corresponding
dual-stream bitrate allocation and adaptation to ensure delay and clarity. We
implement PDStream on a WebRTC-based IVS testbed with real-world network
traces. Results show that PDStream significantly outperforms prior algorithms,
reducing average E2E delay by 17.5\% and slashing its 97th percentile by
33.3\%, while keeping clarity under varying bandwidth.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>IEEE INFOCOM 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Long-tailed Medical Diagnosis with Relation-aware Representation
  Learning and Iterative Classifier Calibration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03238v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03238v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recently computer-aided diagnosis has demonstrated promising performance,
effectively alleviating the workload of clinicians. However, the inherent
sample imbalance among different diseases leads algorithms biased to the
majority categories, leading to poor performance for rare categories. Existing
works formulated this challenge as a long-tailed problem and attempted to
tackle it by decoupling the feature representation and classification. Yet, due
to the imbalanced distribution and limited samples from tail classes, these
works are prone to biased representation learning and insufficient classifier
calibration. To tackle these problems, we propose a new Long-tailed Medical
Diagnosis (LMD) framework for balanced medical image classification on
long-tailed datasets. In the initial stage, we develop a Relation-aware
Representation Learning (RRL) scheme to boost the representation ability by
encouraging the encoder to capture intrinsic semantic features through
different data augmentations. In the subsequent stage, we propose an Iterative
Classifier Calibration (ICC) scheme to calibrate the classifier iteratively.
This is achieved by generating a large number of balanced virtual features and
fine-tuning the encoder using an Expectation-Maximization manner. The proposed
ICC compensates for minority categories to facilitate unbiased classifier
optimization while maintaining the diagnostic knowledge in majority classes.
Comprehensive experiments on three public long-tailed medical datasets
demonstrate that our LMD framework significantly surpasses state-of-the-art
approaches. The source code can be accessed at
https://github.com/peterlipan/LMD.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted in Computers in Biology and Medicine</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ An End-to-End Pipeline Perspective on Video Streaming in Best-Effort
  Networks: A <span class="highlight-title">Survey</span> and Tutorial 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.05192v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.05192v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Leonardo Peroni, Sergey Gorinsky
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Remaining a dominant force in Internet traffic, video streaming captivates
end users, service providers, and researchers. This paper takes a pragmatic
approach to reviewing recent advances in the field by focusing on the prevalent
streaming paradigm that involves delivering long-form two-dimensional videos
over the best-effort Internet with client-side adaptive bitrate (ABR)
algorithms and assistance from content delivery networks (CDNs). To enhance
accessibility, we supplement the survey with tutorial material. Unlike existing
surveys that offer fragmented views, our work provides a holistic perspective
on the entire end-to-end streaming pipeline, from video capture by a
camera-equipped device to playback by the end user. Our novel perspective
covers the ingestion, processing, and distribution stages of the pipeline and
addresses key challenges such as video compression, upload, transcoding, ABR
algorithms, CDN support, and quality of experience. We review over 200 papers
and classify streaming designs by their problem-solving methodology, whether
based on intuition (simple heuristics), theory (formal optimization), or
machine learning (generalizable data patterns). The survey further refines
these methodology-based categories and characterizes each design by additional
traits such as compatible codecs and use of super resolution. We connect the
reviewed research to real-world applications by discussing the practices of
commercial streaming platforms. Finally, the survey highlights prominent
current trends and outlines future directions in video streaming.
</span>
                                    </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>
    <section class="day-container">
        <div class="date">
            <time datetime="2025-02-06T00:00:00Z">2025-02-06</time>
        </div>
            <article>
                <details>
                    <Summary>
                        Information Retrieval <span class="chip" style="font-size: 60%">15</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MRAMG-Bench: A BeyondText Benchmark for Multimodal Retrieval-Augmented
  Multimodal Generation 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04176v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04176v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Qinhan Yu, Zhiyou Xiao, Binghui Li, Zhengren Wang, Chong Chen, Wentao Zhang
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advancements in Retrieval-Augmented Generation (RAG) have shown
remarkable performance in enhancing response accuracy and relevance by
integrating external knowledge into generative models. However, existing RAG
methods primarily focus on providing text-only answers, even in multimodal
retrieval-augmented generation scenarios. In this work, we introduce the
Multimodal Retrieval-Augmented Multimodal Generation (MRAMG) task, which aims
to generate answers that combine both text and images, fully leveraging the
multimodal data within a corpus. Despite the importance of this task, there is
a notable absence of a comprehensive benchmark to effectively evaluate MRAMG
performance. To bridge this gap, we introduce the MRAMG-Bench, a carefully
curated, human-annotated dataset comprising 4,346 documents, 14,190 images, and
4,800 QA pairs, sourced from three categories: Web Data, Academic Papers, and
Lifestyle. The dataset incorporates diverse difficulty levels and complex
multi-image scenarios, providing a robust foundation for evaluating multimodal
generation tasks. To facilitate rigorous evaluation, our MRAMG-Bench
incorporates a comprehensive suite of both statistical and LLM-based metrics,
enabling a thorough analysis of the performance of popular generative models in
the MRAMG task. Besides, we propose an efficient multimodal answer generation
framework that leverages both LLMs and MLLMs to generate multimodal responses.
Our datasets are available at: https://huggingface.co/MRAMG.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>11 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MedRAG: Enhancing Retrieval-augmented Generation with Knowledge
  Graph-Elicited Reasoning for Healthcare Copilot 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04413v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04413v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Xuejiao Zhao, Siyan Liu, Su-Yin Yang, Chunyan Miao
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Retrieval-augmented generation (RAG) is a well-suited technique for
retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a
key module of the healthcare copilot, helping reduce misdiagnosis for
healthcare practitioners and patients. However, the diagnostic accuracy and
specificity of existing heuristic-based RAG models used in the medical domain
are inadequate, particularly for diseases with similar manifestations. This
paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited
reasoning for the medical domain that retrieves diagnosis and treatment
recommendations based on manifestations. MedRAG systematically constructs a
comprehensive four-tier hierarchical diagnostic KG encompassing critical
diagnostic differences of various diseases. These differences are dynamically
integrated with similar EHRs retrieved from an EHR database, and reasoned
within a large language model. This process enables more accurate and specific
decision support, while also proactively providing follow-up questions to
enhance personalized medical decision-making. MedRAG is evaluated on both a
public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)
collected from Tan Tock Seng Hospital, and its performance is compared against
various existing RAG methods. Experimental results show that, leveraging the
information integration and relational abilities of the KG, our MedRAG provides
more specific diagnostic insights and outperforms state-of-the-art models in
reducing misdiagnosis rates. Our code will be available at
https://github.com/SNOWTEAM2023/MedRAG
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Counterfactual Query Rewriting to Use Historical Relevance Feedback 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03891v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03891v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jüri Keller, Maik Fröbe, Gijs Hendriksen, Daria Alexander, Martin Potthast, Matthias Hagen, Philipp Schaer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  When a retrieval system receives a query it has encountered before, previous
relevance feedback, such as clicks or explicit judgments can help to improve
retrieval results. However, the content of a previously relevant document may
have changed, or the document might not be available anymore. Despite this
evolved corpus, we counterfactually use these previously relevant documents as
relevance signals. In this paper we proposed approaches to rewrite user queries
and compare them against a system that directly uses the previous qrels for the
ranking. We expand queries with terms extracted from the previously relevant
documents or derive so-called keyqueries that rank the previously relevant
documents to the top of the current corpus. Our evaluation in the CLEF LongEval
scenario shows that rewriting queries with historical relevance feedback
improves the retrieval effectiveness and even outperforms computationally
expensive transformer-based approaches.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Boosting Knowledge Graph-based Recommendations through Confidence-Aware
  Augmentation with Large Language Models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03715v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03715v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Rui Cai, Chao Wang, Qianyi Cai, Dazhong Shen, Hui Xiong
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Knowledge Graph-based recommendations have gained significant attention due
to their ability to leverage rich semantic relationships. However, constructing
and maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy
of KGs can suffer from noisy, outdated, or irrelevant triplets. Recent
advancements in Large Language Models (LLMs) offer a promising way to improve
the quality and relevance of KGs for recommendation tasks. Despite this,
integrating LLMs into KG-based systems presents challenges, such as efficiently
augmenting KGs, addressing hallucinations, and developing effective joint
learning methods. In this paper, we propose the Confidence-aware KG-based
Recommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework
that combines KGs and LLMs for recommendation task. The framework includes: (1)
an LLM-based subgraph augmenter for enriching KGs with high-quality
information, (2) a confidence-aware message propagation mechanism to filter
noisy triplets, and (3) a dual-view contrastive learning method to integrate
user-item interactions and KG data. Additionally, we employ a confidence-aware
explanation generation process to guide LLMs in producing realistic
explanations for recommendations. Finally, extensive experiments demonstrate
the effectiveness of CKG-LLMA across multiple public datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ LLM Alignment as Retriever Optimization: An Information Retrieval
  Perspective 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03699v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03699v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) have revolutionized artificial intelligence with
capabilities in reasoning, coding, and communication, driving innovation across
industries. Their true potential depends on effective alignment to ensure
correct, trustworthy and ethical behavior, addressing challenges like
misinformation, hallucinations, bias and misuse. While existing Reinforcement
Learning (RL)-based alignment methods are notoriously complex, direct
optimization approaches offer a simpler alternative. In this work, we introduce
a novel direct optimization approach for LLM alignment by drawing on
established Information Retrieval (IR) principles. We present a systematic
framework that bridges LLM alignment and IR methodologies, mapping LLM
generation and reward models to IR's retriever-reranker paradigm. Building on
this foundation, we propose LLM Alignment as Retriever Preference Optimization
(LarPO), a new alignment method that enhances overall alignment quality.
Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %
averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work
opens new avenues for advancing LLM alignment by integrating IR foundations,
offering a promising direction for future research.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>26 pages</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Emancipatory Information Retrieval 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2501.19241v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2501.19241v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Bhaskar Mitra
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Our world today is facing a confluence of several mutually reinforcing crises
each of which intersects with concerns of social justice and emancipation. This
paper is a provocation for the role of computer-mediated information access in
our emancipatory struggles. We define emancipatory information retrieval as the
study and development of information access methods that challenge various
forms of human oppression, and situates its activities within broader
collective emancipatory praxis. The term "emancipatory" here signifies the
moral concerns of universal humanization of all peoples and the elimination of
oppression to create the conditions under which we can collectively flourish.
To develop an emancipatory research agenda for information retrieval (IR), in
this paper we speculate about the practices that the community can adopt,
enumerate some of the projects that the field should undertake, and discuss
provocations to spark new ideas and directions for research. We challenge the
field of IR research to embrace humanistic values and commit to universal
emancipation and social justice as part of our research. In that process, the
community must both imagine post-oppressive worlds, and reimagine the role of
IR in that world and in the journey that leads us there.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ MA4DIV: Multi-Agent Reinforcement Learning for Search Result
  Diversification 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2403.17421v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2403.17421v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqun Chen, Jiaxin Mao, Yi Zhang, Dehong Ma, Long Xia, Jun Fan, Daiting Shi, Zhicong Cheng, Simiu Gu, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Search result diversification (SRD), which aims to ensure that documents in a
ranking list cover a broad range of subtopics, is a significant and widely
studied problem in Information Retrieval and Web Search. Existing methods
primarily utilize a paradigm of "greedy selection", i.e., selecting one
document with the highest diversity score at a time or optimize an
approximation of the objective function. These approaches tend to be
inefficient and are easily trapped in a suboptimal state. To address these
challenges, we introduce Multi-Agent reinforcement learning (MARL) for search
result DIVersity, which called MA4DIV. In this approach, each document is an
agent and the search result diversification is modeled as a cooperative task
among multiple agents. By modeling the SRD ranking problem as a cooperative
MARL problem, this approach allows for directly optimizing the diversity
metrics, such as $\alpha$-NDCG, while achieving high training efficiency. We
conducted experiments on public TREC datasets and a larger scale dataset in the
industrial setting. The experiemnts show that MA4DIV achieves substantial
improvements in both effectiveness and efficiency than existing baselines,
especially on the industrial dataset. The code of MA4DIV can be seen on
https://github.com/chenyiqun/MA4DIV.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TourRank: Utilizing Large Language Models for Documents Ranking with a
  Tournament-Inspired Strategy 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2406.11678v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2406.11678v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yiqun Chen, Qi Liu, Yi Zhang, Weiwei Sun, Xinyu Ma, Wei Yang, Daiting Shi, Jiaxin Mao, Dawei Yin
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large Language Models (LLMs) are increasingly employed in zero-shot documents
ranking, yielding commendable results. However, several significant challenges
still persist in LLMs for ranking: (1) LLMs are constrained by limited input
length, precluding them from processing a large number of documents
simultaneously; (2) The output document sequence is influenced by the input
order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a
balance between cost and ranking performance is challenging. To tackle these
issues, we introduce a novel documents ranking method called TourRank, which is
inspired by the sport tournaments, such as FIFA World Cup. Specifically, we 1)
overcome the limitation in input length and reduce the ranking latency by
incorporating a multi-stage grouping strategy similar to the parallel group
stage of sport tournaments; 2) improve the ranking performance and robustness
to input orders by using a points system to ensemble multiple ranking results.
We test TourRank with different LLMs on the TREC DL datasets and the BEIR
benchmark. The experimental results demonstrate that TourRank delivers
state-of-the-art performance at a modest cost. The code of TourRank can be seen
on https://github.com/chenyiqun/TourRank.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Generalization analysis of an unfolding network for analysis-based
  Compressed Sensing 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2303.05582v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2303.05582v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Vicky Kouni, Yannis Panagakis
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Unfolding networks have shown promising results in the Compressed Sensing
(CS) field. Yet, the investigation of their generalization ability is still in
its infancy. In this paper, we perform a generalization analysis of a
state-of-the-art ADMM-based unfolding network, which jointly learns a decoder
for CS and a sparsifying redundant analysis operator. To this end, we first
impose a structural constraint on the learnable sparsifier, which parametrizes
the network's hypothesis class. For the latter, we estimate its Rademacher
complexity. With this estimate in hand, we deliver generalization error bounds
-- which scale like the square root of the number of layers -- for the examined
network. Finally, the validity of our theory is assessed and numerical
comparisons to a state-of-the-art unfolding network are made, on synthetic and
real-world datasets. Our experimental results demonstrate that our proposed
framework complies with our theoretical findings and outperforms the baseline,
consistently for all datasets.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Had enough of experts? Quantitative knowledge retrieval from large
  language models 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2402.07770v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2402.07770v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        David Selby, Kai Spriestersbach, Yuichiro Iwashita, Mohammad Saad, Dennis Bappert, Archana Warrier, Sumantrak Mukherjee, Koichi Kise, Sebastian Vollmer
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have been extensively studied for their
abilities to generate convincing natural language sequences, however their
utility for quantitative information retrieval is less well understood. Here we
explore the feasibility of LLMs as a mechanism for quantitative knowledge
retrieval to aid two data analysis tasks: elicitation of prior distributions
for Bayesian models and imputation of missing data. We introduce a framework
that leverages LLMs to enhance Bayesian workflows by eliciting expert-like
prior knowledge and imputing missing data. Tested on diverse datasets, this
approach can improve predictive accuracy and reduce data requirements, offering
significant potential in healthcare, environmental science and engineering
applications. We discuss the implications and challenges of treating LLMs as
'experts'.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ SPRec: Self-Play to Debias LLM-based Recommendation <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.09243v3">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.09243v3.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Chongming Gao, Ruijun Chen, Shuai Yuan, Kexin Huang, Yuanqing Yu, Xiangnan He
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Large language models (LLMs) have attracted significant attention in
recommendation systems. Current work primarily applies supervised fine-tuning
(SFT) to adapt the model for recommendation tasks. However, SFT on positive
examples only limits the model's ability to align with user preference. To
address this, researchers recently introduced Direct Preference Optimization
(DPO), which explicitly aligns LLMs with user preferences using offline
preference ranking data. However, we found that DPO inherently biases the model
towards a few items, exacerbating the filter bubble issue and ultimately
degrading user experience.
  In this paper, we propose SPRec, a novel self-play framework designed to
mitigate over-recommendation and improve fairness without requiring additional
data or manual intervention. In each self-play iteration, the model undergoes
an SFT step followed by a DPO step, treating offline interaction data as
positive samples and the predicted outputs from the previous iteration as
negative samples. This effectively re-weights the DPO loss function using the
model's logits, adaptively suppressing biased items. Extensive experiments on
multiple real-world datasets demonstrate SPRec's effectiveness in enhancing
recommendation accuracy and fairness. The implementation is available via
https://github.com/RegionCh/SPRec
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Accepted by WWW 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ CPRM: A LLM-based Continual <span class="highlight-title">Pre-train</span>ing Framework for Relevance
  Modeling in Commercial Search 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.01269v4">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.01269v4.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Kaixin Wu, Yixin Ji, Zeyuan Chen, Qiang Wang, Cunxiang Wang, Hong Liu, Baijun Ji, Jia Xu, Zhongyi Liu, Jinjie Gu, Yuan Zhou, Linjian Mo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Relevance modeling between queries and items stands as a pivotal component in
commercial search engines, directly affecting the user experience. Given the
remarkable achievements of large language models (LLMs) in various natural
language processing (NLP) tasks, LLM-based relevance modeling is gradually
being adopted within industrial search systems. Nevertheless, foundational LLMs
lack domain-specific knowledge and do not fully exploit the potential of
in-context learning. Furthermore, structured item text remains underutilized,
and there is a shortage in the supply of corresponding queries and background
knowledge. We thereby propose CPRM (Continual Pre-training for Relevance
Modeling), a framework designed for the continual pre-training of LLMs to
address these issues. Our CPRM framework includes three modules: 1) employing
both queries and multi-field item to jointly pre-train for enhancing domain
knowledge, 2) applying in-context pre-training, a novel approach where LLMs are
pre-trained on a sequence of related queries or items, and 3) conducting
reading comprehension on items to produce associated domain knowledge and
background information (e.g., generating summaries and corresponding queries)
to further strengthen LLMs. Results on offline experiments and online A/B
testing demonstrate that our model achieves convincing performance compared to
strong baselines.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction
  System <span class="chip">WWW 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2412.20005v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2412.20005v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Yujie Luo, Xiangyuan Ru, Kangwei Liu, Lin Yuan, Mengshu Sun, Ningyu Zhang, Lei Liang, Zhiqiang Zhang, Jun Zhou, Lanning Wei, Da Zheng, Haofen Wang, Huajun Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  We introduce OneKE, a dockerized schema-guided knowledge extraction system,
which can extract knowledge from the Web and raw PDF Books, and support various
domains (science, news, etc.). Specifically, we design OneKE with multiple
agents and a configure knowledge base. Different agents perform their
respective roles, enabling support for various extraction scenarios. The
configure knowledge base facilitates schema configuration, error case debugging
and correction, further improving the performance. Empirical evaluations on
benchmark datasets demonstrate OneKE's efficacy, while case studies further
elucidate its adaptability to diverse tasks across multiple domains,
highlighting its potential for broad applications. We have open-sourced the
Code at https://github.com/zjunlp/OneKE and released a Video at
http://oneke.openkg.cn/demo.mp4.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WWW 2025 Demonstration</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ ColPali: Efficient Document Retrieval with Vision Language Models <span class="chip">ICLR 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2407.01449v5">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2407.01449v5.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Manuel Faysse, Hugues Sibille, Tony Wu, Bilel Omrani, Gautier Viaud, Céline Hudelot, Pierre Colombo
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Documents are visually rich structures that convey information through text,
but also figures, page layouts, tables, or even fonts. Since modern retrieval
systems mainly rely on the textual information they extract from document pages
to index documents -often through lengthy and brittle processes-, they struggle
to exploit key visual cues efficiently. This limits their capabilities in many
practical document retrieval applications such as Retrieval Augmented
Generation (RAG). To benchmark current systems on visually rich document
retrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe,
composed of various page-level retrieval tasks spanning multiple domains,
languages, and practical settings. The inherent complexity and performance
shortcomings of modern systems motivate a new concept; doing document retrieval
by directly embedding the images of the document pages. We release ColPali, a
Vision Language Model trained to produce high-quality multi-vector embeddings
from images of document pages. Combined with a late interaction matching
mechanism, ColPali largely outperforms modern document retrieval pipelines
while being drastically simpler, faster and end-to-end trainable. We release
models, data, code and benchmarks under open licenses at https://hf.co/vidore.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>Published as a conference paper at ICLR 2025</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ TD3: Tucker Decomposition Based <span class="highlight-title">Dataset</span> Distillation Method for
  Sequential Recommendation <span class="chip">WWW2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.02854v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.02854v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Jiaqing Zhang, Mingjia Yin, Hao Wang, Yawen Li, Yuyang Ye, Xingyu Lou, Junping Du, Enhong Chen
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  In the era of data-centric AI, the focus of recommender systems has shifted
from model-centric innovations to data-centric approaches. The success of
modern AI models is built on large-scale datasets, but this also results in
significant training costs. Dataset distillation has emerged as a key solution,
condensing large datasets to accelerate model training while preserving model
performance. However, condensing discrete and sequentially correlated user-item
interactions, particularly with extensive item sets, presents considerable
challenges. This paper introduces \textbf{TD3}, a novel \textbf{T}ucker
\textbf{D}ecomposition based \textbf{D}ataset \textbf{D}istillation method
within a meta-learning framework, designed for sequential recommendation. TD3
distills a fully expressive \emph{synthetic sequence summary} from original
data. To efficiently reduce computational complexity and extract refined latent
patterns, Tucker decomposition decouples the summary into four factors:
\emph{synthetic user latent factor}, \emph{temporal dynamics latent factor},
\emph{shared item latent factor}, and a \emph{relation core} that models their
interconnections. Additionally, a surrogate objective in bi-level optimization
is proposed to align feature spaces extracted from models trained on both
original data and synthetic sequence summary beyond the na\"ive performance
matching approach. In the \emph{inner-loop}, an augmentation technique allows
the learner to closely fit the synthetic summary, ensuring an accurate update
of it in the \emph{outer-loop}. To accelerate the optimization process and
address long dependencies, RaT-BPTT is employed for bi-level optimization.
Experiments and analyses on multiple public datasets have confirmed the
superiority and cross-architecture generalizability of the proposed designs.
Codes are released at https://github.com/USTC-StarTeam/TD3.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>This work has been accepted by WWW2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
            <article>
                <details>
                    <Summary>
                        Multimedia <span class="chip" style="font-size: 60%">5</span>
                    </Summary>
                    <div class="details-content">
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based
  Speech Synthesis 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04128v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04128v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zhen Ye, Xinfa Zhu, Chi-Min Chan, Xinsheng Wang, Xu Tan, Jiahe Lei, Yi Peng, Haohe Liu, Yizhu Jin, Zheqi DAI, Hongzhan Lin, Jianyi Chen, Xingjian Du, Liumeng Xue, Yunlin Chen, Zhifei Li, Lei Xie, Qiuqiang Kong, Yike Guo, Wei Xue
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Recent advances in text-based large language models (LLMs), particularly in
the GPT series and the o1 model, have demonstrated the effectiveness of scaling
both training-time and inference-time compute. However, current
state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring
separate models (e.g., diffusion models after LLM), complicating the decision
of whether to scale a particular model during training or testing. This work
makes the following contributions: First, we explore the scaling of train-time
and inference-time compute for speech synthesis. Second, we propose a simple
framework Llasa for speech synthesis that employs a single-layer vector
quantizer (VQ) codec and a single Transformer architecture to fully align with
standard LLMs such as Llama. Our experiments reveal that scaling train-time
compute for Llasa consistently improves the naturalness of synthesized speech
and enables the generation of more complex and accurate prosody patterns.
Furthermore, from the perspective of scaling inference-time compute, we employ
speech understanding models as verifiers during the search, finding that
scaling inference-time compute shifts the sampling modes toward the preferences
of specific verifiers, thereby improving emotional expressiveness, timbre
consistency, and content accuracy. In addition, we released the checkpoint and
training code for our TTS model (1B, 3B, 8B) and codec model publicly
available.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ CDIO: Cross-Domain Inference Optimization with Resource Preference
  Prediction for Edge-Cloud Collaboration 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04078v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04078v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Zheming Yang, Wen Ji, Qi Guo, Dieli Hu, Chang Zhao, Xiaowei Li, Xuanlei Zhao, Yi Zhao, Chaoyu Gong, Yang You
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Currently, massive video tasks are processed by edge-cloud collaboration.
However, the diversity of task requirements and the dynamics of resources pose
great challenges to efficient inference, resulting in many wasted resources. In
this paper, we present CDIO, a cross-domain inference optimization framework
designed for edge-cloud collaboration. For diverse input tasks, CDIO can
predict resource preference types by analyzing spatial complexity and
processing requirements of the task. Subsequently, a cross-domain collaborative
optimization algorithm is employed to guide resource allocation in the
edge-cloud system. By ensuring that each task is matched with the ideal
servers, the edge-cloud system can achieve higher efficiency inference. The
evaluation results on public datasets demonstrate that CDIO can effectively
meet the accuracy and delay requirements for task processing. Compared to
state-of-the-art edge-cloud solutions, CDIO achieves a computing and bandwidth
consumption reduction of 20%-40%. And it can reduce energy consumption by more
than 40%.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>10 pages, 9 figures</span>
                                        </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ Adaptive Prototype Knowledge Transfer for Federated Learning with Mixed
  Modalities and Heterogeneous Tasks 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.04400v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.04400v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Keke Gai, Mohan Wang, Jing Yu, Dongjue Wang, Qi Wu
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Multimodal Federated Learning (MFL) enables multiple clients to
collaboratively train models on multimodal data while ensuring clients'
privacy. However, modality and task heterogeneity hinder clients from learning
a unified representation, weakening local model generalization, especially in
MFL with mixed modalities where only some clients have multimodal data. In this
work, we propose an Adaptive prototype-based Multimodal Federated Learning
(AproMFL) framework for mixed modalities and heterogeneous tasks to address the
aforementioned issues. Our AproMFL transfers knowledge through
adaptively-constructed prototypes without a prior public dataset. Clients
adaptively select prototype construction methods in line with tasks; server
converts client prototypes into unified multimodal prototypes and aggregates
them to form global prototypes, avoid clients keeping unified labels. We divide
the model into various modules and only aggregate mapping modules to reduce
communication and computation overhead. To address aggregation issues in
heterogeneity, we develop a client relationship graph-based scheme to
dynamically adjust aggregation weights. Extensive experiments on representative
datasets evidence effectiveness of AproMFL.
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                         ☆ MD-<span class="highlight-title">BERT</span>: Action Recognition in Dark Videos via Dynamic Multi-Stream
  Fusion and Temporal Modeling 
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2502.03724v1">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2502.03724v1.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Sharana Dharshikgan Suresh Dass, Hrishav Bakul Barua, Ganesh Krishnasamy, Raveendran Paramesran, Raphael C. -W. Phan
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Action recognition in dark, low-light (under-exposed) or noisy videos is a
challenging task due to visibility degradation, which can hinder critical
spatiotemporal details. This paper proposes MD-BERT, a novel multi-stream
approach that integrates complementary pre-processing techniques such as gamma
correction and histogram equalization alongside raw dark frames to address
these challenges. We introduce the Dynamic Feature Fusion (DFF) module,
extending existing attentional fusion methods to a three-stream setting,
thereby capturing fine-grained and global contextual information across
different brightness and contrast enhancements. The fused spatiotemporal
features are then processed by a BERT-based temporal model, which leverages its
bidirectional self-attention to effectively capture long-range dependencies and
contextual relationships across frames. Extensive experiments on the ARID V1.0
and ARID V1.5 dark video datasets show that MD-BERT outperforms existing
methods, establishing a new state-of-the-art performance. Ablation studies
further highlight the individual contributions of each input stream and the
effectiveness of the proposed DFF and BERT modules. The official website of
this work is available at: https://github.com/HrishavBakulBarua/DarkBERT
</span>
                                    </div>
                                </details>
                            </article>
                            <article>
                                <details class="article-expander">
                                    <summary class="article-expander-title">
                                        ♻ ☆ Improving Accuracy and Generalization for Efficient Visual Tracking <span class="chip">WACV 2025</span>
                                    </summary>
                                    <div class="article-authors">
                                        <a href="http://arxiv.org/abs/2411.18855v2">
                                            <i class="ri-links-line"></i>
                                        </a>
                                        <a href="https://arxiv.org/pdf/2411.18855v2.pdf">
                                            <i class="ri-file-paper-2-line"></i>
                                        </a>
                                        Ram Zaveri, Shivang Patel, Yu Gu, Gianfranco Doretto
                                    </div>
                                    <div class="article-summary-box-inner">
                                        <span>  Efficient visual trackers overfit to their training distributions and lack
generalization abilities, resulting in them performing well on their respective
in-distribution (ID) test sets and not as well on out-of-distribution (OOD)
sequences, imposing limitations to their deployment in-the-wild under
constrained resources. We introduce SiamABC, a highly efficient Siamese tracker
that significantly improves tracking performance, even on OOD sequences.
SiamABC takes advantage of new architectural designs in the way it bridges the
dynamic variability of the target, and of new losses for training. Also, it
directly addresses OOD tracking generalization by including a fast
backward-free dynamic test-time adaptation method that continuously adapts the
model according to the dynamic visual changes of the target. Our extensive
experiments suggest that SiamABC shows remarkable performance gains in OOD sets
while maintaining accurate performance on the ID benchmarks. SiamABC
outperforms MixFormerV2-S by 7.6\% on the OOD AVisT benchmark while being 3x
faster (100 FPS) on a CPU. Our code and models are available at
https://wvuvl.github.io/SiamABC/.
</span>
                                    </div>
                                        <div class="article-summary-box-inner">
                                            <span class="chip">comment</span>: <span>WACV 2025</span>
                                        </div>
                                </details>
                            </article>
                    </div>
                </details>
            </article>
    </section>

</body>

<footer>
    <div>
        <time id="build-timestamp" datetime="2025-02-14T05:26:13.361071388Z">
            2025-02-14 05:26:13 UTC
        </time>
    </div>
</footer>
<script src="index.js"></script>
</html>
